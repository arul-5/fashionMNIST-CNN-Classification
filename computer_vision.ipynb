{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arulk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "#importing necessary libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.FashionMNIST(root = \"data\",\n",
    "                                  train = True,\n",
    "                                  download=True,\n",
    "                                   transform=ToTensor(),\n",
    "                                   target_transform=None\n",
    "                                   )\n",
    "test_data = datasets.FashionMNIST(\n",
    "  root = \"data\",\n",
    "  train = False,\n",
    "  download=True,\n",
    "  transform=ToTensor(),\n",
    "  target_transform=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0431,\n",
       "           0.5569, 0.7843, 0.4157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.3333, 0.7255, 0.4392, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5961, 0.8392,\n",
       "           0.8510, 0.7608, 0.9255, 0.8471, 0.7333, 0.5843, 0.5294, 0.6000,\n",
       "           0.8275, 0.8510, 0.9059, 0.8039, 0.8510, 0.7373, 0.1333, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2588, 0.7255, 0.6510,\n",
       "           0.7059, 0.7098, 0.7451, 0.8275, 0.8667, 0.7725, 0.5725, 0.7765,\n",
       "           0.8078, 0.7490, 0.6588, 0.7451, 0.6745, 0.7373, 0.6863, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5294, 0.6000, 0.6275,\n",
       "           0.6863, 0.7059, 0.6667, 0.7294, 0.7333, 0.7451, 0.7373, 0.7451,\n",
       "           0.7333, 0.6824, 0.7647, 0.7255, 0.6824, 0.6314, 0.6863, 0.2314,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6314, 0.5765, 0.6275,\n",
       "           0.6667, 0.6980, 0.6941, 0.7059, 0.6588, 0.6784, 0.6824, 0.6706,\n",
       "           0.7255, 0.7216, 0.7255, 0.6745, 0.6706, 0.6431, 0.6824, 0.4706,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.6863, 0.5725, 0.5686,\n",
       "           0.6588, 0.6980, 0.7098, 0.7255, 0.7059, 0.7216, 0.6980, 0.7020,\n",
       "           0.7333, 0.7490, 0.7569, 0.7451, 0.7098, 0.6706, 0.6745, 0.6196,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.6941, 0.6078, 0.5490,\n",
       "           0.5922, 0.6745, 0.7490, 0.7333, 0.7294, 0.7333, 0.7294, 0.7333,\n",
       "           0.7137, 0.7490, 0.7608, 0.7373, 0.7059, 0.6314, 0.6314, 0.7255,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2314, 0.6667, 0.6000, 0.5529,\n",
       "           0.4706, 0.6039, 0.6275, 0.6314, 0.6745, 0.6588, 0.6510, 0.6314,\n",
       "           0.6471, 0.6745, 0.6667, 0.6431, 0.5451, 0.5843, 0.6353, 0.6510,\n",
       "           0.0824, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.3098, 0.5686, 0.6275, 0.8392,\n",
       "           0.4824, 0.5020, 0.6000, 0.6275, 0.6431, 0.6196, 0.6157, 0.6039,\n",
       "           0.6078, 0.6667, 0.6471, 0.5529, 0.7647, 0.7569, 0.5961, 0.6510,\n",
       "           0.2392, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.3922, 0.6157, 0.8824, 0.9608,\n",
       "           0.6863, 0.4431, 0.6824, 0.6196, 0.6196, 0.6275, 0.6078, 0.6275,\n",
       "           0.6431, 0.6980, 0.7373, 0.5294, 0.7255, 0.9412, 0.7882, 0.6745,\n",
       "           0.4235, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1216, 0.6824, 0.1098,\n",
       "           0.4941, 0.6000, 0.6510, 0.5961, 0.6196, 0.6196, 0.6275, 0.6314,\n",
       "           0.6157, 0.6588, 0.7490, 0.7373, 0.0706, 0.5176, 0.6235, 0.0275,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.3216, 0.7333, 0.6235, 0.6000, 0.6157, 0.6196, 0.6353, 0.6431,\n",
       "           0.6431, 0.6039, 0.7333, 0.7451, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118, 0.0196, 0.0000,\n",
       "           0.1451, 0.6863, 0.6196, 0.6078, 0.6353, 0.6196, 0.6275, 0.6353,\n",
       "           0.6471, 0.6000, 0.6941, 0.8039, 0.0000, 0.0000, 0.0118, 0.0118,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000,\n",
       "           0.0980, 0.6863, 0.5961, 0.6275, 0.6196, 0.6314, 0.6275, 0.6431,\n",
       "           0.6431, 0.6314, 0.6510, 0.7843, 0.0000, 0.0000, 0.0039, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.0000,\n",
       "           0.1176, 0.6706, 0.5765, 0.6431, 0.6078, 0.6471, 0.6314, 0.6471,\n",
       "           0.6353, 0.6667, 0.6431, 0.6353, 0.0000, 0.0000, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.0000,\n",
       "           0.2235, 0.6510, 0.6078, 0.6431, 0.6510, 0.6314, 0.6314, 0.6431,\n",
       "           0.6549, 0.6471, 0.6471, 0.6353, 0.1098, 0.0000, 0.0118, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000,\n",
       "           0.4471, 0.6314, 0.6314, 0.6510, 0.6235, 0.6588, 0.6314, 0.6314,\n",
       "           0.6745, 0.6353, 0.6471, 0.6706, 0.1961, 0.0000, 0.0196, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000,\n",
       "           0.5843, 0.6157, 0.6549, 0.6745, 0.6235, 0.6745, 0.6431, 0.6314,\n",
       "           0.6745, 0.6667, 0.6275, 0.6706, 0.3490, 0.0000, 0.0157, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0157,\n",
       "           0.6706, 0.6431, 0.6510, 0.6784, 0.6235, 0.7020, 0.6510, 0.6275,\n",
       "           0.6824, 0.6549, 0.6353, 0.6510, 0.5020, 0.0000, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.0706,\n",
       "           0.5961, 0.6784, 0.6275, 0.7020, 0.6039, 0.7098, 0.6510, 0.6431,\n",
       "           0.6863, 0.6667, 0.6510, 0.6667, 0.6431, 0.0000, 0.0000, 0.0039,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.0000, 0.1843,\n",
       "           0.6471, 0.6745, 0.6549, 0.7255, 0.6000, 0.7333, 0.6784, 0.6471,\n",
       "           0.6824, 0.7020, 0.6510, 0.6510, 0.6196, 0.0196, 0.0000, 0.0118,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.0000, 0.3412,\n",
       "           0.7059, 0.6353, 0.7020, 0.7020, 0.6157, 0.7490, 0.7137, 0.6471,\n",
       "           0.6588, 0.7451, 0.6784, 0.6471, 0.6510, 0.0784, 0.0000, 0.0157,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.0000, 0.4118,\n",
       "           0.7333, 0.6157, 0.7608, 0.6863, 0.6314, 0.7451, 0.7216, 0.6667,\n",
       "           0.6196, 0.8039, 0.6941, 0.6588, 0.6706, 0.1725, 0.0000, 0.0157,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0196, 0.0000, 0.5412,\n",
       "           0.7098, 0.6196, 0.8039, 0.6275, 0.6549, 0.7451, 0.7765, 0.6549,\n",
       "           0.5961, 0.8549, 0.7294, 0.6667, 0.6745, 0.2235, 0.0000, 0.0196,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0196, 0.0000, 0.5294,\n",
       "           0.6824, 0.6549, 0.7804, 0.6078, 0.6510, 0.7882, 0.8588, 0.6471,\n",
       "           0.6196, 0.8549, 0.7373, 0.6549, 0.6863, 0.2196, 0.0000, 0.0275,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0196, 0.0000, 0.5059,\n",
       "           0.6706, 0.6745, 0.6941, 0.6000, 0.6235, 0.8078, 0.8471, 0.5804,\n",
       "           0.6157, 0.8078, 0.7451, 0.6471, 0.6863, 0.1882, 0.0000, 0.0196,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0196, 0.0000, 0.6549,\n",
       "           0.7333, 0.7137, 0.7765, 0.7608, 0.7843, 0.8863, 0.9412, 0.7216,\n",
       "           0.8078, 1.0000, 0.7725, 0.6980, 0.7020, 0.1647, 0.0000, 0.0196,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.4510,\n",
       "           0.5294, 0.4431, 0.4157, 0.3333, 0.3216, 0.4235, 0.5216, 0.3255,\n",
       "           0.3529, 0.4745, 0.4706, 0.4314, 0.6196, 0.0706, 0.0000, 0.0118,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = train_data[10]\n",
    "image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T-shirt/top': 0,\n",
       " 'Trouser': 1,\n",
       " 'Pullover': 2,\n",
       " 'Dress': 3,\n",
       " 'Coat': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'Bag': 8,\n",
       " 'Ankle boot': 9}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_to_idx = train_data.class_to_idx\n",
    "class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 0, 0,  ..., 3, 0, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28d2a069d50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualizing the data\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "plt.imshow(image.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.squeeze(), cmap = \"gray\")\n",
    "plt.title(class_names[label])\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset FashionMNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: ToTensor(),\n",
       " Dataset FashionMNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: data\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: ToTensor())"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "BATCH_SIZE = 32\n",
    "train_dataloader = DataLoader(dataset =train_data,\n",
    "                              batch_size = BATCH_SIZE,\n",
    "                              shuffle = True)\n",
    "test_dataloader = DataLoader(dataset = test_data,\n",
    "                             batch_size = BATCH_SIZE,\n",
    "                             shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x28d2a13fe80>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x28d7f1843a0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before flattening: torch.Size([1, 28, 28])\n",
      "Shape after flattening: torch.Size([1, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten_model  = nn.Flatten()\n",
    "x = train_features_batch[0] \n",
    "output = flatten_model(x)\n",
    "print(f\"Shape before flattening: {x.shape}\")\n",
    "print(f\"Shape after flattening: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTModelV0(nn.Module):\n",
    "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "    super().__init__()\n",
    "    self.layer_stack = nn.Sequential(\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "      nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
    "    )\n",
    "  def forward(self,x):\n",
    "    return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNISTModelV0(\n",
       "  (layer_stack): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model_0  =FashionMNISTModelV0(\n",
    "  input_shape=28*28,\n",
    "  hidden_units=10,\n",
    "  output_shape=len(class_names)\n",
    "\n",
    ")\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0315,  0.3171,  0.0531, -0.2525,  0.5959,  0.2112,  0.3233,  0.2694,\n",
       "         -0.1004,  0.0157]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_x = torch.rand([1,1,28,28])\n",
    "model_0(dummy_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer_stack.1.weight',\n",
       "              tensor([[ 0.0273,  0.0296, -0.0084,  ..., -0.0142,  0.0093,  0.0135],\n",
       "                      [-0.0188, -0.0354,  0.0187,  ..., -0.0106, -0.0001,  0.0115],\n",
       "                      [-0.0008,  0.0017,  0.0045,  ..., -0.0127, -0.0188,  0.0059],\n",
       "                      ...,\n",
       "                      [-0.0116,  0.0273, -0.0344,  ...,  0.0176,  0.0283, -0.0011],\n",
       "                      [-0.0230,  0.0257,  0.0291,  ..., -0.0187, -0.0087,  0.0001],\n",
       "                      [ 0.0176, -0.0147,  0.0053,  ..., -0.0336, -0.0221,  0.0205]])),\n",
       "             ('layer_stack.1.bias',\n",
       "              tensor([-0.0093,  0.0283, -0.0033,  0.0255,  0.0017,  0.0037, -0.0302, -0.0123,\n",
       "                       0.0018,  0.0163])),\n",
       "             ('layer_stack.2.weight',\n",
       "              tensor([[ 0.0614, -0.0687,  0.0021,  0.2718,  0.2109,  0.1079, -0.2279, -0.1063,\n",
       "                        0.2019,  0.2847],\n",
       "                      [-0.1495,  0.1344, -0.0740,  0.2006, -0.0475, -0.2514, -0.3130, -0.0118,\n",
       "                        0.0932, -0.1864],\n",
       "                      [ 0.2488,  0.1500,  0.1907,  0.1457, -0.3050, -0.0580,  0.1643,  0.1565,\n",
       "                       -0.2877, -0.1792],\n",
       "                      [ 0.2305, -0.2618,  0.2397, -0.0610,  0.0232,  0.1542,  0.0851, -0.2027,\n",
       "                        0.1030, -0.2715],\n",
       "                      [-0.1596, -0.0555, -0.0633,  0.2302, -0.1726,  0.2654,  0.1473,  0.1029,\n",
       "                        0.2252, -0.2160],\n",
       "                      [-0.2725,  0.0118,  0.1559,  0.1596,  0.0132,  0.3024,  0.1124,  0.1366,\n",
       "                       -0.1533,  0.0965],\n",
       "                      [-0.1184, -0.2555, -0.2057, -0.1909, -0.0477, -0.1324,  0.2905,  0.1307,\n",
       "                       -0.2629,  0.0133],\n",
       "                      [ 0.2727, -0.0127,  0.0513,  0.0863, -0.1043, -0.2047, -0.1185, -0.0825,\n",
       "                        0.2488, -0.2571],\n",
       "                      [ 0.0425, -0.1209, -0.0336, -0.0281, -0.1227,  0.0730,  0.0747, -0.1816,\n",
       "                        0.1943,  0.2853],\n",
       "                      [-0.1310,  0.0645, -0.1171,  0.2168, -0.0245, -0.2820,  0.0736,  0.2621,\n",
       "                        0.0012, -0.0810]])),\n",
       "             ('layer_stack.2.bias',\n",
       "              tensor([-0.0087,  0.1791,  0.2712, -0.0791,  0.1685,  0.1762,  0.2825,  0.2266,\n",
       "                      -0.2612, -0.2613]))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "  correct = torch.eq(y_true, y_pred).sum().item()\n",
    "  acc= (correct/ len(y_pred)) * 100\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params = model_0.parameters(),\n",
    "                           lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer \n",
    "def print_train_time(start:float, end: float, device: torch.device = None):\n",
    "  \"\"\"prints difference start and end time\"\"\"\n",
    "  total_time = end-start\n",
    "  print(f\"Train time is {total_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5b98eaf6864bd8bdcca1f4c0c2eb66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.5904 | Test Loss: 0.5095, Test Acc: 82.0387\n",
      "Epoch: 1\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4763 | Test Loss: 0.4799, Test Acc: 83.1969\n",
      "Epoch: 2\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4550 | Test Loss: 0.4766, Test Acc: 83.4265\n",
      "Epoch: 3\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4425 | Test Loss: 0.4631, Test Acc: 83.7460\n",
      "Epoch: 4\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4358 | Test Loss: 0.4687, Test Acc: 83.2668\n",
      "Epoch: 5\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4291 | Test Loss: 0.4589, Test Acc: 83.6362\n",
      "Epoch: 6\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4248 | Test Loss: 0.4877, Test Acc: 83.3167\n",
      "Epoch: 7\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4227 | Test Loss: 0.4722, Test Acc: 83.3766\n",
      "Epoch: 8\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4203 | Test Loss: 0.4713, Test Acc: 83.4565\n",
      "Epoch: 9\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4175 | Test Loss: 0.4628, Test Acc: 83.6462\n",
      "Train time is 103.211 seconds\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "torch.manual_seed(42)\n",
    "start_time = timer()\n",
    "epochs = 10\n",
    "for epoch in tqdm(range(epochs)):\n",
    "  print(f\"Epoch: {epoch}\\n----\")\n",
    "  train_loss = 0\n",
    "  for batch, (X,y) in enumerate(train_dataloader):\n",
    "    model_0.train()\n",
    "    y_pred  =model_0(X)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    train_loss += loss\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch%400 ==0:\n",
    "       print(f\"Looked at {batch*len(X)}/{len(train_dataloader.dataset)} samples.\")\n",
    "  train_loss /= len(train_dataloader )\n",
    "  test_loss, test_acc = 0,0\n",
    "  model_0.eval()\n",
    "  with torch.inference_mode():\n",
    "    for X, y in test_dataloader:\n",
    "      test_pred = model_0(X)\n",
    "      test_loss += loss_fn(test_pred, y)\n",
    "      \n",
    "      test_acc += accuracy_fn(y_true = y, y_pred  =test_pred.argmax(dim=1))\n",
    "    test_loss /= len(test_dataloader)\n",
    "    test_acc /= len(test_dataloader)\n",
    "  print(f\"\\nTrain Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "end_time = timer()\n",
    "total_train_time = print_train_time(start=start_time, end=end_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76d24cdb23e4276bef09bd848d8250f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV0',\n",
       " 'model_loss': 0.46279823780059814,\n",
       " 'model_acc': 83.64616613418531}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "def eval_model(model: torch.nn.Module, data_loader: torch.utils.data.DataLoader,loss_fn: torch.nn.Module, accuracy_fn):\n",
    "  '''returns a dictionary containing the results of model predicting on data loader'''\n",
    "  loss, acc =0,0\n",
    "  model.eval()\n",
    "  with torch.inference_mode():\n",
    "    for X,y in tqdm(data_loader):\n",
    "      y_pred = model(X)\n",
    "      loss += loss_fn(y_pred,y)\n",
    "      acc += accuracy_fn(y_true = y, y_pred = y_pred.argmax(dim=1))\n",
    "    loss /= len(data_loader)\n",
    "    acc  /= len(data_loader)\n",
    "  return {\"model_name\": model.__class__.__name__,\n",
    "          \"model_loss\": loss.item(),\n",
    "          \"model_acc\": acc}\n",
    "model_0_results = eval_model(model = model_0, data_loader = test_dataloader, loss_fn = loss_fn, accuracy_fn = accuracy_fn)\n",
    "model_0_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model with non linear layers\n",
    "class FashionMNISTModelV1(nn.Module):\n",
    "  def __init__(self, \n",
    "               input_shape:int,\n",
    "               hidden_units: int,\n",
    "               output_shape: int):\n",
    "    super().__init__()\n",
    "    self.layer_stack = nn.Sequential(\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "  def forward(self, x: torch.Tensor):\n",
    "    return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0273,  0.0296, -0.0084,  ..., -0.0142,  0.0093,  0.0135],\n",
       "        [-0.0188, -0.0354,  0.0187,  ..., -0.0106, -0.0001,  0.0115],\n",
       "        [-0.0008,  0.0017,  0.0045,  ..., -0.0127, -0.0188,  0.0059],\n",
       "        ...,\n",
       "        [-0.0116,  0.0273, -0.0344,  ...,  0.0176,  0.0283, -0.0011],\n",
       "        [-0.0230,  0.0257,  0.0291,  ..., -0.0187, -0.0087,  0.0001],\n",
       "        [ 0.0176, -0.0147,  0.0053,  ..., -0.0336, -0.0221,  0.0205]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model_1 = FashionMNISTModelV1(input_shape=784,\n",
    "                              hidden_units=10,\n",
    "                              output_shape=len(class_names))\n",
    "next(model_1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params = model_1.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.train()\n",
    "    for batch, (X,y) in enumerate(data_loader):\n",
    "      y_pred  =model(X)\n",
    "      loss = loss_fn(y_pred, y)\n",
    "      train_loss += loss\n",
    "      train_acc += accuracy_fn(y_true = y, \n",
    "                               y_pred = y_pred.argmax(dim=1))\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "    train_loss /= len(data_loader )\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train Loss:{train_loss:.5f} | Train Acc: {train_acc:.5f}%\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module,\n",
    "              data_loader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn):\n",
    "  model.eval()\n",
    "  test_loss, test_acc = 0,0\n",
    "  with torch.inference_mode():\n",
    "    for X, y in data_loader:\n",
    "      test_pred = model(X)\n",
    "      test_loss += loss_fn(test_pred, y)\n",
    "        \n",
    "      test_acc += accuracy_fn(y_true = y, y_pred  =test_pred.argmax(dim=1))\n",
    "    test_loss /= len(data_loader)\n",
    "    test_acc /= len(data_loader)\n",
    "  print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffac793210f6485aa2b2f2746ec28284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train Loss:1.09199 | Train Acc: 61.34333%\n",
      "Test Loss: 0.9564, Test Acc: 64.9960%\n",
      "Epoch: 1\n",
      "Train Loss:0.78101 | Train Acc: 71.92833%\n",
      "Test Loss: 0.7223, Test Acc: 73.9117%\n",
      "Epoch: 2\n",
      "Train Loss:0.67027 | Train Acc: 75.93667%\n",
      "Test Loss: 0.6850, Test Acc: 75.0200%\n",
      "Train time is 33.191 seconds\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "train_time_start = timer()\n",
    "epochs = 3\n",
    "for epoch in tqdm(range(epochs)):\n",
    "  print(f\"Epoch: {epoch}\")\n",
    "  train_step(\n",
    "    model = model_1, data_loader=train_dataloader, loss_fn = loss_fn, optimizer=optimizer, accuracy_fn=accuracy_fn\n",
    "  )\n",
    "  test_step(model =model_1, data_loader= test_dataloader, loss_fn= loss_fn, accuracy_fn= accuracy_fn)\n",
    "train_time_end = timer()\n",
    "total_train_time = print_train_time(start = train_time_start, end = train_time_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34995804eeea425581ffe94e39716460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_1_results = eval_model(model=model_1, data_loader=test_dataloader, loss_fn=loss_fn, accuracy_fn=accuracy_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV1',\n",
       " 'model_loss': 0.6850008964538574,\n",
       " 'model_acc': 75.01996805111821}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTModelV2(nn.Module):\n",
    "  '''Model architecture that replicates tinyVGG'''\n",
    "  def __init__(self, input_shape:int, hidden_units: int, output_shape: int):\n",
    "    super().__init__()\n",
    "    self.conv_block_1 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=input_shape,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride = 1,\n",
    "                padding = 1\n",
    "                ),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units,\n",
    "                kernel_size =3,\n",
    "                stride = 1,\n",
    "                padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size = 2)\n",
    "    )\n",
    "    self.conv_block_2 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units,kernel_size=3,stride = 1, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride = 1, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2)\n",
    "    )\n",
    "    self.classifier = nn.Sequential(\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(in_features=hidden_units*7*7,\n",
    "                out_features=output_shape)\n",
    "    )\n",
    "  def forward(self, x):\n",
    "    x =self.conv_block_1(x)\n",
    "    #print(x.shape)\n",
    "    x = self.conv_block_2(x)\n",
    "    #print(x.shape)\n",
    "    x = self.classifier(x)\n",
    "    #print(x.shape)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model_2 = FashionMNISTModelV2(input_shape=1,hidden_units=10,output_shape=len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_img_tensor = torch.randn(size = (1,28,28))\n",
    "rand_img_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-7.9311e-02,  1.6144e+00, -4.6171e-01, -5.7414e-01,  5.1842e-01,\n",
       "          -4.8354e-01,  1.3702e+00,  1.8823e-01, -6.3737e-01,  8.7616e-02,\n",
       "           1.1489e+00,  8.7162e-01,  2.0577e-01, -1.0062e+00,  1.1125e+00,\n",
       "          -7.4517e-01, -2.3947e-01,  7.5288e-01, -6.6769e-01,  5.5451e-01,\n",
       "           9.0538e-01,  1.7207e+00,  3.2258e-01,  5.4998e-01,  1.3368e+00,\n",
       "           9.1989e-01,  2.9305e-01,  7.0214e-01],\n",
       "         [-1.0596e+00, -2.2214e+00,  7.0677e-01, -2.1389e-01, -1.0270e+00,\n",
       "          -5.2316e-01,  1.4774e+00,  3.0483e-01, -6.4894e-01,  4.9036e-01,\n",
       "          -2.8043e-01,  9.4100e-01, -8.9237e-01, -3.5752e-01,  1.0479e-01,\n",
       "           4.1266e-02,  3.3505e-01, -2.4310e-01, -6.5055e-01, -3.3003e-01,\n",
       "          -3.1443e-01, -1.3658e+00,  3.5626e-02, -4.3072e-01, -9.8891e-01,\n",
       "          -1.0607e+00,  7.0623e-01, -2.2878e-01],\n",
       "         [ 7.1535e-01,  4.1778e-01,  3.6404e-01, -1.6342e+00,  5.9972e-01,\n",
       "          -3.3900e-01,  1.5490e-01, -2.7944e-01, -5.9674e-01,  2.4182e-02,\n",
       "           8.2635e-01,  1.0355e-01, -1.5869e-01,  1.6984e+00, -5.5956e-02,\n",
       "          -4.5470e-01, -4.8386e-01,  5.0997e-01, -1.6908e-01, -2.8621e-01,\n",
       "          -4.7618e-01,  1.1133e+00,  2.1901e+00,  3.5307e-01,  3.8706e-02,\n",
       "           6.6833e-01,  7.5911e-01,  3.1745e-01],\n",
       "         [-1.3778e+00,  1.1541e+00, -1.0930e+00, -8.7139e-01,  3.2765e-01,\n",
       "           1.3853e-01,  1.1921e+00, -3.0719e-01,  3.2675e-01, -9.5395e-02,\n",
       "          -1.8270e-01,  3.3828e-01, -1.7729e+00, -2.3087e-01,  5.7353e-01,\n",
       "          -8.1984e-01, -9.4873e-01, -2.8691e-01, -9.0246e-01, -1.5298e+00,\n",
       "          -2.7262e-01, -7.8116e-02,  3.0451e-01,  1.5553e+00, -1.5069e-01,\n",
       "          -2.1063e+00, -6.3016e-01,  1.2424e+00],\n",
       "         [-1.0116e-01, -5.3877e-01, -1.4040e+00,  6.1056e-01, -4.8852e-01,\n",
       "           7.1804e-01,  1.8486e+00, -2.4315e+00,  1.1788e+00, -2.2412e+00,\n",
       "           1.2707e+00, -1.3595e+00,  2.4941e-01,  5.3944e-01,  5.8983e-02,\n",
       "           2.8754e-01,  8.8116e-02, -1.0595e-02,  2.0317e+00,  3.4074e-01,\n",
       "           1.1845e+00,  1.3882e+00,  1.3713e-01, -8.4199e-01, -1.4412e+00,\n",
       "          -6.7775e-01,  5.9116e-01,  1.5989e+00],\n",
       "         [-1.3531e+00,  8.3320e-01, -1.3048e-01,  5.8364e-01, -1.0035e+00,\n",
       "           1.0835e+00,  2.0384e-01,  5.5035e-01, -1.5820e-01, -1.9969e-01,\n",
       "           4.6645e-01,  5.6034e-01,  7.2922e-01, -1.2451e+00,  1.4043e+00,\n",
       "          -3.0455e-01, -1.4661e+00, -3.2681e-01, -5.9296e-01,  8.6525e-01,\n",
       "          -1.8208e-02, -6.9522e-01, -6.3725e-01,  1.3755e+00,  5.5248e-01,\n",
       "           8.8571e-01, -1.3390e+00, -4.0027e-01],\n",
       "         [ 3.7823e-01, -9.8944e-01,  1.5292e+00,  9.4857e-01,  1.0798e+00,\n",
       "           2.6206e+00,  6.8642e-01,  1.5355e+00, -1.2886e+00,  6.9983e-01,\n",
       "          -1.6089e-01, -8.2809e-01,  1.8141e+00,  9.5141e-01, -1.2033e+00,\n",
       "          -5.1429e-01,  2.1783e+00,  1.4013e+00,  3.8764e-01,  8.8688e-01,\n",
       "          -1.4357e+00,  6.3409e-01, -5.4079e-01,  1.3265e+00, -2.8981e-01,\n",
       "          -8.8429e-01, -3.3879e-01,  7.6070e-01],\n",
       "         [-1.3467e+00,  6.5218e-01, -1.3508e+00,  2.1091e+00,  1.0489e+00,\n",
       "          -6.5886e-01,  7.8481e-01, -1.1543e+00,  3.3469e-01,  2.3107e-01,\n",
       "          -1.2114e+00, -1.2591e+00,  1.1152e+00,  6.0639e-01,  9.8586e-01,\n",
       "           1.4940e+00,  1.9783e+00,  3.8038e-01,  4.1839e-02,  2.8445e-01,\n",
       "          -3.8796e-01, -7.5004e-01,  6.0020e-01,  9.0811e-01,  1.1711e+00,\n",
       "          -8.9157e-01,  1.7047e+00, -1.7131e+00],\n",
       "         [-8.9742e-01, -8.2137e-01,  4.4577e-01,  9.5227e-01, -5.5234e-01,\n",
       "          -7.3259e-01,  5.0387e-01, -1.8186e-01,  5.5075e-01,  1.4681e-01,\n",
       "           1.9950e+00, -3.5538e-01,  4.6698e-01,  7.5128e-01, -3.8457e-01,\n",
       "          -6.6300e-02,  8.3199e-01, -6.3693e-01,  1.3496e-01,  4.8852e-02,\n",
       "          -1.1078e+00,  1.5005e+00,  5.2926e-01, -1.5583e+00,  5.2111e-01,\n",
       "           1.2260e+00,  2.8403e-01,  3.0900e+00],\n",
       "         [-8.7840e-01,  3.9075e-02,  3.5006e-02, -1.3603e+00, -1.1896e+00,\n",
       "           6.0244e-01, -6.9180e-01,  6.1055e-01,  2.7785e-01,  7.3420e-01,\n",
       "          -3.7356e-01, -3.9519e-01, -8.7802e-01,  1.0258e+00,  5.1349e-01,\n",
       "           7.2127e-01,  1.0249e+00, -6.9139e-01, -5.3251e-01, -2.0061e+00,\n",
       "           7.6148e-01, -1.8958e-01, -6.1491e-01, -4.6902e-01, -6.9639e-02,\n",
       "          -1.9187e+00, -1.1859e+00,  1.3960e+00],\n",
       "         [-7.4998e-01, -9.5122e-01,  1.1336e+00,  3.0468e-01,  1.1521e-02,\n",
       "          -3.6487e-01, -1.4563e-01,  1.1416e+00,  5.6293e-01, -1.3238e-01,\n",
       "           8.6988e-01, -7.6166e-01, -5.1871e-01,  8.0090e-01, -7.4484e-01,\n",
       "           1.9110e+00,  4.3963e-01,  1.9945e+00, -8.3347e-01,  2.4162e-01,\n",
       "           1.8362e+00, -4.7441e-01, -3.8593e-01,  3.6728e-01, -3.6168e-01,\n",
       "          -7.9803e-01,  1.1246e+00,  5.0134e-01],\n",
       "         [ 7.4502e-01,  1.4871e+00, -5.1455e-02,  2.5273e-01, -3.8512e-01,\n",
       "          -5.4549e-01,  1.2161e-01,  1.1134e-01, -4.3781e-01, -9.3683e-03,\n",
       "           2.5680e-01, -3.0753e-03,  1.9262e+00,  9.8983e-01,  7.9826e-01,\n",
       "           9.6311e-01,  7.2050e-01, -2.8325e-01,  9.3731e-02,  1.6574e+00,\n",
       "          -1.5055e-01,  2.1911e+00,  1.8251e-01,  1.4459e-01,  1.6274e+00,\n",
       "           1.4943e+00,  4.5169e-01,  6.8142e-01],\n",
       "         [-2.7034e-01, -2.3219e+00, -2.0621e+00,  6.0365e-01, -1.4820e-01,\n",
       "          -2.0676e-01, -4.1520e-01, -5.6131e-01, -1.8090e+00, -1.9060e+00,\n",
       "          -8.7443e-01,  1.7292e+00,  1.5932e+00,  8.2392e-01,  1.7495e-01,\n",
       "           3.7812e-01,  2.7788e-01,  8.9592e-01, -9.0071e-01, -5.3120e-01,\n",
       "           8.2710e-02,  3.8164e-01, -1.0024e+00, -2.2076e-01,  1.2380e+00,\n",
       "          -9.3480e-02,  6.0029e-01,  3.4585e-01],\n",
       "         [-1.6561e+00,  1.7567e-01,  8.8577e-01,  2.2398e-02,  5.2696e-01,\n",
       "           1.0364e+00,  5.2805e-01,  2.5790e-01, -2.3163e-01,  2.0548e+00,\n",
       "           4.3681e-01,  1.1093e+00, -1.1608e+00,  7.4833e-02, -1.9967e-01,\n",
       "          -1.3696e-01,  1.1638e+00, -8.7660e-01, -6.7370e-01, -6.5271e-01,\n",
       "           7.9882e-02, -5.4998e-01, -8.9937e-01,  5.2211e-01, -1.3242e+00,\n",
       "          -1.9728e-01,  2.9199e-01, -1.2133e+00],\n",
       "         [ 2.3239e+00, -1.2668e+00, -1.4738e+00, -5.0602e-01, -2.2938e-02,\n",
       "          -2.7809e+00, -8.4194e-01, -6.7214e-01, -3.2566e-02, -1.4618e+00,\n",
       "          -1.6406e-01, -9.0867e-01,  2.7789e-01,  3.9141e-01, -6.6960e-01,\n",
       "          -8.3025e-02, -2.3748e-01,  1.3108e+00,  6.0794e-01,  1.3435e+00,\n",
       "          -4.3808e-01, -1.3862e+00, -7.7125e-01, -3.1686e-01,  1.4500e+00,\n",
       "          -1.9820e-02, -2.9167e-02,  1.7699e+00],\n",
       "         [ 7.4439e-01, -1.7409e-01, -9.1780e-01, -2.1325e+00,  8.5168e-01,\n",
       "           1.5665e+00,  2.2803e+00, -3.1174e-01, -4.3286e-02,  1.0356e+00,\n",
       "           1.3417e+00, -1.1890e-01,  1.1489e+00,  2.4101e-01, -3.8728e-01,\n",
       "           7.1120e-01, -1.1070e+00,  1.0268e+00,  2.8653e-01, -1.0950e-01,\n",
       "          -4.3233e-01,  9.0922e-01,  3.7495e-01, -1.6454e-01, -2.2700e-02,\n",
       "           7.4911e-01, -1.1758e+00,  2.6725e-01],\n",
       "         [ 9.0308e-01, -8.7897e-01,  3.5524e-01, -4.6694e-01, -7.9778e-01,\n",
       "           1.0261e+00,  1.1465e+00,  8.7531e-03,  2.7468e+00, -3.2277e-01,\n",
       "           3.7913e-01, -2.3662e-01, -8.7216e-01,  1.8639e-01,  1.7569e+00,\n",
       "           1.2287e+00,  6.5599e-01,  6.4568e-01,  1.3101e+00, -2.2886e-01,\n",
       "           1.5612e+00, -5.4137e-01, -9.8579e-01, -6.8336e-01,  5.9688e-01,\n",
       "          -7.9719e-01, -8.7012e-01,  4.1262e-01],\n",
       "         [-6.3653e-01, -1.9996e-01, -2.1504e+00,  1.2741e-01,  4.7593e-01,\n",
       "          -5.7431e-01, -8.4836e-02,  1.2047e+00,  7.3054e-01,  2.2496e+00,\n",
       "           1.1137e-01, -2.8414e+00, -8.2265e-01, -6.6255e-01,  3.7517e-01,\n",
       "          -1.5977e+00, -1.5368e+00, -1.0531e+00,  6.7938e-02, -1.4703e+00,\n",
       "          -9.2387e-01, -1.1561e-01, -2.5698e+00,  1.8282e+00,  1.4328e-01,\n",
       "           1.6073e-01,  7.2218e-01, -1.8006e+00],\n",
       "         [-1.1940e+00, -5.4677e-02,  5.3031e-01,  3.6764e-02, -4.3221e-01,\n",
       "          -3.4771e-01,  9.7368e-01,  1.1764e+00, -2.1270e+00,  7.1570e-01,\n",
       "           1.1010e-01, -1.2989e+00, -1.4647e+00, -1.9571e+00,  1.0173e-01,\n",
       "          -3.4405e-01, -2.0067e+00, -4.7450e-01, -5.7338e-01, -1.1818e+00,\n",
       "           6.9315e-01,  1.2282e+00,  8.1225e-01, -1.3510e+00, -6.2128e-02,\n",
       "          -3.9983e-01, -5.8419e-01, -1.5906e+00],\n",
       "         [-8.8425e-02, -3.5751e-01, -1.7776e+00,  2.9816e-02,  2.2818e+00,\n",
       "           6.3594e-01,  5.8638e-02, -1.2594e+00, -1.2911e+00,  6.9719e-01,\n",
       "           5.5881e-01,  4.3986e-01, -6.0764e-01,  1.2469e+00,  1.7595e+00,\n",
       "           1.9139e+00, -3.7457e-01,  4.3008e-01, -6.1285e-01, -1.1323e+00,\n",
       "           8.0130e-02, -5.6896e-01, -9.8219e-01,  1.3032e+00, -3.0372e-01,\n",
       "          -1.5758e+00, -6.8768e-01,  8.2566e-02],\n",
       "         [ 4.7117e-01,  5.2938e-01, -4.0145e-02, -1.0268e+00, -3.4830e-01,\n",
       "          -3.3875e-01,  6.5079e-01,  2.1760e+00,  6.2526e-01, -1.9560e-01,\n",
       "           1.1907e-01, -5.4186e-01,  7.8255e-01, -1.3453e+00, -5.0752e-01,\n",
       "          -4.5030e-01, -5.7623e-01, -7.6363e-01, -2.9068e-01, -3.9835e-01,\n",
       "          -1.3938e+00,  8.4655e-01, -1.7191e+00,  5.3331e-01, -4.1483e-02,\n",
       "           1.7672e+00,  1.8622e+00, -1.7111e-01],\n",
       "         [ 6.9229e-01,  1.0485e+00, -1.5103e-01, -2.2977e+00, -2.6759e-01,\n",
       "          -1.5436e+00,  4.3679e-02,  1.9653e+00, -5.0734e-01, -6.9348e-01,\n",
       "           8.8805e-01, -1.5327e+00,  1.1756e+00,  9.9251e-01, -8.6223e-01,\n",
       "           7.6898e-01, -1.2935e+00, -5.7089e-01,  1.3834e+00,  6.2520e-01,\n",
       "          -4.7215e-01,  1.9148e+00, -2.5678e-01, -6.2261e-01,  5.1901e-01,\n",
       "           5.7094e-01,  1.6640e+00,  2.1912e+00],\n",
       "         [-1.3623e+00, -3.1455e-01,  1.9871e+00,  5.5510e-02,  3.3931e-01,\n",
       "           1.5300e+00,  2.6910e+00,  6.5812e-01,  8.5173e-01, -7.9921e-01,\n",
       "           1.2907e+00, -1.4698e+00, -4.6088e-01, -7.7026e-01, -1.3132e+00,\n",
       "          -5.0987e-02, -1.1506e+00, -1.1598e+00,  8.6636e-01, -1.1831e+00,\n",
       "          -4.6678e-02, -5.3465e-01,  1.6594e+00, -3.4037e-01, -2.0934e+00,\n",
       "           2.3202e-01,  2.0433e-01, -2.8004e-01],\n",
       "         [-2.6763e+00, -1.4162e+00,  1.3186e+00, -2.1153e-01, -1.0821e-01,\n",
       "          -1.9288e+00, -1.0776e+00,  5.7729e-02, -1.3966e+00,  1.8160e-01,\n",
       "          -2.0047e+00, -1.4949e+00,  6.5802e-01,  2.3591e+00, -1.6228e+00,\n",
       "           2.1309e+00, -7.1931e-01, -7.0995e-02, -7.3834e-01, -7.0517e-01,\n",
       "           8.0304e-01,  1.0928e+00, -2.2593e+00,  4.3819e-01, -1.1242e+00,\n",
       "           1.2278e+00,  2.9173e-02,  1.8709e+00],\n",
       "         [ 2.1658e+00, -9.4675e-02,  1.1324e+00, -8.9746e-01, -1.3276e-01,\n",
       "           1.8673e+00,  7.0729e-01, -1.7225e-01,  5.1121e-02, -5.1556e-01,\n",
       "          -7.1416e-01,  7.8066e-01,  1.7730e-01,  9.3133e-01, -1.1519e+00,\n",
       "           4.2236e-01, -7.7286e-01,  5.9300e-01, -1.9722e+00,  9.8274e-02,\n",
       "           3.5185e-01,  1.3421e+00,  1.0195e+00, -1.0780e+00,  1.8059e-01,\n",
       "           1.4115e+00, -1.2840e+00,  1.6185e+00],\n",
       "         [-1.3939e+00,  1.9779e+00,  6.5874e-01,  7.4859e-01, -1.5970e+00,\n",
       "           3.9493e-01,  7.7917e-01, -8.1259e-01, -4.4622e-01,  1.1844e+00,\n",
       "          -1.6756e+00, -6.3713e-01,  1.2459e+00,  3.1614e-01,  4.7528e-01,\n",
       "           7.6048e-01,  6.7942e-01,  1.1236e+00, -1.6474e+00,  1.5934e+00,\n",
       "          -9.1132e-01, -7.2998e-01,  5.7815e-01, -8.3520e-01, -1.6799e+00,\n",
       "          -1.8157e-01,  1.0120e-01, -4.2478e-01],\n",
       "         [ 1.1139e+00,  3.9286e-02, -9.3781e-01, -4.0317e-01, -6.8518e-01,\n",
       "          -2.3737e-01,  8.4334e-01,  1.2986e+00, -1.3211e+00,  1.1308e+00,\n",
       "          -2.4632e-01, -6.1183e-01, -2.5458e+00, -2.6585e-01, -2.3986e-01,\n",
       "           6.5792e-01, -9.7218e-01,  6.4865e-01,  1.8544e+00, -8.7844e-01,\n",
       "          -7.1559e-01, -1.7704e+00,  9.1369e-01, -3.5753e-01, -1.0355e-01,\n",
       "           3.8849e-01,  1.3942e+00, -1.0104e+00],\n",
       "         [ 9.2978e-01, -6.5083e-01, -5.5883e-01, -1.1416e+00, -7.0653e-01,\n",
       "          -6.3873e-01, -1.2861e+00,  1.1223e-01, -1.0935e+00, -7.9730e-01,\n",
       "          -6.5264e-02, -6.7834e-02,  4.0721e-01,  1.2035e+00, -9.9266e-01,\n",
       "          -1.4999e+00, -1.0396e+00, -7.0431e-02,  1.0616e+00, -4.6982e-01,\n",
       "          -1.0189e+00, -7.8133e-01, -5.4789e-01,  1.0941e+00,  1.4848e-01,\n",
       "          -7.0568e-01,  9.7262e-01,  5.2513e-01]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0366, -0.0940,  0.0686, -0.0485,  0.0068,  0.0290,  0.0132,  0.0084,\n",
       "         -0.0030, -0.0185]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2(rand_img_tensor.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params = model_2.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv_block_1.0.weight',\n",
       "              tensor([[[[ 0.2548,  0.2767, -0.0781],\n",
       "                        [ 0.3062, -0.0730,  0.0673],\n",
       "                        [-0.1623,  0.1958,  0.2938]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2445,  0.2897,  0.0624],\n",
       "                        [ 0.2463,  0.0451,  0.1607],\n",
       "                        [-0.0471,  0.2570,  0.0493]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1556,  0.0850, -0.1536],\n",
       "                        [-0.0391, -0.1354,  0.2211],\n",
       "                        [-0.2631, -0.1537, -0.0941]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2004,  0.0315, -0.3292],\n",
       "                        [ 0.3010, -0.2832,  0.2573],\n",
       "                        [ 0.0555, -0.1082,  0.2060]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0520,  0.2693,  0.0364],\n",
       "                        [-0.1051,  0.0896, -0.0904],\n",
       "                        [ 0.1403,  0.2976,  0.1927]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1457,  0.1924,  0.0596],\n",
       "                        [ 0.1693, -0.2032, -0.3300],\n",
       "                        [-0.1288, -0.2557,  0.2735]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0960,  0.1381,  0.1054],\n",
       "                        [-0.0058,  0.2609, -0.2368],\n",
       "                        [ 0.0210, -0.2275,  0.1028]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1148,  0.1021, -0.0694],\n",
       "                        [ 0.2765, -0.1976, -0.1988],\n",
       "                        [-0.1988,  0.2998,  0.1111]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3208, -0.2751, -0.3306],\n",
       "                        [-0.2608, -0.2242,  0.1350],\n",
       "                        [ 0.1194,  0.2770, -0.1721]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2272,  0.1769, -0.1347],\n",
       "                        [ 0.2023, -0.0791,  0.1907],\n",
       "                        [-0.2590, -0.1682,  0.1016]]]])),\n",
       "             ('conv_block_1.0.bias',\n",
       "              tensor([ 0.0705, -0.0850,  0.1987,  0.2266, -0.2417, -0.1780,  0.3052, -0.1125,\n",
       "                      -0.1182, -0.3225])),\n",
       "             ('conv_block_1.2.weight',\n",
       "              tensor([[[[-0.0604,  0.0263, -0.0139],\n",
       "                        [-0.0765,  0.0025, -0.0720],\n",
       "                        [-0.0894, -0.0580, -0.0923]],\n",
       "              \n",
       "                       [[-0.0671,  0.1054,  0.0199],\n",
       "                        [ 0.0325, -0.0983, -0.0692],\n",
       "                        [-0.0351,  0.0165, -0.0928]],\n",
       "              \n",
       "                       [[-0.0454, -0.0631,  0.0003],\n",
       "                        [-0.0392, -0.0073, -0.0714],\n",
       "                        [-0.0724, -0.0615, -0.0361]],\n",
       "              \n",
       "                       [[-0.0832,  0.0884, -0.0209],\n",
       "                        [ 0.0907,  0.0328, -0.0893],\n",
       "                        [ 0.0729, -0.0290, -0.0404]],\n",
       "              \n",
       "                       [[-0.0875, -0.1048,  0.0302],\n",
       "                        [-0.0230,  0.0410, -0.0865],\n",
       "                        [ 0.0783, -0.0774, -0.0182]],\n",
       "              \n",
       "                       [[ 0.0220,  0.0544,  0.0851],\n",
       "                        [ 0.0960, -0.0836,  0.0265],\n",
       "                        [-0.0453, -0.0116, -0.0789]],\n",
       "              \n",
       "                       [[ 0.0960, -0.0774,  0.0563],\n",
       "                        [ 0.0370,  0.0343, -0.0570],\n",
       "                        [ 0.0958,  0.0232,  0.0136]],\n",
       "              \n",
       "                       [[-0.0929,  0.0442, -0.0158],\n",
       "                        [-0.0483,  0.0905,  0.0235],\n",
       "                        [-0.0583, -0.0534, -0.0050]],\n",
       "              \n",
       "                       [[ 0.0589, -0.0269, -0.0601],\n",
       "                        [-0.0361, -0.0787,  0.0376],\n",
       "                        [ 0.0816, -0.0992,  0.0245]],\n",
       "              \n",
       "                       [[ 0.0545,  0.0191, -0.0375],\n",
       "                        [ 0.0550,  0.0554,  0.0394],\n",
       "                        [-0.0185, -0.0279,  0.0113]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0186, -0.0314,  0.0674],\n",
       "                        [ 0.0906, -0.0104, -0.0236],\n",
       "                        [ 0.0015, -0.0063,  0.0253]],\n",
       "              \n",
       "                       [[ 0.0295, -0.0957, -0.0389],\n",
       "                        [ 0.0888,  0.0411, -0.0052],\n",
       "                        [-0.0636, -0.0645, -0.0944]],\n",
       "              \n",
       "                       [[-0.0344,  0.0356,  0.0672],\n",
       "                        [ 0.0487, -0.0932, -0.0634],\n",
       "                        [-0.0166,  0.1020,  0.0152]],\n",
       "              \n",
       "                       [[-0.0273,  0.0436, -0.0401],\n",
       "                        [-0.0682,  0.0769, -0.0479],\n",
       "                        [-0.0211, -0.1049,  0.0705]],\n",
       "              \n",
       "                       [[ 0.0799,  0.0384, -0.0735],\n",
       "                        [-0.1040, -0.0856,  0.0786],\n",
       "                        [ 0.0506,  0.0887,  0.0552]],\n",
       "              \n",
       "                       [[ 0.0267, -0.0010, -0.0802],\n",
       "                        [-0.0903, -0.0986,  0.0432],\n",
       "                        [-0.0518, -0.0212, -0.0607]],\n",
       "              \n",
       "                       [[-0.0192, -0.0742, -0.0689],\n",
       "                        [ 0.0350, -0.0313,  0.0651],\n",
       "                        [-0.0338, -0.0773, -0.0186]],\n",
       "              \n",
       "                       [[-0.0511, -0.0322, -0.1003],\n",
       "                        [ 0.0590, -0.0734,  0.0530],\n",
       "                        [ 0.0478,  0.0753, -0.0809]],\n",
       "              \n",
       "                       [[ 0.0758, -0.0498,  0.0391],\n",
       "                        [ 0.0990, -0.0149, -0.0008],\n",
       "                        [-0.0243, -0.0880,  0.0506]],\n",
       "              \n",
       "                       [[-0.1046,  0.0654,  0.0789],\n",
       "                        [ 0.0997, -0.0249, -0.0866],\n",
       "                        [ 0.0237,  0.0582, -0.1049]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0239, -0.0632, -0.0092],\n",
       "                        [-0.0519, -0.0431, -0.0335],\n",
       "                        [-0.1002,  0.0865,  0.0884]],\n",
       "              \n",
       "                       [[-0.0165, -0.0120, -0.0430],\n",
       "                        [-0.0952, -0.1026,  0.0392],\n",
       "                        [-0.0579, -0.0678, -0.0082]],\n",
       "              \n",
       "                       [[-0.0351, -0.0341,  0.0034],\n",
       "                        [-0.0224, -0.0363, -0.0505],\n",
       "                        [-0.0858,  0.0884, -0.0422]],\n",
       "              \n",
       "                       [[ 0.0279, -0.0366,  0.0086],\n",
       "                        [ 0.0983,  0.0486, -0.0913],\n",
       "                        [ 0.0418,  0.1001,  0.0277]],\n",
       "              \n",
       "                       [[ 0.0707,  0.1039, -0.0162],\n",
       "                        [ 0.0219, -0.0733, -0.0217],\n",
       "                        [ 0.0781,  0.0540, -0.0667]],\n",
       "              \n",
       "                       [[-0.0845, -0.0720, -0.1040],\n",
       "                        [-0.0813, -0.0261,  0.0711],\n",
       "                        [ 0.0176, -0.0802, -0.0846]],\n",
       "              \n",
       "                       [[ 0.0524, -0.0784, -0.0130],\n",
       "                        [ 0.0506, -0.0488, -0.0115],\n",
       "                        [-0.0092, -0.0249, -0.0534]],\n",
       "              \n",
       "                       [[-0.0940, -0.0852, -0.0564],\n",
       "                        [ 0.1018, -0.0509, -0.0708],\n",
       "                        [ 0.0256,  0.0291,  0.0578]],\n",
       "              \n",
       "                       [[ 0.0801,  0.0587, -0.1045],\n",
       "                        [ 0.0093,  0.0639, -0.0097],\n",
       "                        [-0.0621,  0.1005, -0.0394]],\n",
       "              \n",
       "                       [[-0.0600, -0.0950,  0.0047],\n",
       "                        [ 0.0467,  0.0233,  0.0208],\n",
       "                        [-0.0799, -0.0984,  0.0019]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0961,  0.0608, -0.0614],\n",
       "                        [-0.0137, -0.0777, -0.0509],\n",
       "                        [ 0.0191,  0.0574,  0.0873]],\n",
       "              \n",
       "                       [[-0.0968,  0.0705, -0.0743],\n",
       "                        [ 0.0395,  0.0892,  0.0015],\n",
       "                        [ 0.0959, -0.0898, -0.0403]],\n",
       "              \n",
       "                       [[ 0.0615, -0.0230, -0.0216],\n",
       "                        [-0.0439,  0.0727,  0.0517],\n",
       "                        [ 0.0338, -0.0592, -0.0856]],\n",
       "              \n",
       "                       [[ 0.0114,  0.0312, -0.0487],\n",
       "                        [-0.0295,  0.0712,  0.0084],\n",
       "                        [ 0.0048, -0.0259, -0.0955]],\n",
       "              \n",
       "                       [[-0.0991, -0.0504, -0.0536],\n",
       "                        [ 0.0328, -0.0307, -0.0412],\n",
       "                        [ 0.1005,  0.0367,  0.0751]],\n",
       "              \n",
       "                       [[-0.0510, -0.0431,  0.0387],\n",
       "                        [-0.0702, -0.0689, -0.0051],\n",
       "                        [-0.0386, -0.0790,  0.0625]],\n",
       "              \n",
       "                       [[ 0.0848,  0.0171, -0.0184],\n",
       "                        [-0.0976, -0.0384,  0.0268],\n",
       "                        [ 0.0497, -0.0133, -0.0417]],\n",
       "              \n",
       "                       [[ 0.0587, -0.0839,  0.0666],\n",
       "                        [-0.0409,  0.0016, -0.0208],\n",
       "                        [ 0.0128, -0.0319,  0.0766]],\n",
       "              \n",
       "                       [[-0.0027,  0.0823,  0.1013],\n",
       "                        [-0.0514, -0.0769,  0.0846],\n",
       "                        [ 0.0826, -0.0805, -0.0081]],\n",
       "              \n",
       "                       [[-0.1039, -0.0863,  0.0204],\n",
       "                        [ 0.0280,  0.0223, -0.0287],\n",
       "                        [ 0.0972,  0.0151, -0.0622]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0060,  0.0253,  0.0369],\n",
       "                        [-0.0745,  0.0395, -0.0539],\n",
       "                        [-0.0876, -0.0576,  0.1017]],\n",
       "              \n",
       "                       [[ 0.0901,  0.0944,  0.0619],\n",
       "                        [ 0.0796, -0.0141, -0.0580],\n",
       "                        [ 0.0527, -0.0546, -0.0711]],\n",
       "              \n",
       "                       [[-0.0337,  0.0221,  0.0543],\n",
       "                        [-0.0409, -0.0620,  0.0142],\n",
       "                        [-0.0621, -0.0686,  0.0549]],\n",
       "              \n",
       "                       [[-0.0177,  0.0963,  0.1025],\n",
       "                        [ 0.0315,  0.0363,  0.0243],\n",
       "                        [ 0.0017, -0.0077,  0.0014]],\n",
       "              \n",
       "                       [[ 0.0394,  0.0980, -0.0273],\n",
       "                        [-0.0446, -0.0255, -0.0509],\n",
       "                        [ 0.0179,  0.0787,  0.0824]],\n",
       "              \n",
       "                       [[ 0.0484, -0.0776, -0.0566],\n",
       "                        [-0.0232, -0.0194,  0.0087],\n",
       "                        [-0.0968,  0.0328, -0.0804]],\n",
       "              \n",
       "                       [[-0.0667, -0.0876,  0.0918],\n",
       "                        [-0.0998,  0.0795, -0.0035],\n",
       "                        [-0.0123,  0.0659, -0.0097]],\n",
       "              \n",
       "                       [[ 0.0661,  0.0762, -0.0915],\n",
       "                        [ 0.0406,  0.0199,  0.0227],\n",
       "                        [ 0.0154,  0.0288, -0.0507]],\n",
       "              \n",
       "                       [[-0.0135,  0.1002,  0.0708],\n",
       "                        [-0.0040, -0.0991,  0.0046],\n",
       "                        [-0.0718,  0.0857, -0.0640]],\n",
       "              \n",
       "                       [[-0.0076, -0.0234,  0.0188],\n",
       "                        [ 0.0992,  0.0100,  0.0610],\n",
       "                        [ 0.0818,  0.0851, -0.0364]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0236,  0.0508, -0.0288],\n",
       "                        [ 0.0494, -0.0230, -0.0715],\n",
       "                        [ 0.0429,  0.0162,  0.0470]],\n",
       "              \n",
       "                       [[ 0.1047,  0.0720,  0.0999],\n",
       "                        [ 0.0056, -0.0907, -0.0739],\n",
       "                        [-0.0655, -0.0929, -0.0528]],\n",
       "              \n",
       "                       [[-0.0970, -0.0973, -0.0630],\n",
       "                        [-0.1039, -0.0647,  0.0402],\n",
       "                        [ 0.0879, -0.0314, -0.0307]],\n",
       "              \n",
       "                       [[ 0.0563, -0.0520, -0.0498],\n",
       "                        [ 0.0649, -0.0918,  0.0129],\n",
       "                        [ 0.0931,  0.0181,  0.0287]],\n",
       "              \n",
       "                       [[-0.0614, -0.0015,  0.0058],\n",
       "                        [ 0.0259,  0.0410,  0.0916],\n",
       "                        [-0.0805,  0.0032, -0.0527]],\n",
       "              \n",
       "                       [[-0.0834, -0.0084, -0.0928],\n",
       "                        [ 0.0736,  0.0122, -0.0568],\n",
       "                        [ 0.0551, -0.0998, -0.0408]],\n",
       "              \n",
       "                       [[-0.0205, -0.0896, -0.0670],\n",
       "                        [-0.0172,  0.0800,  0.1018],\n",
       "                        [ 0.0671, -0.0629, -0.0690]],\n",
       "              \n",
       "                       [[ 0.0920,  0.0373,  0.0028],\n",
       "                        [ 0.0143, -0.0847, -0.0352],\n",
       "                        [ 0.1015, -0.0260, -0.0053]],\n",
       "              \n",
       "                       [[-0.0875, -0.0590, -0.0022],\n",
       "                        [-0.0655, -0.0131,  0.0429],\n",
       "                        [-0.1031,  0.0313, -0.0697]],\n",
       "              \n",
       "                       [[-0.0514,  0.0405,  0.0838],\n",
       "                        [-0.0288, -0.0433, -0.0953],\n",
       "                        [-0.0544, -0.0923, -0.0241]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0215, -0.0988,  0.0920],\n",
       "                        [ 0.0661, -0.1032, -0.0503],\n",
       "                        [ 0.0344, -0.0217, -0.0115]],\n",
       "              \n",
       "                       [[-0.0476,  0.0847, -0.0589],\n",
       "                        [ 0.0874,  0.0068,  0.0212],\n",
       "                        [ 0.0822, -0.0174, -0.0600]],\n",
       "              \n",
       "                       [[-0.0170,  0.0855, -0.0782],\n",
       "                        [ 0.0239, -0.1036,  0.0553],\n",
       "                        [ 0.0389,  0.0045,  0.0452]],\n",
       "              \n",
       "                       [[ 0.0001,  0.0583, -0.0834],\n",
       "                        [-0.0155,  0.0468,  0.1050],\n",
       "                        [ 0.0537, -0.0767,  0.0811]],\n",
       "              \n",
       "                       [[-0.0235, -0.0225, -0.0958],\n",
       "                        [-0.0166,  0.0746,  0.0147],\n",
       "                        [-0.0614,  0.0324, -0.0338]],\n",
       "              \n",
       "                       [[ 0.0962, -0.0915, -0.0333],\n",
       "                        [-0.1018, -0.0415,  0.0332],\n",
       "                        [ 0.1015,  0.0177,  0.1033]],\n",
       "              \n",
       "                       [[ 0.0206,  0.0609,  0.0845],\n",
       "                        [ 0.0881, -0.0590,  0.0969],\n",
       "                        [ 0.0639, -0.0493, -0.0503]],\n",
       "              \n",
       "                       [[-0.0884,  0.0265, -0.0854],\n",
       "                        [ 0.0445,  0.0333, -0.0916],\n",
       "                        [ 0.0287, -0.0086,  0.0482]],\n",
       "              \n",
       "                       [[ 0.0605, -0.1048,  0.0967],\n",
       "                        [ 0.0884,  0.0419, -0.0963],\n",
       "                        [-0.0377, -0.0305, -0.0271]],\n",
       "              \n",
       "                       [[ 0.0594,  0.0383,  0.0835],\n",
       "                        [-0.0395,  0.0355,  0.0375],\n",
       "                        [-0.0878, -0.1022, -0.0547]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0722, -0.0992, -0.0918],\n",
       "                        [ 0.0591,  0.0569,  0.0867],\n",
       "                        [-0.0796, -0.0771,  0.0541]],\n",
       "              \n",
       "                       [[ 0.0917,  0.0631,  0.0165],\n",
       "                        [ 0.0347,  0.1000, -0.0680],\n",
       "                        [-0.0479,  0.0737, -0.0721]],\n",
       "              \n",
       "                       [[-0.0581,  0.0769,  0.0333],\n",
       "                        [ 0.0341, -0.0447, -0.0015],\n",
       "                        [ 0.0965, -0.0633,  0.0008]],\n",
       "              \n",
       "                       [[ 0.0501, -0.0728,  0.1024],\n",
       "                        [-0.0527, -0.0253, -0.0285],\n",
       "                        [-0.0687, -0.1034,  0.0594]],\n",
       "              \n",
       "                       [[ 0.0280, -0.0987, -0.0678],\n",
       "                        [ 0.1042,  0.0403,  0.0423],\n",
       "                        [-0.0631, -0.0462, -0.0159]],\n",
       "              \n",
       "                       [[-0.0193, -0.0722,  0.0087],\n",
       "                        [ 0.0105, -0.0133,  0.0146],\n",
       "                        [-0.0418,  0.0274,  0.0398]],\n",
       "              \n",
       "                       [[-0.0555, -0.1045,  0.0552],\n",
       "                        [ 0.0251, -0.0536,  0.1016],\n",
       "                        [-0.0477,  0.0712,  0.0535]],\n",
       "              \n",
       "                       [[-0.0884,  0.0680, -0.0969],\n",
       "                        [-0.0584, -0.0176, -0.0711],\n",
       "                        [ 0.1030, -0.0211,  0.0419]],\n",
       "              \n",
       "                       [[-0.0941,  0.0607, -0.0328],\n",
       "                        [-0.0802,  0.0154,  0.0511],\n",
       "                        [ 0.0912, -0.0644, -0.0519]],\n",
       "              \n",
       "                       [[ 0.0203,  0.0286,  0.0405],\n",
       "                        [ 0.0579, -0.0239,  0.0586],\n",
       "                        [ 0.0777, -0.0275,  0.0750]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0515,  0.0930, -0.0599],\n",
       "                        [-0.0521, -0.0305,  0.0053],\n",
       "                        [ 0.0633, -0.0602,  0.0528]],\n",
       "              \n",
       "                       [[-0.0378,  0.0637, -0.0050],\n",
       "                        [-0.0923, -0.0580, -0.0763],\n",
       "                        [ 0.0523, -0.0707, -0.0088]],\n",
       "              \n",
       "                       [[ 0.0227, -0.0578,  0.0304],\n",
       "                        [-0.1029, -0.0754, -0.0955],\n",
       "                        [-0.0319, -0.0384,  0.0151]],\n",
       "              \n",
       "                       [[-0.0195,  0.0496,  0.0966],\n",
       "                        [ 0.0378, -0.0415, -0.0987],\n",
       "                        [ 0.0382, -0.0522,  0.0536]],\n",
       "              \n",
       "                       [[ 0.0705,  0.0407,  0.0989],\n",
       "                        [ 0.1001,  0.0223, -0.0768],\n",
       "                        [ 0.0942, -0.0500, -0.0498]],\n",
       "              \n",
       "                       [[ 0.0882,  0.0817,  0.0318],\n",
       "                        [ 0.0066, -0.0887, -0.0109],\n",
       "                        [ 0.1011,  0.0268,  0.0090]],\n",
       "              \n",
       "                       [[-0.0219, -0.0368,  0.0628],\n",
       "                        [ 0.0065,  0.0686, -0.0187],\n",
       "                        [ 0.0461,  0.0435,  0.0168]],\n",
       "              \n",
       "                       [[ 0.0662,  0.0661,  0.0977],\n",
       "                        [ 0.0810, -0.0270, -0.0892],\n",
       "                        [ 0.0193, -0.0009, -0.0275]],\n",
       "              \n",
       "                       [[-0.0177,  0.0050,  0.0769],\n",
       "                        [ 0.0329, -0.0374, -0.0433],\n",
       "                        [-0.0261, -0.0407,  0.0948]],\n",
       "              \n",
       "                       [[ 0.0558,  0.0952,  0.0003],\n",
       "                        [ 0.0213,  0.0366, -0.0998],\n",
       "                        [ 0.0094, -0.0071, -0.0591]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0818,  0.0933,  0.0857],\n",
       "                        [ 0.0489,  0.1006, -0.0428],\n",
       "                        [-0.0182,  0.0399, -0.0174]],\n",
       "              \n",
       "                       [[-0.0207, -0.0871,  0.0283],\n",
       "                        [-0.0637,  0.0038,  0.1028],\n",
       "                        [-0.0324, -0.0332,  0.0636]],\n",
       "              \n",
       "                       [[-0.0388, -0.0091,  0.0984],\n",
       "                        [-0.0432, -0.0754, -0.0590],\n",
       "                        [-0.0292, -0.0500, -0.0547]],\n",
       "              \n",
       "                       [[ 0.0426,  0.0179, -0.0337],\n",
       "                        [-0.0819, -0.0332, -0.0445],\n",
       "                        [-0.0343, -0.0951,  0.0227]],\n",
       "              \n",
       "                       [[-0.0774, -0.0821, -0.0861],\n",
       "                        [ 0.0440, -0.0635, -0.0435],\n",
       "                        [ 0.0826,  0.0560,  0.0604]],\n",
       "              \n",
       "                       [[-0.1001, -0.0756, -0.0398],\n",
       "                        [ 0.0871,  0.0108, -0.0788],\n",
       "                        [ 0.0007, -0.0819, -0.0231]],\n",
       "              \n",
       "                       [[-0.0290,  0.0912,  0.0326],\n",
       "                        [-0.0184,  0.0178, -0.0304],\n",
       "                        [ 0.0414,  0.0417,  0.0283]],\n",
       "              \n",
       "                       [[-0.0411,  0.0899, -0.0152],\n",
       "                        [-0.0410,  0.0660,  0.0859],\n",
       "                        [ 0.1049,  0.0312, -0.0359]],\n",
       "              \n",
       "                       [[ 0.0535,  0.0904, -0.1034],\n",
       "                        [-0.0131, -0.0719,  0.0196],\n",
       "                        [ 0.0436, -0.0218, -0.0088]],\n",
       "              \n",
       "                       [[ 0.0474, -0.0177, -0.0885],\n",
       "                        [ 0.0843, -0.0531, -0.0116],\n",
       "                        [ 0.0099, -0.0063, -0.0992]]]])),\n",
       "             ('conv_block_1.2.bias',\n",
       "              tensor([ 0.0484, -0.0479, -0.0547,  0.0252, -0.0550, -0.0487, -0.0355, -0.0396,\n",
       "                      -0.0440, -0.0284])),\n",
       "             ('conv_block_2.0.weight',\n",
       "              tensor([[[[ 2.7393e-02, -8.5299e-02, -6.3802e-02],\n",
       "                        [ 1.5381e-03,  1.4659e-02,  5.8217e-02],\n",
       "                        [-7.4044e-02,  3.3646e-02,  5.9914e-02]],\n",
       "              \n",
       "                       [[ 5.8530e-02, -9.8180e-02, -4.0225e-02],\n",
       "                        [-9.0606e-02, -6.6704e-02,  5.8711e-02],\n",
       "                        [-1.5740e-02,  4.4769e-02, -6.1876e-02]],\n",
       "              \n",
       "                       [[ 1.6018e-02, -6.3758e-02,  5.2693e-02],\n",
       "                        [-4.6104e-02, -2.6432e-02, -9.1456e-02],\n",
       "                        [ 3.4823e-04,  1.0008e-01,  5.1163e-02]],\n",
       "              \n",
       "                       [[-5.6240e-02,  1.4176e-03, -1.1558e-02],\n",
       "                        [-8.4862e-02,  8.2650e-02,  1.6993e-03],\n",
       "                        [ 2.2199e-02, -4.2567e-02, -4.9323e-02]],\n",
       "              \n",
       "                       [[ 1.7381e-02,  3.8971e-02,  2.3643e-02],\n",
       "                        [-5.0801e-02,  1.0234e-01, -1.5517e-02],\n",
       "                        [-6.4554e-02, -4.9301e-02,  1.0377e-01]],\n",
       "              \n",
       "                       [[ 5.0738e-06, -1.4309e-02, -4.3867e-02],\n",
       "                        [-2.7633e-02, -8.8779e-02, -8.3767e-02],\n",
       "                        [ 6.1695e-02,  9.0172e-02,  1.0059e-01]],\n",
       "              \n",
       "                       [[-7.6099e-02,  5.7012e-02, -6.5245e-02],\n",
       "                        [ 6.2883e-02,  7.6058e-02,  8.1573e-02],\n",
       "                        [ 7.5900e-02,  6.5941e-02,  2.0517e-03]],\n",
       "              \n",
       "                       [[ 4.8434e-02, -3.7712e-02,  4.5899e-02],\n",
       "                        [-3.3879e-02, -1.7700e-03, -9.1746e-02],\n",
       "                        [-2.7562e-02, -5.5432e-02, -3.5557e-02]],\n",
       "              \n",
       "                       [[-6.7313e-02, -9.4810e-02,  6.8639e-03],\n",
       "                        [ 6.8408e-02,  9.6001e-02,  6.1512e-02],\n",
       "                        [-5.4638e-02, -1.0425e-01,  3.9983e-02]],\n",
       "              \n",
       "                       [[ 5.9062e-02, -9.0495e-02,  3.7798e-02],\n",
       "                        [ 8.9121e-02,  6.3853e-03, -6.3505e-02],\n",
       "                        [ 8.6423e-02,  4.5011e-02,  6.9802e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.1287e-02,  6.1342e-02, -7.2002e-02],\n",
       "                        [ 1.0430e-01, -4.4662e-02,  6.3516e-02],\n",
       "                        [ 2.1107e-02,  2.7935e-02, -1.6165e-02]],\n",
       "              \n",
       "                       [[ 4.3295e-02, -4.3932e-02, -9.9357e-02],\n",
       "                        [-4.0499e-02,  8.2592e-02, -2.7751e-02],\n",
       "                        [ 3.3132e-02, -3.8973e-02,  7.9073e-02]],\n",
       "              \n",
       "                       [[ 6.3086e-02,  3.7211e-02, -5.3881e-02],\n",
       "                        [-8.6133e-02,  3.9686e-03, -6.1839e-02],\n",
       "                        [ 8.6667e-02, -1.0130e-01,  4.7104e-02]],\n",
       "              \n",
       "                       [[ 1.0508e-01,  5.2792e-02,  3.5942e-02],\n",
       "                        [-1.0142e-01,  1.0139e-01, -1.8030e-02],\n",
       "                        [-9.8495e-02,  1.0406e-01, -4.2894e-02]],\n",
       "              \n",
       "                       [[-7.4575e-03,  9.6479e-02, -7.3070e-02],\n",
       "                        [-7.4576e-02,  1.7141e-02, -1.4109e-02],\n",
       "                        [ 2.4280e-02, -8.8407e-02,  3.1524e-03]],\n",
       "              \n",
       "                       [[-4.6882e-02, -5.1820e-02, -9.6517e-02],\n",
       "                        [ 5.5890e-02,  2.0306e-02, -8.9118e-02],\n",
       "                        [ 8.3648e-02,  3.1794e-02,  1.9560e-02]],\n",
       "              \n",
       "                       [[-6.1890e-02,  1.5896e-02,  1.0157e-01],\n",
       "                        [ 7.2299e-02, -8.2100e-02,  9.6220e-02],\n",
       "                        [ 8.1702e-03,  5.0698e-02,  8.1869e-02]],\n",
       "              \n",
       "                       [[ 8.9862e-02, -8.2170e-02,  9.2303e-02],\n",
       "                        [-7.1591e-02,  7.9021e-03, -7.3656e-02],\n",
       "                        [-2.3109e-02, -4.7901e-03, -1.2611e-02]],\n",
       "              \n",
       "                       [[-1.6652e-02,  8.3137e-03,  1.0398e-01],\n",
       "                        [ 6.1244e-02,  5.8973e-02,  4.2190e-02],\n",
       "                        [ 8.1606e-02, -4.8645e-03,  8.3813e-03]],\n",
       "              \n",
       "                       [[ 2.1693e-02, -9.1931e-02, -8.4913e-02],\n",
       "                        [ 1.2923e-02, -4.1241e-02, -1.9342e-03],\n",
       "                        [-2.4187e-02,  1.6408e-02,  6.8581e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4958e-02,  8.4418e-02,  8.3227e-02],\n",
       "                        [-8.0901e-02, -8.1400e-02, -8.5284e-02],\n",
       "                        [-5.7766e-02, -4.1033e-02, -7.9341e-03]],\n",
       "              \n",
       "                       [[-2.5635e-02, -5.3258e-02, -3.3488e-02],\n",
       "                        [-3.8131e-02,  1.0341e-01, -3.9068e-02],\n",
       "                        [-7.5473e-02,  4.3818e-02, -6.0886e-03]],\n",
       "              \n",
       "                       [[ 8.0698e-02,  6.5863e-02,  9.6843e-02],\n",
       "                        [-7.7197e-02,  6.7764e-02,  8.8464e-02],\n",
       "                        [-5.2054e-02,  9.6890e-02,  7.9019e-02]],\n",
       "              \n",
       "                       [[ 1.1544e-03,  5.0823e-02, -3.6853e-02],\n",
       "                        [-9.1936e-02,  2.6645e-02,  3.1425e-02],\n",
       "                        [-6.8891e-02,  5.1123e-02, -9.0043e-02]],\n",
       "              \n",
       "                       [[ 9.0718e-02,  1.0208e-01,  2.8699e-02],\n",
       "                        [-6.6137e-02,  5.1300e-02,  1.7963e-02],\n",
       "                        [ 2.8663e-02,  3.4643e-02,  8.0254e-02]],\n",
       "              \n",
       "                       [[-4.5309e-02, -2.3711e-02,  2.8746e-02],\n",
       "                        [ 1.1486e-02,  8.5000e-02, -5.5365e-02],\n",
       "                        [-3.8387e-03,  1.9696e-02, -2.7996e-02]],\n",
       "              \n",
       "                       [[ 7.1859e-02,  1.1530e-02, -9.7422e-02],\n",
       "                        [-1.1420e-02, -4.7809e-02,  1.0243e-02],\n",
       "                        [-1.2250e-02, -1.0456e-01, -1.9208e-02]],\n",
       "              \n",
       "                       [[-1.0096e-02, -3.1083e-02,  9.6848e-02],\n",
       "                        [-2.3000e-02,  6.7717e-02,  2.6112e-02],\n",
       "                        [-8.8979e-02,  2.4770e-02,  8.7356e-02]],\n",
       "              \n",
       "                       [[-6.8948e-02, -6.8134e-02,  1.0318e-01],\n",
       "                        [ 8.4697e-02, -5.8807e-02,  6.3429e-02],\n",
       "                        [-1.3485e-02, -1.0393e-01,  7.9198e-03]],\n",
       "              \n",
       "                       [[ 3.4057e-02, -3.1619e-02,  3.6670e-02],\n",
       "                        [-9.0136e-02,  7.3050e-02,  8.9865e-02],\n",
       "                        [ 5.8130e-02,  1.7866e-02,  3.4716e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.6269e-02, -2.6339e-02, -1.0063e-02],\n",
       "                        [-5.8659e-02, -7.7857e-02,  7.0900e-02],\n",
       "                        [ 7.1535e-02, -9.5731e-02,  3.3542e-02]],\n",
       "              \n",
       "                       [[ 4.2881e-02,  1.0014e-01,  6.0985e-02],\n",
       "                        [ 9.6907e-02, -3.4510e-02,  7.3827e-02],\n",
       "                        [ 8.5740e-02, -9.9541e-02, -8.4613e-02]],\n",
       "              \n",
       "                       [[ 2.1335e-02,  5.7557e-02, -5.2369e-02],\n",
       "                        [ 1.1609e-02, -1.5303e-04,  2.6680e-02],\n",
       "                        [-5.6642e-02,  5.9455e-02,  7.0098e-02]],\n",
       "              \n",
       "                       [[-7.3139e-02,  1.0211e-03,  2.9247e-04],\n",
       "                        [ 3.3849e-02,  9.8198e-02,  3.0913e-02],\n",
       "                        [-2.3951e-02,  9.4672e-02, -4.0112e-02]],\n",
       "              \n",
       "                       [[-3.0608e-02,  7.1969e-03, -8.0270e-02],\n",
       "                        [ 1.1470e-02, -7.1518e-02,  1.0838e-02],\n",
       "                        [ 1.0099e-02,  1.4591e-02, -8.8891e-02]],\n",
       "              \n",
       "                       [[-1.0012e-01,  4.8501e-02,  9.0399e-02],\n",
       "                        [-9.3537e-02,  3.9043e-02, -7.7594e-02],\n",
       "                        [ 6.6082e-03,  9.8068e-02,  7.9965e-02]],\n",
       "              \n",
       "                       [[-7.7069e-02,  6.5203e-02,  5.5057e-02],\n",
       "                        [-1.6169e-04,  1.0211e-01, -4.1866e-02],\n",
       "                        [-2.4530e-02, -5.3275e-02,  1.5168e-02]],\n",
       "              \n",
       "                       [[ 2.7911e-02,  8.3990e-03, -5.9307e-02],\n",
       "                        [-4.7452e-02,  3.5855e-02, -9.2426e-02],\n",
       "                        [-1.6416e-02, -2.3350e-03, -4.2708e-02]],\n",
       "              \n",
       "                       [[ 3.8360e-02,  6.7940e-03,  7.4004e-02],\n",
       "                        [-9.3616e-03, -6.6528e-02,  7.4477e-02],\n",
       "                        [ 1.4720e-02, -3.0189e-02, -6.9476e-02]],\n",
       "              \n",
       "                       [[ 2.4707e-02, -1.0053e-01,  2.7762e-02],\n",
       "                        [ 5.2119e-02, -9.2465e-02, -6.9009e-02],\n",
       "                        [-7.5781e-02,  8.8597e-02,  8.9611e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.5987e-03,  9.8959e-02, -3.5239e-02],\n",
       "                        [-1.0233e-01,  3.6819e-02,  3.7343e-02],\n",
       "                        [ 1.0334e-01, -3.0510e-05,  8.0785e-02]],\n",
       "              \n",
       "                       [[ 6.4612e-02,  7.6292e-02, -1.0460e-01],\n",
       "                        [ 8.6800e-02, -8.9856e-02,  9.4501e-02],\n",
       "                        [-4.3682e-03, -9.3415e-02,  2.9314e-02]],\n",
       "              \n",
       "                       [[-2.1456e-02, -9.4678e-02, -3.8215e-02],\n",
       "                        [ 1.0868e-02,  8.2098e-02, -3.2406e-02],\n",
       "                        [ 6.2610e-02,  1.3200e-02,  3.5531e-03]],\n",
       "              \n",
       "                       [[ 2.0170e-02, -6.9177e-02, -8.7616e-02],\n",
       "                        [-3.3121e-02, -9.8226e-02, -4.9158e-02],\n",
       "                        [ 4.8494e-03, -6.9424e-02, -4.3723e-02]],\n",
       "              \n",
       "                       [[-1.8941e-02, -1.2144e-02, -5.8187e-02],\n",
       "                        [ 5.0650e-03, -1.4795e-02,  3.0147e-02],\n",
       "                        [ 4.7611e-03, -5.2638e-02, -3.6291e-02]],\n",
       "              \n",
       "                       [[-1.2149e-03, -6.5774e-02,  8.2520e-03],\n",
       "                        [-7.4425e-03,  4.0897e-02,  2.4947e-02],\n",
       "                        [ 7.8887e-02, -3.4749e-03, -7.7887e-02]],\n",
       "              \n",
       "                       [[ 4.7119e-02, -7.1240e-02, -1.4489e-02],\n",
       "                        [-3.4132e-02, -3.9997e-02, -3.9000e-02],\n",
       "                        [ 9.6863e-02,  6.0342e-02,  2.9213e-02]],\n",
       "              \n",
       "                       [[ 9.8975e-02, -9.5524e-02,  1.7010e-02],\n",
       "                        [ 6.7481e-02,  7.0022e-02, -8.3890e-02],\n",
       "                        [ 3.7514e-02, -6.0050e-02, -4.1187e-03]],\n",
       "              \n",
       "                       [[-2.1996e-02, -8.8013e-02, -1.0055e-01],\n",
       "                        [-6.9349e-02,  4.7832e-02,  4.8218e-02],\n",
       "                        [-9.1681e-02, -3.9586e-02,  1.7218e-03]],\n",
       "              \n",
       "                       [[-9.1135e-02,  5.9393e-02,  9.5473e-02],\n",
       "                        [ 1.8643e-02, -7.8321e-02,  2.4580e-02],\n",
       "                        [ 3.8265e-02,  8.3468e-02, -5.6085e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.4437e-02,  4.6312e-02,  6.5624e-03],\n",
       "                        [-3.4345e-02, -4.4169e-02, -5.4351e-02],\n",
       "                        [ 8.5328e-02, -1.8187e-02,  7.6022e-02]],\n",
       "              \n",
       "                       [[ 9.4094e-02,  1.3353e-02,  2.2454e-02],\n",
       "                        [-7.1789e-03,  7.2397e-02, -9.4983e-02],\n",
       "                        [ 4.1919e-02, -1.7174e-02,  4.8132e-02]],\n",
       "              \n",
       "                       [[-4.6949e-04, -3.9029e-02, -1.1379e-02],\n",
       "                        [ 5.6920e-02, -7.3210e-02, -6.6629e-02],\n",
       "                        [-2.3611e-02, -3.8235e-02,  4.1409e-02]],\n",
       "              \n",
       "                       [[ 7.0937e-02, -1.1289e-02,  9.9672e-02],\n",
       "                        [-4.4042e-02, -5.9151e-02, -4.7191e-02],\n",
       "                        [-7.2624e-02, -7.3885e-02, -9.3921e-02]],\n",
       "              \n",
       "                       [[-9.3422e-02,  2.7512e-02,  6.4284e-02],\n",
       "                        [ 9.8963e-02,  8.9787e-02, -6.0709e-03],\n",
       "                        [ 2.0454e-02, -6.3068e-02,  4.0743e-02]],\n",
       "              \n",
       "                       [[-1.0107e-01,  4.9719e-02,  1.9334e-02],\n",
       "                        [ 3.2393e-02,  3.8595e-02, -4.8394e-02],\n",
       "                        [ 9.0452e-02,  5.0307e-02,  6.9243e-02]],\n",
       "              \n",
       "                       [[ 1.3922e-02,  6.6196e-02,  7.0941e-02],\n",
       "                        [ 4.7775e-02,  8.0297e-02, -1.9119e-02],\n",
       "                        [ 6.9310e-02,  2.4286e-02,  6.3424e-02]],\n",
       "              \n",
       "                       [[ 1.0267e-01,  2.3869e-02, -3.9124e-02],\n",
       "                        [-1.0488e-02,  2.9676e-02,  1.7773e-02],\n",
       "                        [-2.8795e-02,  8.2590e-02,  6.3331e-02]],\n",
       "              \n",
       "                       [[-6.5475e-02, -8.5889e-03, -1.0119e-02],\n",
       "                        [-6.6063e-02,  1.5374e-02, -3.2360e-02],\n",
       "                        [-5.4419e-02, -3.3894e-02, -3.7584e-02]],\n",
       "              \n",
       "                       [[ 1.0084e-01,  4.0432e-02,  1.0373e-01],\n",
       "                        [ 2.8903e-02,  2.3868e-02,  4.3333e-02],\n",
       "                        [ 1.8092e-02, -8.2722e-02, -6.2334e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5538e-02,  1.5846e-03,  3.9709e-02],\n",
       "                        [ 4.0588e-02,  8.3623e-02,  2.1458e-02],\n",
       "                        [-3.5975e-02, -7.9271e-02, -7.7203e-02]],\n",
       "              \n",
       "                       [[-6.2965e-02,  3.1792e-02,  5.6950e-02],\n",
       "                        [ 9.2224e-02, -3.3342e-02, -8.3150e-03],\n",
       "                        [-3.1303e-02, -3.8517e-04,  3.3837e-02]],\n",
       "              \n",
       "                       [[-2.3160e-03,  4.8799e-03,  1.3354e-02],\n",
       "                        [ 3.9256e-02, -3.1981e-02, -6.2855e-02],\n",
       "                        [ 2.4869e-02, -1.2481e-02, -4.7753e-02]],\n",
       "              \n",
       "                       [[ 4.4268e-02,  9.5597e-04, -1.5333e-02],\n",
       "                        [-5.1027e-02, -1.3868e-02, -8.9632e-02],\n",
       "                        [ 2.3980e-02,  1.5818e-03,  6.3966e-02]],\n",
       "              \n",
       "                       [[ 6.8063e-03,  8.4277e-03,  2.8715e-02],\n",
       "                        [ 8.0210e-02, -4.9812e-02,  6.2930e-02],\n",
       "                        [ 2.5779e-02, -7.0320e-02,  3.6702e-02]],\n",
       "              \n",
       "                       [[-6.3217e-02, -3.3181e-02, -5.0245e-02],\n",
       "                        [-7.1711e-02,  8.3017e-02, -9.4217e-02],\n",
       "                        [ 5.2706e-02, -9.4870e-02, -1.2829e-02]],\n",
       "              \n",
       "                       [[ 6.2868e-03,  7.4937e-02, -3.8147e-02],\n",
       "                        [ 3.0340e-02,  1.6329e-02,  6.2021e-02],\n",
       "                        [ 6.2668e-03,  3.9470e-02, -6.3677e-02]],\n",
       "              \n",
       "                       [[-7.3250e-02,  9.3928e-02, -7.6808e-02],\n",
       "                        [-1.7945e-02, -1.2742e-02,  1.0308e-01],\n",
       "                        [-2.2780e-02, -8.0249e-02, -2.6721e-02]],\n",
       "              \n",
       "                       [[ 5.4372e-02,  4.1773e-02,  8.7204e-02],\n",
       "                        [-2.1579e-02,  4.9653e-02, -9.9194e-02],\n",
       "                        [ 4.0787e-02,  4.8432e-02,  6.7998e-02]],\n",
       "              \n",
       "                       [[-6.0446e-02, -2.8142e-02,  2.5502e-02],\n",
       "                        [-7.4905e-02, -8.3851e-02, -1.0141e-01],\n",
       "                        [ 5.8842e-03,  6.5458e-02,  2.7075e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.4263e-03,  3.6727e-02, -6.6240e-02],\n",
       "                        [ 1.1113e-02, -2.6186e-02, -5.2193e-02],\n",
       "                        [ 9.0902e-02, -8.1550e-02,  1.5448e-02]],\n",
       "              \n",
       "                       [[-9.2624e-02, -3.5762e-03, -4.6840e-02],\n",
       "                        [ 3.4695e-02, -5.9191e-02,  6.7466e-02],\n",
       "                        [-8.5536e-02,  6.3313e-02, -7.9181e-02]],\n",
       "              \n",
       "                       [[ 5.6456e-02, -4.4384e-02, -2.4556e-04],\n",
       "                        [-1.9238e-02,  6.8414e-02,  3.4546e-02],\n",
       "                        [-9.2887e-02,  9.6914e-03, -7.2718e-02]],\n",
       "              \n",
       "                       [[ 7.8800e-02,  1.7319e-02, -2.7109e-02],\n",
       "                        [-5.3777e-02,  3.6485e-02, -6.3129e-02],\n",
       "                        [ 4.9992e-02,  5.7519e-02,  6.4701e-02]],\n",
       "              \n",
       "                       [[ 2.7537e-02, -9.2272e-02,  7.5823e-02],\n",
       "                        [-3.2700e-02, -3.1163e-02, -1.1325e-02],\n",
       "                        [ 7.7068e-02,  8.1052e-02,  1.6276e-02]],\n",
       "              \n",
       "                       [[ 5.0296e-02, -9.8241e-02,  2.4901e-04],\n",
       "                        [-9.3254e-02,  3.5876e-02, -7.5099e-02],\n",
       "                        [-3.7568e-02,  7.3684e-02,  1.0074e-01]],\n",
       "              \n",
       "                       [[-6.3286e-02, -5.8503e-02,  1.3055e-02],\n",
       "                        [ 4.1437e-02, -1.7168e-02, -3.2918e-02],\n",
       "                        [-6.9237e-02,  4.4997e-02,  1.0328e-01]],\n",
       "              \n",
       "                       [[-5.1026e-02,  4.9718e-02,  5.1481e-02],\n",
       "                        [ 8.4728e-02, -1.2001e-02,  3.3202e-03],\n",
       "                        [ 7.7444e-02,  6.6631e-02,  1.0411e-01]],\n",
       "              \n",
       "                       [[-3.0207e-02,  4.1709e-02,  7.3605e-02],\n",
       "                        [-7.1553e-02,  2.0940e-02, -2.3586e-02],\n",
       "                        [ 6.7760e-02, -4.7342e-02,  7.3933e-03]],\n",
       "              \n",
       "                       [[ 6.3067e-02, -9.6567e-02, -8.9004e-02],\n",
       "                        [-5.3989e-02,  6.7611e-02,  7.0680e-02],\n",
       "                        [-7.1991e-02,  2.0100e-02, -5.5854e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8926e-02,  9.0907e-02,  5.0914e-02],\n",
       "                        [-2.8828e-02,  1.5516e-02,  2.0424e-02],\n",
       "                        [ 2.4691e-02, -3.6079e-02, -6.2074e-02]],\n",
       "              \n",
       "                       [[ 6.9788e-02,  1.4164e-02,  4.4119e-02],\n",
       "                        [-3.9922e-02,  5.1057e-02,  7.6713e-02],\n",
       "                        [ 6.4107e-02,  2.8660e-02,  1.0371e-01]],\n",
       "              \n",
       "                       [[-2.3053e-04,  2.2441e-02,  1.0015e-01],\n",
       "                        [ 1.0245e-01, -4.4506e-02,  9.4953e-02],\n",
       "                        [ 3.8902e-02, -1.1799e-02,  9.2038e-02]],\n",
       "              \n",
       "                       [[-5.4605e-02,  6.8490e-02,  1.0445e-01],\n",
       "                        [-7.2701e-02, -6.2201e-02, -1.0445e-01],\n",
       "                        [-1.8970e-02, -9.5733e-02, -3.5304e-02]],\n",
       "              \n",
       "                       [[ 3.2002e-02,  7.4511e-02,  5.8717e-02],\n",
       "                        [ 5.8511e-02,  4.3730e-02, -6.5378e-02],\n",
       "                        [-8.3694e-02,  4.3696e-03,  1.0009e-01]],\n",
       "              \n",
       "                       [[ 5.9351e-03, -9.0662e-03, -7.1545e-02],\n",
       "                        [-5.2266e-02, -8.1256e-02,  8.4398e-02],\n",
       "                        [-1.7174e-02, -9.3119e-02,  1.1308e-02]],\n",
       "              \n",
       "                       [[ 7.6494e-03, -1.3023e-02,  3.7733e-02],\n",
       "                        [ 5.6687e-02, -9.9128e-02, -8.0753e-02],\n",
       "                        [-5.0639e-03, -9.7729e-02, -9.5750e-02]],\n",
       "              \n",
       "                       [[ 9.3067e-02, -8.0174e-03, -5.2113e-02],\n",
       "                        [-3.6157e-02, -8.2295e-02,  8.2258e-02],\n",
       "                        [-2.2857e-02, -5.9265e-02, -7.9944e-02]],\n",
       "              \n",
       "                       [[ 6.1611e-02, -1.4571e-02, -1.1074e-02],\n",
       "                        [-2.7473e-02, -5.0883e-02,  1.8751e-02],\n",
       "                        [ 8.1099e-02, -6.1093e-02,  5.0504e-03]],\n",
       "              \n",
       "                       [[-8.0165e-02, -4.9426e-02,  9.2525e-02],\n",
       "                        [ 1.1052e-03,  1.0154e-01, -1.8468e-02],\n",
       "                        [-5.7453e-02, -6.2981e-02,  9.3426e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.1058e-02,  5.5318e-02,  2.6203e-02],\n",
       "                        [ 3.1107e-02,  5.9476e-02, -2.7577e-02],\n",
       "                        [ 6.5223e-02, -8.3982e-02, -3.7087e-02]],\n",
       "              \n",
       "                       [[ 7.7164e-02,  3.1283e-02, -1.4038e-02],\n",
       "                        [-2.4616e-02, -6.4364e-02,  6.4098e-02],\n",
       "                        [-3.3520e-03, -3.5664e-03,  2.4929e-02]],\n",
       "              \n",
       "                       [[ 7.7787e-02, -5.3778e-02, -3.6303e-02],\n",
       "                        [ 7.1429e-02,  5.9532e-02, -5.1855e-02],\n",
       "                        [-1.0428e-01,  1.9555e-02,  5.5434e-02]],\n",
       "              \n",
       "                       [[ 2.5178e-02,  7.4768e-02, -8.3640e-02],\n",
       "                        [ 5.3156e-02, -6.5531e-02,  5.9325e-02],\n",
       "                        [ 7.8394e-02,  3.3385e-02,  8.5284e-02]],\n",
       "              \n",
       "                       [[-6.9481e-02, -9.4275e-02, -1.0135e-01],\n",
       "                        [ 6.6179e-02,  3.6926e-02, -7.7188e-02],\n",
       "                        [ 5.1048e-02,  9.6177e-02, -1.0394e-01]],\n",
       "              \n",
       "                       [[ 7.6466e-02,  1.6167e-02,  9.8053e-03],\n",
       "                        [ 9.4847e-02,  9.5458e-02,  4.4414e-02],\n",
       "                        [ 8.3288e-02,  4.3853e-02,  1.7176e-02]],\n",
       "              \n",
       "                       [[-9.2656e-02,  1.9689e-02, -7.4993e-02],\n",
       "                        [ 3.2452e-02,  1.8598e-02,  2.3681e-03],\n",
       "                        [-7.2071e-02, -6.3899e-02,  7.7912e-02]],\n",
       "              \n",
       "                       [[ 5.1336e-02,  5.5576e-02, -3.1410e-02],\n",
       "                        [-1.8151e-02, -2.7014e-02,  7.2489e-02],\n",
       "                        [-4.5504e-02,  6.6394e-02,  7.2679e-02]],\n",
       "              \n",
       "                       [[-9.6403e-02,  6.4369e-04, -2.0076e-02],\n",
       "                        [-5.8273e-02,  4.5507e-02, -1.2807e-02],\n",
       "                        [ 9.2287e-02, -6.5976e-02,  4.8976e-02]],\n",
       "              \n",
       "                       [[-8.9998e-02, -5.2833e-02,  7.1903e-03],\n",
       "                        [ 8.3283e-02,  5.5521e-02, -8.6550e-02],\n",
       "                        [ 1.1676e-02, -6.2138e-02,  4.5674e-03]]]])),\n",
       "             ('conv_block_2.0.bias',\n",
       "              tensor([-0.0878, -0.0309,  0.0723, -0.0967, -0.1005,  0.0192,  0.0144, -0.0193,\n",
       "                       0.0920, -0.0635])),\n",
       "             ('conv_block_2.2.weight',\n",
       "              tensor([[[[-6.3992e-02, -7.8791e-02, -1.9619e-02],\n",
       "                        [-2.6901e-02,  6.5222e-02, -5.9186e-03],\n",
       "                        [ 3.3663e-02, -4.3804e-02,  8.5507e-02]],\n",
       "              \n",
       "                       [[ 8.8862e-02, -9.4401e-02, -2.7090e-02],\n",
       "                        [-8.9439e-02,  4.4781e-02, -9.2094e-02],\n",
       "                        [-4.9839e-02,  1.0532e-01, -1.0066e-01]],\n",
       "              \n",
       "                       [[ 7.7771e-02,  8.9049e-03,  8.4289e-02],\n",
       "                        [-5.3494e-02,  6.9236e-02,  1.2718e-02],\n",
       "                        [ 8.1073e-03,  7.1945e-02, -1.0019e-01]],\n",
       "              \n",
       "                       [[-8.4902e-02,  1.0180e-01, -6.3298e-02],\n",
       "                        [-7.5980e-02, -5.1539e-03, -3.3742e-02],\n",
       "                        [-1.4421e-02, -7.0623e-02,  3.8034e-02]],\n",
       "              \n",
       "                       [[-9.0703e-02,  8.5374e-03,  6.1510e-02],\n",
       "                        [ 2.0253e-02,  1.4006e-02,  1.5418e-02],\n",
       "                        [-3.0880e-02, -2.0080e-02, -4.4450e-02]],\n",
       "              \n",
       "                       [[-7.1207e-02, -5.5810e-02,  1.0420e-01],\n",
       "                        [-1.7641e-02,  3.6924e-02,  7.2896e-02],\n",
       "                        [-8.2343e-03, -5.6707e-02, -7.1419e-02]],\n",
       "              \n",
       "                       [[-3.8833e-02,  3.7624e-02, -8.8771e-02],\n",
       "                        [-1.2870e-02,  4.0096e-02,  8.5999e-02],\n",
       "                        [ 3.1721e-02,  2.0846e-02,  7.2162e-02]],\n",
       "              \n",
       "                       [[ 4.8708e-02,  3.5661e-02, -3.2682e-02],\n",
       "                        [-8.4528e-02, -2.2769e-02, -1.9117e-02],\n",
       "                        [ 7.7410e-03, -1.1593e-02,  4.2616e-02]],\n",
       "              \n",
       "                       [[ 7.0050e-02, -4.2735e-02, -1.0002e-01],\n",
       "                        [-5.4081e-02, -5.0436e-02,  5.9750e-02],\n",
       "                        [-6.7994e-02, -9.9145e-03, -2.2340e-02]],\n",
       "              \n",
       "                       [[-6.3976e-02,  4.7780e-02, -4.3909e-02],\n",
       "                        [-5.4531e-03, -7.4112e-02, -1.0632e-02],\n",
       "                        [ 1.4977e-02, -4.2894e-03, -3.9386e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.1315e-02, -2.7311e-02, -5.8439e-02],\n",
       "                        [-7.7732e-02, -2.2329e-02, -9.9578e-02],\n",
       "                        [ 8.7492e-02, -5.0357e-02, -4.3684e-02]],\n",
       "              \n",
       "                       [[ 9.7439e-03,  2.7326e-02, -9.9393e-03],\n",
       "                        [ 7.2313e-02, -6.1448e-02,  3.7777e-02],\n",
       "                        [-2.3773e-04, -8.5747e-02, -4.0824e-02]],\n",
       "              \n",
       "                       [[ 2.6825e-02,  2.0138e-02,  7.6647e-02],\n",
       "                        [ 7.0518e-02, -5.7493e-02, -4.5013e-02],\n",
       "                        [-2.2351e-02, -7.5517e-02, -2.8459e-02]],\n",
       "              \n",
       "                       [[-8.6258e-02,  4.0092e-02,  7.4583e-02],\n",
       "                        [ 8.3459e-03, -7.5460e-02, -7.9827e-02],\n",
       "                        [-4.1036e-02,  3.0659e-02,  2.5711e-03]],\n",
       "              \n",
       "                       [[ 1.9166e-02,  9.9346e-02,  4.8956e-02],\n",
       "                        [ 2.2665e-02, -2.1327e-02,  4.9864e-02],\n",
       "                        [ 3.8563e-02, -9.4879e-02, -6.2266e-02]],\n",
       "              \n",
       "                       [[ 3.5381e-03,  3.9997e-02,  5.1282e-02],\n",
       "                        [-6.2748e-02, -1.0458e-01, -5.4909e-03],\n",
       "                        [-1.2050e-02,  3.0588e-02, -2.8988e-02]],\n",
       "              \n",
       "                       [[ 8.0588e-02,  7.0333e-03,  7.6975e-02],\n",
       "                        [-7.3398e-02,  4.2167e-02,  1.2560e-02],\n",
       "                        [-5.2720e-02,  5.2256e-02, -1.0372e-01]],\n",
       "              \n",
       "                       [[ 8.5220e-02,  8.4947e-03,  1.0178e-02],\n",
       "                        [ 4.8746e-02,  8.7503e-03,  4.5184e-02],\n",
       "                        [ 6.7063e-02, -8.2268e-02,  6.9735e-02]],\n",
       "              \n",
       "                       [[-1.5784e-02, -2.4513e-02,  2.1217e-02],\n",
       "                        [ 8.2446e-02, -5.7302e-02, -7.1039e-02],\n",
       "                        [ 6.5418e-02, -4.9507e-02,  3.3937e-02]],\n",
       "              \n",
       "                       [[-1.5530e-02,  2.9014e-02,  8.0439e-02],\n",
       "                        [-5.3421e-02, -5.1151e-02,  5.1716e-02],\n",
       "                        [ 5.7714e-03, -1.1601e-02, -9.2590e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.9309e-02, -3.9919e-03, -1.9415e-02],\n",
       "                        [-4.3269e-02, -2.0801e-02,  5.1233e-02],\n",
       "                        [-2.4227e-03,  9.0147e-02, -6.0858e-03]],\n",
       "              \n",
       "                       [[-1.5122e-02,  5.9498e-02, -2.7275e-03],\n",
       "                        [-2.1039e-02,  3.5231e-02,  8.3129e-02],\n",
       "                        [ 2.6305e-02,  7.3398e-02,  6.8309e-02]],\n",
       "              \n",
       "                       [[ 2.9810e-02,  3.6650e-02,  3.4014e-02],\n",
       "                        [ 1.0934e-02,  8.9675e-02,  9.7308e-02],\n",
       "                        [ 3.7524e-02, -5.2640e-03,  9.4509e-02]],\n",
       "              \n",
       "                       [[-8.2042e-02,  7.7453e-02,  5.5849e-02],\n",
       "                        [ 6.7687e-02, -8.0992e-03, -7.8646e-02],\n",
       "                        [ 7.5193e-02, -4.6091e-02,  2.7734e-02]],\n",
       "              \n",
       "                       [[ 5.9719e-02, -9.8508e-02,  6.9954e-03],\n",
       "                        [-3.7444e-02,  7.4815e-02, -6.7114e-02],\n",
       "                        [ 6.4001e-02,  6.5730e-02,  5.8156e-02]],\n",
       "              \n",
       "                       [[ 1.0119e-01,  1.5964e-02, -9.5541e-02],\n",
       "                        [ 7.5248e-02,  9.6499e-03,  2.0918e-03],\n",
       "                        [-1.0041e-01, -2.3691e-02, -5.1162e-02]],\n",
       "              \n",
       "                       [[ 1.0324e-01,  7.5054e-02,  7.8634e-02],\n",
       "                        [ 7.2188e-02, -6.5340e-02, -4.5270e-02],\n",
       "                        [-4.1252e-02, -4.2257e-02,  8.2054e-02]],\n",
       "              \n",
       "                       [[ 3.5815e-02,  8.4470e-02, -4.9309e-03],\n",
       "                        [-9.3965e-02, -3.0582e-02,  7.4081e-02],\n",
       "                        [ 6.4174e-02,  3.2632e-02, -3.0919e-02]],\n",
       "              \n",
       "                       [[-9.8386e-02, -5.6639e-02,  5.4958e-02],\n",
       "                        [-4.2518e-02,  5.0421e-02,  2.8781e-02],\n",
       "                        [-4.0486e-02,  6.4202e-02, -3.3871e-02]],\n",
       "              \n",
       "                       [[-3.5020e-03, -4.0152e-02, -9.9988e-02],\n",
       "                        [ 1.6996e-02,  3.0460e-02, -5.3072e-02],\n",
       "                        [ 6.4663e-02, -9.4558e-02, -1.0161e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.5106e-02, -3.6430e-02, -1.1707e-02],\n",
       "                        [-2.0370e-02,  4.8108e-02, -9.2510e-02],\n",
       "                        [ 1.5521e-02,  1.8254e-03,  2.7842e-02]],\n",
       "              \n",
       "                       [[ 1.0479e-01,  6.4874e-02, -5.8366e-02],\n",
       "                        [-8.6378e-02, -2.5520e-02, -5.2876e-02],\n",
       "                        [ 3.6820e-02,  9.6628e-04,  8.4783e-02]],\n",
       "              \n",
       "                       [[ 4.1405e-02, -1.9382e-02,  3.6229e-03],\n",
       "                        [ 2.5244e-02, -1.3080e-02,  8.5058e-02],\n",
       "                        [-8.2420e-02,  5.1377e-02, -6.7192e-02]],\n",
       "              \n",
       "                       [[-9.2347e-02, -2.1640e-02,  5.1366e-02],\n",
       "                        [ 7.4478e-02,  2.6452e-02, -9.1104e-03],\n",
       "                        [-5.9092e-03, -4.2731e-02, -9.4592e-03]],\n",
       "              \n",
       "                       [[-7.2831e-03,  8.9699e-02,  6.1690e-02],\n",
       "                        [-8.4351e-02,  4.3605e-04, -6.4834e-02],\n",
       "                        [-1.6733e-02, -8.3776e-02,  2.7402e-02]],\n",
       "              \n",
       "                       [[-7.6008e-02,  1.0406e-01,  7.9605e-02],\n",
       "                        [-7.2559e-02, -9.9239e-02,  4.1128e-03],\n",
       "                        [-2.9425e-02,  3.0945e-02, -7.1353e-02]],\n",
       "              \n",
       "                       [[ 4.3148e-02, -9.1047e-02, -5.5632e-02],\n",
       "                        [-5.5414e-02,  5.1007e-02, -2.7597e-03],\n",
       "                        [-1.0130e-01, -6.0201e-02, -4.8781e-02]],\n",
       "              \n",
       "                       [[-9.7802e-02,  1.3497e-02,  3.7561e-02],\n",
       "                        [-1.9340e-02, -4.1947e-02, -6.3926e-04],\n",
       "                        [-8.3725e-02, -6.4184e-02, -2.4040e-03]],\n",
       "              \n",
       "                       [[ 9.3643e-02, -3.2414e-02,  5.2247e-02],\n",
       "                        [-4.1484e-02, -2.8060e-02, -1.0034e-01],\n",
       "                        [ 8.7330e-02,  1.0264e-01, -2.2139e-03]],\n",
       "              \n",
       "                       [[ 6.6974e-02,  8.6219e-02,  5.2359e-02],\n",
       "                        [ 5.4288e-02, -1.0035e-01, -9.9050e-02],\n",
       "                        [-8.0906e-02,  3.2970e-02, -9.1177e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.0464e-02, -5.1092e-02, -9.7154e-02],\n",
       "                        [ 1.4203e-04,  1.5207e-02, -6.1686e-02],\n",
       "                        [ 6.9018e-02, -4.0018e-02, -2.9676e-02]],\n",
       "              \n",
       "                       [[ 8.0309e-02,  9.0499e-02, -1.2093e-02],\n",
       "                        [-7.5671e-02, -5.2881e-02,  1.3423e-02],\n",
       "                        [ 6.1790e-02,  5.2477e-02, -4.6547e-02]],\n",
       "              \n",
       "                       [[-9.9650e-02, -9.2249e-02, -3.3537e-02],\n",
       "                        [ 1.3223e-03, -4.7347e-02, -8.3348e-02],\n",
       "                        [ 1.1109e-02, -8.3668e-02, -8.0946e-02]],\n",
       "              \n",
       "                       [[-8.5692e-02, -2.8563e-02,  9.3104e-02],\n",
       "                        [ 4.1207e-02, -1.2498e-02,  2.1694e-02],\n",
       "                        [ 4.1975e-02,  6.1414e-04, -8.5020e-02]],\n",
       "              \n",
       "                       [[-6.4944e-02, -7.1610e-02, -2.6766e-03],\n",
       "                        [-9.6492e-02, -1.9166e-02, -3.8545e-02],\n",
       "                        [ 1.0345e-01,  8.5679e-02,  6.1227e-02]],\n",
       "              \n",
       "                       [[ 5.9116e-03, -3.4129e-02,  2.6887e-02],\n",
       "                        [-7.2830e-02, -4.4957e-02, -2.1175e-02],\n",
       "                        [-2.4766e-02, -9.9854e-02,  4.1903e-02]],\n",
       "              \n",
       "                       [[ 8.6803e-02, -5.8141e-02,  2.8415e-02],\n",
       "                        [-1.2225e-02, -3.8445e-03,  6.1443e-03],\n",
       "                        [ 9.1346e-02,  1.4124e-02, -6.6690e-02]],\n",
       "              \n",
       "                       [[-3.7917e-02,  5.1495e-02,  3.2893e-02],\n",
       "                        [ 2.0487e-03, -1.3912e-02, -4.1012e-02],\n",
       "                        [-3.7413e-02, -5.5602e-02,  1.7273e-02]],\n",
       "              \n",
       "                       [[ 2.9603e-02,  8.0717e-02, -2.3813e-02],\n",
       "                        [ 7.5461e-03,  6.8125e-02,  4.5852e-02],\n",
       "                        [ 1.3544e-02,  3.2390e-02,  5.4714e-03]],\n",
       "              \n",
       "                       [[-9.0419e-02,  4.0636e-03, -2.3040e-02],\n",
       "                        [ 9.5123e-02,  9.5145e-02,  2.0912e-02],\n",
       "                        [ 9.4215e-02, -5.4288e-02,  9.1619e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 9.0756e-02, -4.0288e-03, -8.4592e-02],\n",
       "                        [-3.4015e-02, -2.8189e-02,  1.7411e-03],\n",
       "                        [-9.5569e-02,  1.9535e-02, -4.3839e-02]],\n",
       "              \n",
       "                       [[-2.6989e-02, -5.4443e-02, -2.2255e-02],\n",
       "                        [-9.7896e-02, -5.5885e-02,  9.7108e-03],\n",
       "                        [ 6.9072e-02,  9.5790e-02, -7.9737e-02]],\n",
       "              \n",
       "                       [[ 4.4264e-02, -5.9419e-02, -8.1498e-02],\n",
       "                        [-4.6417e-03, -6.0468e-02, -9.0783e-02],\n",
       "                        [-9.8509e-02, -7.0556e-02,  8.6619e-02]],\n",
       "              \n",
       "                       [[ 5.8788e-02, -4.1726e-02, -7.0553e-02],\n",
       "                        [-8.1085e-02, -6.2246e-02, -4.3376e-02],\n",
       "                        [ 6.3308e-02,  3.4496e-02, -4.0622e-02]],\n",
       "              \n",
       "                       [[ 7.2567e-02, -6.5484e-02, -8.5876e-02],\n",
       "                        [ 2.3006e-02, -5.8123e-02,  2.9987e-02],\n",
       "                        [ 8.9306e-02, -4.9849e-02, -7.3556e-02]],\n",
       "              \n",
       "                       [[ 3.9676e-02, -9.5200e-02,  9.4044e-02],\n",
       "                        [-4.9780e-02,  5.0961e-02, -8.3818e-02],\n",
       "                        [-7.1348e-02,  1.1611e-02,  3.7463e-02]],\n",
       "              \n",
       "                       [[ 8.1734e-02,  8.8158e-02, -6.0623e-03],\n",
       "                        [-1.3552e-02,  1.7424e-02, -2.4486e-02],\n",
       "                        [ 3.5882e-03, -9.9828e-02, -8.6531e-02]],\n",
       "              \n",
       "                       [[ 7.2233e-02, -6.1597e-02,  8.3008e-02],\n",
       "                        [ 1.1568e-02,  2.5676e-02,  9.5804e-02],\n",
       "                        [-5.8628e-02, -1.6640e-02,  1.8675e-02]],\n",
       "              \n",
       "                       [[ 3.6012e-02, -1.0259e-01,  3.7464e-02],\n",
       "                        [-6.2163e-02,  1.3846e-02,  7.1315e-02],\n",
       "                        [-1.0500e-02, -3.3346e-03, -7.8757e-03]],\n",
       "              \n",
       "                       [[ 8.7962e-02,  5.9907e-02,  1.7727e-02],\n",
       "                        [-6.3437e-02, -5.7241e-02,  8.3964e-02],\n",
       "                        [ 7.5834e-02,  6.1033e-02, -8.2189e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.2092e-02, -1.0076e-02,  7.7661e-02],\n",
       "                        [ 9.1553e-02,  1.1554e-02, -4.3863e-02],\n",
       "                        [ 9.9153e-02, -5.4931e-02,  6.8876e-02]],\n",
       "              \n",
       "                       [[-1.0108e-01, -3.3153e-02, -9.1902e-02],\n",
       "                        [-4.7284e-02,  4.4759e-02, -7.5529e-02],\n",
       "                        [-9.1158e-02,  7.5371e-02,  5.6270e-02]],\n",
       "              \n",
       "                       [[-1.1527e-03, -7.4309e-02, -2.7927e-02],\n",
       "                        [-3.4129e-02,  6.5100e-02, -3.4478e-02],\n",
       "                        [-3.0360e-02, -7.4720e-02, -4.9646e-02]],\n",
       "              \n",
       "                       [[ 5.7074e-02,  6.7914e-02,  1.5315e-02],\n",
       "                        [-3.9549e-02,  1.0124e-01,  2.0806e-02],\n",
       "                        [-4.0688e-02, -3.6535e-02, -1.4752e-02]],\n",
       "              \n",
       "                       [[ 4.9974e-02,  3.8555e-02,  7.6418e-02],\n",
       "                        [-4.7494e-03,  8.7183e-02, -4.2816e-02],\n",
       "                        [-4.8547e-02, -3.8927e-02, -9.8896e-02]],\n",
       "              \n",
       "                       [[-6.9195e-02, -9.5382e-02, -6.2294e-03],\n",
       "                        [ 9.9374e-04, -2.7358e-02, -7.2035e-02],\n",
       "                        [ 9.5637e-02, -3.4926e-02,  5.0233e-02]],\n",
       "              \n",
       "                       [[ 7.3408e-02, -6.9292e-02, -1.3179e-02],\n",
       "                        [ 6.0923e-02,  1.0218e-01, -1.3299e-02],\n",
       "                        [ 7.6382e-02, -8.2732e-02, -6.8489e-02]],\n",
       "              \n",
       "                       [[ 8.6682e-02, -9.9801e-03,  1.0414e-01],\n",
       "                        [ 7.6651e-03, -4.3714e-02,  1.0011e-01],\n",
       "                        [ 9.2179e-02,  9.7826e-03, -6.3900e-02]],\n",
       "              \n",
       "                       [[-4.5639e-03, -5.0693e-02,  7.6810e-02],\n",
       "                        [ 4.8829e-03,  2.2191e-02,  6.3927e-02],\n",
       "                        [ 3.4916e-02, -6.5803e-02,  8.7566e-02]],\n",
       "              \n",
       "                       [[ 6.4758e-02, -6.5073e-02,  7.9700e-02],\n",
       "                        [ 2.9905e-02, -2.0750e-02, -7.5385e-02],\n",
       "                        [-1.7490e-02, -1.0335e-01,  6.0163e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.6343e-02, -3.0347e-02,  9.7720e-02],\n",
       "                        [-3.9032e-02,  1.8051e-02, -7.3459e-02],\n",
       "                        [-4.4565e-03,  4.2610e-02,  4.5403e-02]],\n",
       "              \n",
       "                       [[-3.5346e-03, -5.3154e-02,  7.3680e-02],\n",
       "                        [ 6.9788e-02,  1.6916e-02, -4.8475e-02],\n",
       "                        [ 2.2349e-02,  2.8186e-04,  9.6302e-02]],\n",
       "              \n",
       "                       [[ 1.5621e-02,  8.1301e-03,  7.2057e-03],\n",
       "                        [ 5.6079e-02, -1.3024e-03,  9.0351e-02],\n",
       "                        [ 5.4917e-02, -7.9650e-02, -1.2070e-06]],\n",
       "              \n",
       "                       [[-8.9472e-02, -8.0934e-02,  2.0480e-02],\n",
       "                        [ 2.3687e-02, -9.2246e-03,  1.0019e-01],\n",
       "                        [-5.6627e-02, -4.4176e-02, -1.6881e-02]],\n",
       "              \n",
       "                       [[ 6.3911e-04, -8.9284e-03,  9.4909e-02],\n",
       "                        [-4.4519e-02, -5.5137e-02,  9.0599e-03],\n",
       "                        [ 7.9171e-02,  2.5019e-02,  5.6787e-02]],\n",
       "              \n",
       "                       [[ 2.0406e-02,  8.9839e-02,  6.3311e-02],\n",
       "                        [ 7.5428e-02, -1.4198e-02, -8.7268e-02],\n",
       "                        [-5.0002e-02,  3.5910e-02,  7.3950e-02]],\n",
       "              \n",
       "                       [[-4.1184e-02,  8.7218e-02,  1.5150e-02],\n",
       "                        [ 4.1869e-04,  4.1093e-03, -1.8623e-02],\n",
       "                        [ 9.8683e-02,  4.5784e-03,  6.4564e-02]],\n",
       "              \n",
       "                       [[-8.8967e-02, -5.4309e-02,  1.1852e-02],\n",
       "                        [ 8.4169e-02,  5.0184e-02,  2.0076e-02],\n",
       "                        [-1.0414e-01,  1.9816e-03, -6.9581e-02]],\n",
       "              \n",
       "                       [[-9.0006e-02,  1.4414e-02, -6.6693e-02],\n",
       "                        [ 9.5674e-02, -5.7294e-02,  3.3970e-02],\n",
       "                        [ 6.1871e-02, -8.1928e-02,  5.3946e-02]],\n",
       "              \n",
       "                       [[-1.4114e-02,  5.4619e-02,  1.0201e-01],\n",
       "                        [-4.4922e-02, -4.5653e-02,  8.3753e-02],\n",
       "                        [ 1.1722e-02, -1.0513e-02,  7.9971e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.0928e-02, -5.2047e-03,  7.2403e-02],\n",
       "                        [ 4.1195e-02, -6.8180e-02,  2.7398e-02],\n",
       "                        [-8.0368e-02, -5.7245e-02,  6.7779e-02]],\n",
       "              \n",
       "                       [[-2.8093e-02, -5.3691e-02,  7.4717e-03],\n",
       "                        [ 2.5759e-02, -6.5524e-02, -7.1084e-02],\n",
       "                        [-1.0209e-01,  2.7236e-02, -6.8013e-02]],\n",
       "              \n",
       "                       [[ 8.0331e-03, -2.3576e-02, -6.8923e-02],\n",
       "                        [-3.3636e-02, -8.1027e-02, -5.5797e-02],\n",
       "                        [-3.2857e-03, -9.0116e-02, -9.2447e-02]],\n",
       "              \n",
       "                       [[ 7.8958e-02,  9.9188e-03, -4.6618e-02],\n",
       "                        [-3.5047e-03,  7.8168e-02, -8.7939e-02],\n",
       "                        [-5.5886e-02, -7.6226e-02, -7.6634e-03]],\n",
       "              \n",
       "                       [[-3.6274e-03, -8.2146e-02,  7.3163e-02],\n",
       "                        [-8.0946e-02,  9.8414e-02, -7.2560e-02],\n",
       "                        [-1.4446e-02,  1.9710e-02, -4.6852e-02]],\n",
       "              \n",
       "                       [[ 9.6939e-02, -7.2673e-02, -5.8427e-03],\n",
       "                        [-7.7398e-02,  2.9261e-02,  8.9871e-02],\n",
       "                        [ 9.7776e-02,  1.2514e-02, -5.2773e-02]],\n",
       "              \n",
       "                       [[ 1.0244e-01,  7.8667e-03,  7.1317e-02],\n",
       "                        [-5.4751e-02, -4.8920e-02, -8.7504e-02],\n",
       "                        [ 9.6990e-02,  1.7486e-02, -7.5704e-02]],\n",
       "              \n",
       "                       [[ 9.0535e-03, -4.5211e-02,  5.2659e-03],\n",
       "                        [ 3.4988e-02, -5.2308e-02,  1.8394e-02],\n",
       "                        [-6.6553e-02,  2.0312e-02, -1.0178e-01]],\n",
       "              \n",
       "                       [[ 1.6797e-02,  1.0473e-01,  9.7094e-02],\n",
       "                        [ 3.8451e-02,  7.7563e-02,  1.0248e-01],\n",
       "                        [ 2.9870e-02,  3.5156e-02,  1.3707e-02]],\n",
       "              \n",
       "                       [[ 9.3322e-02,  9.0551e-02, -4.9570e-02],\n",
       "                        [-4.3333e-03, -5.3110e-02,  3.7824e-02],\n",
       "                        [-1.0214e-01,  3.7301e-02, -2.8929e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.8227e-02,  3.2899e-02, -5.2454e-02],\n",
       "                        [ 5.4687e-02,  4.4762e-02, -8.9602e-02],\n",
       "                        [ 1.0517e-01,  9.0731e-02,  6.5584e-02]],\n",
       "              \n",
       "                       [[-1.0699e-02,  3.7345e-02, -5.7028e-02],\n",
       "                        [-3.5818e-02,  4.9749e-02,  4.6925e-02],\n",
       "                        [ 4.1741e-02, -1.0053e-01,  8.7350e-02]],\n",
       "              \n",
       "                       [[-4.4028e-02,  9.1223e-02,  8.6852e-02],\n",
       "                        [ 3.9070e-02,  1.0502e-01,  6.0528e-02],\n",
       "                        [ 6.1821e-02, -3.5794e-02,  9.7766e-02]],\n",
       "              \n",
       "                       [[ 2.7627e-02,  6.2280e-02, -2.3834e-02],\n",
       "                        [ 7.6340e-02,  9.3509e-02, -8.0770e-02],\n",
       "                        [ 8.6415e-02, -6.9664e-02, -7.2571e-02]],\n",
       "              \n",
       "                       [[-8.8089e-02,  3.0459e-02, -7.9144e-02],\n",
       "                        [-3.9680e-02, -5.2988e-02,  2.8172e-02],\n",
       "                        [-1.0349e-01, -4.8324e-02,  7.7112e-04]],\n",
       "              \n",
       "                       [[ 9.4660e-03, -4.7605e-02,  3.7764e-02],\n",
       "                        [-6.9544e-02, -8.9270e-02, -1.4986e-02],\n",
       "                        [-5.6989e-02,  6.6443e-02, -7.2049e-02]],\n",
       "              \n",
       "                       [[-8.8494e-03,  4.3782e-02, -9.2311e-02],\n",
       "                        [ 8.1599e-02, -4.7895e-02, -2.8684e-02],\n",
       "                        [-6.4480e-02, -3.9279e-02, -4.0645e-02]],\n",
       "              \n",
       "                       [[-9.3801e-02,  3.6019e-02, -3.3768e-04],\n",
       "                        [ 1.0311e-01,  7.1117e-02,  9.1699e-02],\n",
       "                        [ 3.1014e-02,  5.5388e-02,  9.8704e-02]],\n",
       "              \n",
       "                       [[ 8.6545e-02, -8.0996e-02, -2.3636e-02],\n",
       "                        [-1.0166e-01,  3.9877e-03, -3.7229e-02],\n",
       "                        [ 9.1486e-02,  1.6666e-02,  1.1601e-03]],\n",
       "              \n",
       "                       [[-7.6248e-02, -8.2718e-02,  1.6594e-02],\n",
       "                        [-5.2376e-02, -4.8409e-02,  7.3938e-02],\n",
       "                        [-5.4952e-02, -4.6918e-02,  8.0934e-02]]]])),\n",
       "             ('conv_block_2.2.bias',\n",
       "              tensor([ 0.0412, -0.0599,  0.0319,  0.0531, -0.0936,  0.0197,  0.0241, -0.0041,\n",
       "                       0.1011, -0.0697])),\n",
       "             ('classifier.1.weight',\n",
       "              tensor([[ 0.0245, -0.0240, -0.0387,  ...,  0.0094, -0.0015, -0.0225],\n",
       "                      [ 0.0228,  0.0067, -0.0439,  ..., -0.0302,  0.0368,  0.0293],\n",
       "                      [ 0.0303,  0.0347, -0.0211,  ...,  0.0207, -0.0423, -0.0240],\n",
       "                      ...,\n",
       "                      [-0.0359, -0.0343,  0.0166,  ...,  0.0324,  0.0113, -0.0143],\n",
       "                      [-0.0294, -0.0316,  0.0251,  ..., -0.0056,  0.0300, -0.0396],\n",
       "                      [-0.0246, -0.0035, -0.0046,  ..., -0.0146, -0.0358,  0.0175]])),\n",
       "             ('classifier.1.bias',\n",
       "              tensor([ 0.0320, -0.0445,  0.0246, -0.0357, -0.0442,  0.0156, -0.0010, -0.0277,\n",
       "                       0.0404,  0.0037]))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and testing for `model_2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "155cae526457444fba81273cf72a74c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 \n",
      "---\n",
      "Train Loss:0.59121 | Train Acc: 78.49833%\n",
      "Test Loss: 0.3966, Test Acc: 85.9125%\n",
      "Epoch : 1 \n",
      "---\n",
      "Train Loss:0.36237 | Train Acc: 87.00167%\n",
      "Test Loss: 0.3484, Test Acc: 87.1006%\n",
      "Epoch : 2 \n",
      "---\n",
      "Train Loss:0.32448 | Train Acc: 88.23167%\n",
      "Test Loss: 0.3225, Test Acc: 88.2887%\n",
      "Epoch : 3 \n",
      "---\n",
      "Train Loss:0.30294 | Train Acc: 89.12333%\n",
      "Test Loss: 0.3249, Test Acc: 87.8894%\n",
      "Epoch : 4 \n",
      "---\n",
      "Train Loss:0.28887 | Train Acc: 89.46667%\n",
      "Test Loss: 0.2970, Test Acc: 89.5667%\n",
      "Epoch : 5 \n",
      "---\n",
      "Train Loss:0.27732 | Train Acc: 89.99000%\n",
      "Test Loss: 0.3094, Test Acc: 88.9377%\n",
      "Epoch : 6 \n",
      "---\n",
      "Train Loss:0.27009 | Train Acc: 90.06167%\n",
      "Test Loss: 0.2976, Test Acc: 89.4369%\n",
      "Epoch : 7 \n",
      "---\n",
      "Train Loss:0.26414 | Train Acc: 90.42500%\n",
      "Test Loss: 0.2860, Test Acc: 89.6266%\n",
      "Epoch : 8 \n",
      "---\n",
      "Train Loss:0.25628 | Train Acc: 90.62000%\n",
      "Test Loss: 0.2849, Test Acc: 89.8263%\n",
      "Epoch : 9 \n",
      "---\n",
      "Train Loss:0.25132 | Train Acc: 90.78167%\n",
      "Test Loss: 0.3079, Test Acc: 88.7580%\n",
      "Train time is 736.133 seconds\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "from timeit import default_timer as timer\n",
    "train_time_start_model_2 = timer()\n",
    "\n",
    "epochs = 10\n",
    "for epoch in tqdm(range(epochs)):\n",
    "  print(f\"Epoch : {epoch} \\n---\")\n",
    "  train_step(model = model_2, data_loader= train_dataloader, loss_fn= loss_fn, optimizer=optimizer, accuracy_fn=accuracy_fn)\n",
    "  test_step(model=model_2, data_loader= test_dataloader, loss_fn = loss_fn, accuracy_fn=accuracy_fn)\n",
    "train_time_end_model_2 = timer()\n",
    "total_train_time = print_train_time(start = train_time_start_model_2,\n",
    "                                    end = train_time_end_model_2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b7a526c9ee4871a5810134df4c0f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV2',\n",
       " 'model_loss': 0.3078635632991791,\n",
       " 'model_acc': 88.75798722044729}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_results = eval_model(model = model_2,\n",
    "                             data_loader=test_dataloader,\n",
    "                             loss_fn = loss_fn,\n",
    "                             accuracy_fn = accuracy_fn)\n",
    "\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV0',\n",
       " 'model_loss': 0.46279823780059814,\n",
       " 'model_acc': 83.64616613418531}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_loss</th>\n",
       "      <th>model_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FashionMNISTModelV0</td>\n",
       "      <td>0.462798</td>\n",
       "      <td>83.646166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FashionMNISTModelV1</td>\n",
       "      <td>0.685001</td>\n",
       "      <td>75.019968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FashionMNISTModelV2</td>\n",
       "      <td>0.307864</td>\n",
       "      <td>88.757987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name  model_loss  model_acc\n",
       "0  FashionMNISTModelV0    0.462798  83.646166\n",
       "1  FashionMNISTModelV1    0.685001  75.019968\n",
       "2  FashionMNISTModelV2    0.307864  88.757987"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "compare_results = pd.DataFrame([model_0_results,\n",
    "                                model_1_results, model_2_results])\n",
    "compare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_loss</th>\n",
       "      <th>model_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FashionMNISTModelV0</td>\n",
       "      <td>0.462798</td>\n",
       "      <td>83.646166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FashionMNISTModelV1</td>\n",
       "      <td>0.685001</td>\n",
       "      <td>75.019968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FashionMNISTModelV2</td>\n",
       "      <td>0.307864</td>\n",
       "      <td>88.757987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name  model_loss  model_acc\n",
       "0  FashionMNISTModelV0    0.462798  83.646166\n",
       "1  FashionMNISTModelV1    0.685001  75.019968\n",
       "2  FashionMNISTModelV2    0.307864  88.757987"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'model')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAr0AAAGwCAYAAACkUt2bAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9PklEQVR4nO3de1gWdf7/8RcHQUBRlNRQCAIJMQRcS4XSL+ousqhbmpkpaOBuFmbkucMumhqQUnkoKQ+g381TC7bFuppZWJCVYqglXzTPZabrATwiwvz+6Oe93oGKqKHj83Fdc13cM5/5zHs+cyWve/rMYGMYhiEAAADAxGzrugAAAADgRiP0AgAAwPQIvQAAADA9Qi8AAABMj9ALAAAA0yP0AgAAwPQIvQAAADA9+7ouALgZVFZW6sCBA2rYsKFsbGzquhwAAFADhmHoxIkT8vDwkK3t5e/lEnoBSQcOHJCnp2ddlwEAAGph//79atWq1WXbEHoBSQ0bNpT0y380rq6udVwNAACoidLSUnl6elp+j18OoReQLFMaXF1dCb0AANxiajI1kQfZAAAAYHqEXgAAAJgeoRcAAACmR+gFAACA6RF6AQAAYHqEXgAAAJgeoRcAAACmR+gFAACA6RF6AQAAYHqEXgAAAJgeoRcAAACmR+gFAACA6RF6AQAAYHqEXgAAAJgeoRcAAACmR+gFAACA6RF6AQAAYHqEXgAAAJgeoRcAAACmR+gFAACA6RF6AQAAYHqEXgAAAJgeoRcAAACmR+gFAACA6RF6AQAAYHqEXgAAAJgeoRcAAACmR+gFAACA6dnXdQHAzeTepNWydXSu6zIAADCVPSnRdV0Cd3oBAABgfoReAAAAmB6hFwAAAKZH6AUAAIDpEXoBAABgeoReAAAAmB6hFwAAAKZH6AUAAIDpEXoBAABgeoReAAAAmB6hFwAAAKZH6AUAAIDpEXoBAABgeoReAAAAmB6hFwAAAKZH6AUAAIDpEXoBAABgeoReAAAAmB6hFwAAAKZH6AUAAIDpEXoBAABgeoReAAAAmB6hFwAAAKZH6AUAAIDpEXoBAABgeqYLvbm5ubKxsdHx48cv2WbixIkKCQn5zWq6XdXkWvyat7e33njjjRtWEwAAuD3VaegdOnSobGxsqizff//9DT3umDFjtHbt2uva54WA5+bmprNnz1pt27Bhg+Xcft2+bdu2qqiosGrfuHFjZWZmWj7/Oghu3rxZffr0UbNmzVS/fn15e3trwIABOnTokCZOnFjtmF68SP8d++HDh1c5l4SEBNnY2Gjo0KHXPjC1dO7cObm7uyslJaXa7ZMnT1bz5s1VXl6u7Oxs/f73v9cdd9whV1dXde7cWatXr/6NKwYAADezOr/T27NnT/30009Wi4+Pzw09ZoMGDdS0adMb0nfDhg21YsUKq3Xz58+Xl5dXte137dqlRYsW1bj/w4cPq3v37mrSpIlWr16toqIiZWRkyMPDQ6dOndKYMWOsxrJVq1Z6+eWXrdZd4OnpqaVLl+rMmTOWdWfPntXixYsvWe9vxcHBQYMHD1ZGRkaVbYZhKDMzU7GxsapXr54+++wz/f73v9fKlStVUFCgiIgI9e7dW998800dVA4AAG5GdR56HR0d1aJFC6tlxowZCgoKkouLizw9PfX000/r5MmTln327t2r3r17y83NTS4uLmrbtq1Wrlxp1W9BQYE6dOggZ2dnhYWFqbi42LLt19MbKisr9fLLL6tVq1ZydHRUSEiIVq1aZdm+Z88e2djYKDs7WxEREXJ2dlZwcLDWr19f5XyGDBmiBQsWWD6fOXNGS5cu1ZAhQ6o9/2eeeUZJSUkqKyur0Xjl5+erpKRE8+bNU2hoqHx8fBQREaHXX39dPj4+atCggdVY2tnZqWHDhlbrLmjfvr08PT2VnZ1tWZednS0vLy+FhoZaHbesrEwjR4603F1+4IEHtGHDBqs2K1eulL+/v5ycnBQREaE9e/ZUqT8vL08PPvignJyc5OnpqZEjR+rUqVPVnmt8fLy2b9+uvLw8q/Xr1q3Trl27FB8fL0l64403NG7cON13331q3bq1XnnlFbVu3VoffvhhjcYUAACYX52H3urY2tpq5syZ+u6777Rw4UJ98sknGjdunGV7QkKCysrK9Nlnn2nr1q1KTU1VgwYNrPp48cUXlZaWpo0bN8re3l5xcXGXPN6MGTOUlpam6dOna8uWLYqMjFSfPn20Y8eOKn2OGTNGhYWF8vf318CBA3X+/HmrNjExMfr888+1b98+SVJWVpa8vb3Vvn37ao+dmJio8+fPa9asWTUamxYtWuj8+fNasWKFDMOo0T6XExcXZ3U3dcGCBXriiSeqtBs3bpyysrK0cOFCbdq0SX5+foqMjNTRo0clSfv371ffvn3Vu3dvFRYWatiwYZowYYJVHzt37lTPnj3Vr18/bdmyRcuWLVNeXp5GjBhRbW1BQUG67777rL5ESFJGRobCwsIUEBBQ7X6VlZU6ceKEmjRpcsnzLisrU2lpqdUCAADMq85Db05Ojho0aGBZ+vfvr8TEREVERMjb21vdunXTlClTtHz5css++/btU3h4uIKCgnT33XerV69e6tKli1W/U6dOVdeuXRUYGKgJEyboiy++qDLX9oLp06dr/Pjxeuyxx3TPPfcoNTVVISEhVR6oGjNmjKKjo+Xv769JkyZp7969VeYfN2vWTFFRUZY5uQsWLLhs4HZ2dlZSUpKSk5NVUlJyxfHq1KmTXnjhBT3++ONyd3dXVFSUpk2bpp9//vmK+1Zn8ODBysvL0969e7V3717l5+dr8ODBVm1OnTqlOXPmaNq0aYqKilJgYKDmzp0rJycnzZ8/X5I0Z84c+fr6Ki0tTffcc48GDRpUZU5wcnKyBg0apMTERLVu3VphYWGaOXOmFi1adMlrEx8fr/fee89yp//EiRP6xz/+cdkxnT59uk6ePKlHH330km2Sk5PVqFEjy+Lp6VmT4QIAALeoOg+9ERERKiwstCwzZ87Uxx9/rO7du6tly5Zq2LChYmJidOTIEZ0+fVqSNHLkSE2ZMkXh4eFKSkrSli1bqvTbrl07y8933nmnJOnQoUNV2pWWlurAgQMKDw+3Wh8eHq6ioqJa9RkXF6fMzEzt2rVL69ev16BBgy47BvHx8WratKlSU1Mv2+6CqVOn6uDBg0pPT1fbtm2Vnp6ugIAAbd26tUb7X+yOO+5QdHS0MjMzlZGRoejoaLm7u1u12blzp8rLy63GqF69err//vstY1RUVKSOHTta7de5c2erz5s3b1ZmZqbVl5zIyEhVVlZq9+7d1dY3cOBAVVRUWL70LFu2TLa2thowYEC17RcvXqxJkyZp+fLlatas2SXP+/nnn1dJSYll2b9//yXbAgCAW1+dh14XFxf5+flZlrKyMvXq1Uvt2rVTVlaWCgoK9Oabb0r65Yl+SRo2bJh27dqlmJgYbd26VR06dKgyPaBevXqWny+8saCysvKaaq1pn1FRUTpz5ozi4+PVu3fvKz40Z29vr6lTp2rGjBk6cOBAjWpp2rSp+vfvr+nTp6uoqEgeHh6aPn36VZzNf10I6QsXLrzsHdRrdfLkST355JNWX3I2b96sHTt2yNfXt9p9XF1d9cgjj1imYGRkZOjRRx+tMp1FkpYuXaphw4Zp+fLl6tGjx2VrcXR0lKurq9UCAADMq85D768VFBSosrJSaWlp6tSpk/z9/asNgp6enho+fLiys7M1evRozZ07t1bHc3V1lYeHh/Lz863W5+fnKzAwsFZ92tvbKzY2Vrm5uTUOkf3791fbtm01adKkqz6eg4ODfH19L/lA2JX07NlT586dU3l5uSIjI6ts9/X1lYODg9UYlZeXa8OGDZYxatOmjb7++mur/b788kurz+3bt9e2bdusvuRcWBwcHC5ZX3x8vPLy8pSTk6MvvvjC8gDbxZYsWaInnnhCS5YsUXR09FWdPwAAMD/7ui7g1/z8/FReXq5Zs2apd+/eys/PV3p6ulWbxMRERUVFyd/fX8eOHdOnn36qNm3a1PqYY8eOVVJSknx9fRUSEqKMjAwVFhbq3XffrXWfkydP1tixY6/q1WgpKSnVhs6L5eTkaOnSpXrsscfk7+8vwzD04YcfauXKldW+3qsm7OzsLNMU7Ozsqmx3cXHRU089pbFjx6pJkyby8vLSq6++qtOnT1sC6PDhw5WWlqaxY8dq2LBhKigosHrXsCSNHz9enTp10ogRIzRs2DC5uLho27ZtWrNmjWbPnn3J+rp06SI/Pz/FxsYqICBAYWFhVtsXL16sIUOGaMaMGerYsaMOHjwoSXJyclKjRo1qNSYAAMBcbro7vcHBwXrttdeUmpqqe++9V++++66Sk5Ot2lRUVCghIUFt2rRRz5495e/vr7feeqvWxxw5cqRGjRql0aNHKygoSKtWrdIHH3yg1q1b17pPBwcHubu7W/1Biivp1q2bunXrVuWNEBcLDAyUs7OzRo8erZCQEHXq1EnLly/XvHnzFBMTU+t6r/S/+FNSUtSvXz/FxMSoffv2+v7777V69Wq5ublJkry8vJSVlaX3339fwcHBSk9P1yuvvGLVR7t27bRu3Tpt375dDz74oEJDQ/W3v/1NHh4el63NxsZGcXFxOnbsWLV3zt955x2dP39eCQkJuvPOOy3Ls88+W4uRAAAAZmRjXI/3XgG3uNLS0l/e4pC4XLaOznVdDgAAprIn5cZMPbzw+7ukpOSKz+fcdHd6AQAAgOuN0AsAAADTI/QCAADA9Ai9AAAAMD1CLwAAAEyP0AsAAADTI/QCAADA9Ai9AAAAMD1CLwAAAEyP0AsAAADTI/QCAADA9Ai9AAAAMD1CLwAAAEyP0AsAAADTI/QCAADA9Ai9AAAAMD1CLwAAAEyP0AsAAADTI/QCAADA9Ai9AAAAMD1CLwAAAEyP0AsAAADTI/QCAADA9Ai9AAAAMD37ui4AuJl8OylSrq6udV0GAAC4zrjTCwAAANMj9AIAAMD0CL0AAAAwPUIvAAAATI/QCwAAANMj9AIAAMD0CL0AAAAwPUIvAAAATI/QCwAAANMj9AIAAMD0CL0AAAAwPUIvAAAATI/QCwAAANMj9AIAAMD0CL0AAAAwPUIvAAAATI/QCwAAANMj9AIAAMD0CL0AAAAwPUIvAAAATI/QCwAAANMj9AIAAMD0CL0AAAAwPUIvAAAATI/QCwAAANMj9AIAAMD0CL0AAAAwPUIvAAAATI/QCwAAANMj9AIAAMD0CL0AAAAwPUIvAAAATI/QCwAAANMj9AIAAMD0CL0AAAAwPUIvAAAATI/QCwAAANMj9AIAAMD0CL0AAAAwPUIvAAAATI/QCwAAANMj9AIAAMD0CL0AAAAwPUIvAAAATI/QCwAAANMj9AIAAMD0CL0AAAAwPUIvAAAATI/QCwAAANMj9AIAAMD0CL0AAAAwPUIvAAAATI/QCwAAANMj9AIAAMD0CL0AAAAwPUIvAAAATI/QCwAAANMj9AIAAMD0CL0AAAAwPUIvAAAATM++rgsAbib3Jq2WraNzXZcBALiF7EmJrusSUAPc6QUAAIDpEXoBAABgeoReAAAAmB6hFwAAAKZH6AUAAIDpEXoBAABgeoReAAAAmB6hFwAAAKZH6AUAAIDpEXoBAABgeoReAAAAmB6hFwAAAKZH6AUAAIDp2de0oZubm2xsbGrU9ujRo7UuCAAAALjeahx633jjjRtYBgAAAHDj1Dj0Dhky5EbWAQAAANwwtZ7Tu3PnTr300ksaOHCgDh06JEn697//re++++66FQcAAABcD7UKvevWrVNQUJC++uorZWdn6+TJk5KkzZs3Kykp6boWCAAAAFyrWoXeCRMmaMqUKVqzZo0cHBws67t166Yvv/zyuhUHAAAAXA+1Cr1bt27Vww8/XGV9s2bN9J///OeaiwIAAACup1qF3saNG+unn36qsv6bb75Ry5Ytr7koAAAA4HqqVeh97LHHNH78eB08eFA2NjaqrKxUfn6+xowZo9jY2OtdIwAAAHBNahV6X3nlFQUEBMjT01MnT55UYGCgunTporCwML300kvXu0YAAADgmtT4Pb0Xc3Bw0Ny5c/XXv/5V3377rU6ePKnQ0FC1bt36etcHAAAAXLNahd4LvLy85OXldb1qAQAAAG6IGofeUaNG1bjT1157rVbFXA+5ubmKiIjQsWPH1Lhx42rbTJw4Ue+//74KCwt/09puNzW5Fr/m7e2txMREJSYm3tDaAADA7aXGc3q/+eYbq2X+/Pl6++23lZubq9zcXL3zzjuaP3/+VQXJoUOHysbGpsry/fff1+ZcamzMmDFau3btde0zNzdXNjY2cnNz09mzZ622bdiwwXJuv27ftm1bVVRUWLVv3LixMjMzLZ+9vb31xhtvWD5v3rxZffr0UbNmzVS/fn15e3trwIABOnTokCZOnFjtmF68SP8d++HDh1c5l4SEBNnY2Gjo0KHXPjC1dO7cObm7uyslJaXa7ZMnT1bz5s1VXl6un376SY8//rj8/f1la2tLYAYAAFXUOPR++umnlqV3797q2rWrfvjhB23atEmbNm3S/v37FRERoejo6KsqoGfPnvrpp5+sFh8fn6s+kavRoEEDNW3a9Ib03bBhQ61YscJq3fz58y85DWTXrl1atGhRjfs/fPiwunfvriZNmmj16tUqKipSRkaGPDw8dOrUKY0ZM8ZqLFu1aqWXX37Zat0Fnp6eWrp0qc6cOWNZd/bsWS1evLjOp604ODho8ODBysjIqLLNMAxlZmYqNjZW9erVU1lZme644w699NJLCg4OroNqAQDAza5Wb29IS0tTcnKy3NzcLOvc3Nw0ZcoUpaWlXVVfjo6OatGihdUyY8YMBQUFycXFRZ6ennr66actf+pYkvbu3avevXvLzc1NLi4uatu2rVauXGnVb0FBgTp06CBnZ2eFhYWpuLjYsm3ixIkKCQmxfK6srNTLL7+sVq1aydHRUSEhIVq1apVl+549e2RjY6Ps7GxFRETI2dlZwcHBWr9+fZXzGTJkiBYsWGD5fObMGS1dulRDhgyp9vyfeeYZJSUlqaysrEbjlZ+fr5KSEs2bN0+hoaHy8fFRRESEXn/9dfn4+KhBgwZWY2lnZ6eGDRtarbugffv28vT0VHZ2tmVddna2vLy8FBoaanXcsrIyjRw50nJ3+YEHHtCGDRus2qxcuVL+/v5ycnJSRESE9uzZU6X+vLw8Pfjgg3JycpKnp6dGjhypU6dOVXuu8fHx2r59u/Ly8qzWr1u3Trt27VJ8fLykX+6Ez5gxQ7GxsWrUqFGNxhEAANxeahV6S0tLdfjw4SrrDx8+rBMnTlx7Uba2mjlzpr777jstXLhQn3zyicaNG2fZnpCQoLKyMn322WfaunWrUlNT1aBBA6s+XnzxRaWlpWnjxo2yt7dXXFzcJY83Y8YMpaWlafr06dqyZYsiIyPVp08f7dixo0qfY8aMUWFhofz9/TVw4ECdP3/eqk1MTIw+//xz7du3T5KUlZUlb29vtW/fvtpjJyYm6vz585o1a1aNxqZFixY6f/68VqxYIcMwarTP5cTFxVndTV2wYIGeeOKJKu3GjRunrKwsLVy4UJs2bZKfn58iIyN19OhRSdL+/fvVt29f9e7dW4WFhRo2bJgmTJhg1cfOnTvVs2dP9evXT1u2bNGyZcuUl5enESNGVFtbUFCQ7rvvPqsvEZKUkZGhsLAwBQQE1Pq8y8rKVFpaarUAAADzqlXoffjhh/XEE08oOztbP/zwg3744QdlZWUpPj5effv2vaq+cnJy1KBBA8vSv39/JSYmKiIiQt7e3urWrZumTJmi5cuXW/bZt2+fwsPDFRQUpLvvvlu9evVSly5drPqdOnWqunbtqsDAQE2YMEFffPFFlbm2F0yfPl3jx4/XY489pnvuuUepqakKCQmxmkcr/TIXODo6Wv7+/po0aZL27t1bZf5xs2bNFBUVZZmTu2DBgssGbmdnZyUlJSk5OVklJSVXHK9OnTrphRde0OOPPy53d3dFRUVp2rRp+vnnn6+4b3UGDx6svLw87d27V3v37lV+fr4GDx5s1ebUqVOaM2eOpk2bpqioKAUGBmru3LlycnLS/PnzJUlz5syRr6+v0tLSdM8992jQoEFV5gQnJydr0KBBSkxMVOvWrRUWFqaZM2dq0aJFl7w28fHxeu+99yx3+k+cOKF//OMflx3TmkhOTlajRo0si6en5zX1BwAAbm61Cr3p6emKiorS448/rrvuukt33XWXHn/8cfXs2VNvvfXWVfUVERGhwsJCyzJz5kx9/PHH6t69u1q2bKmGDRsqJiZGR44c0enTpyVJI0eO1JQpUxQeHq6kpCRt2bKlSr/t2rWz/HznnXdKkg4dOlSlXWlpqQ4cOKDw8HCr9eHh4SoqKqpVn3FxccrMzNSuXbu0fv16DRo06LJjEB8fr6ZNmyo1NfWy7S6YOnWqDh48qPT0dLVt21bp6ekKCAjQ1q1ba7T/xe644w5FR0crMzNTGRkZio6Olru7u1WbnTt3qry83GqM6tWrp/vvv98yRkVFRerYsaPVfp07d7b6vHnzZmVmZlp9yYmMjFRlZaV2795dbX0DBw5URUWF5UvPsmXLZGtrqwEDBlz1uV7s+eefV0lJiWXZv3//NfUHAABubrUKvc7Oznrrrbd05MgRy9scjh49qrfeeksuLi5X1ZeLi4v8/PwsS1lZmXr16qV27dopKytLBQUFevPNNyX98kS/JA0bNky7du1STEyMtm7dqg4dOlSZHlCvXj3LzxfeWFBZWVmb073qPqOionTmzBnFx8erd+/eV3xozt7eXlOnTtWMGTN04MCBGtXStGlT9e/fX9OnT1dRUZE8PDw0ffr0qzib/7oQ0hcuXHjNd1Av5+TJk3ryySetvuRs3rxZO3bskK+vb7X7uLq66pFHHrFMwcjIyNCjjz5aZTrL1XJ0dJSrq6vVAgAAzKtWofcCFxcXNWnSRE2aNLnqsHspBQUFqqysVFpamjp16iR/f/9qg6Cnp6eGDx+u7OxsjR49WnPnzq3V8VxdXeXh4aH8/Hyr9fn5+QoMDKxVn/b29oqNjVVubm6NQ2T//v3Vtm1bTZo06aqP5+DgIF9f30s+EHYlPXv21Llz51ReXq7IyMgq2319feXg4GA1RuXl5dqwYYNljNq0aaOvv/7aar8vv/zS6nP79u21bds2qy85FxYHB4dL1hcfH6+8vDzl5OToiy++sDzABgAAUFO1Cr0X3nbQqFEjy/SGxo0ba/Lkydd8N9XPz0/l5eWaNWuWdu3apf/93/9Venq6VZvExEStXr1au3fv1qZNm/Tpp5+qTZs2tT7m2LFjlZqaqmXLlqm4uFgTJkxQYWGhnn322Vr3OXnyZB0+fLjaEHkpKSkpWrBgwWXDa05OjgYPHqycnBxt375dxcXFmj59ulauXKk//elPtarVzs5ORUVF2rZtm+zs7Kpsd3Fx0VNPPaWxY8dq1apV2rZtm/785z/r9OnTlgA6fPhw7dixQ2PHjlVxcbEWL15s9a5hSRo/fry++OILjRgxQoWFhdqxY4f++c9/XvJBtgu6dOkiPz8/xcbGKiAgQGFhYVXaXLhzfPLkSR0+fFiFhYXatm1brcYDAACYT63+DPGLL76o+fPnKyUlxTLPMy8vTxMnTtTZs2c1derUWhcUHBys1157TampqXr++efVpUsXJScnKzY21tKmoqJCCQkJ+uGHH+Tq6qqePXvq9ddfr/UxR44cqZKSEo0ePVqHDh1SYGCgPvjgA7Vu3brWfTo4OFSZG3sl3bp1U7du3fTRRx9dsk1gYKCcnZ01evRo7d+/X46OjmrdurXmzZunmJiYWtd7pf+9n5KSosrKSsXExOjEiRPq0KGDVq9ebXltnZeXl7KysvTcc89p1qxZuv/++/XKK69Y3elu166d1q1bpxdffFEPPvigDMOQr6/vFefn2tjYKC4uTi+88IKef/75attc/Iq1goICLV68WHfddVe1r00DAAC3HxujFu+98vDwUHp6uvr06WO1/p///Keefvpp/fjjj9etQOC3UFpa+stbHBKXy9bRua7LAQDcQvakXN0f5sL1c+H3d0lJyRVv4NVqesPRo0erfUdqQECA5b2tAAAAwM2iVqE3ODhYs2fPrrJ+9uzZ/BlYAAAA3HRqNaf31VdfVXR0tD7++GPLu1jXr1+vffv26d///vd1LRAAAAC4VrW609u1a1cVFxerb9++On78uI4fP66+fftq+/btevDBB693jQAAAMA1qdWdXumXP47Qp08fderUyfKaso0bN0pSlQfcAAAAgLpUq9C7atUqxcbG6siRI/r1yx9sbGxUUVFxXYoDAAAArodaTW945pln1L9/fx04cECVlZVWC4EXAAAAN5tahd6ff/5Zo0aNUvPmza93PQAAAMB1V6vQ+8gjjyg3N/c6lwIAAADcGLWa0zt79mz1799fn3/+uYKCglSvXj2r7SNHjrwuxQEAAADXQ61C75IlS/TRRx+pfv36ys3NlY2NjWWbjY0NoRcAAAA3lVqF3hdffFGTJk3ShAkTZGtbqxkSAAAAwG+mVon13LlzGjBgAIEXAAAAt4RapdYhQ4Zo2bJl17sWAAAA4Iao1fSGiooKvfrqq1q9erXatWtX5UG211577boUBwAAAFwPtQq9W7duVWhoqCTp22+/tdp28UNtAAAAwM2gVqH3008/vd51AAAAADcMT6IBAADA9Ai9AAAAMD1CLwAAAEyP0AsAAADTI/QCAADA9Ai9AAAAMD1CLwAAAEyvVu/pBczq20mRcnV1resyAADAdcadXgAAAJgeoRcAAACmR+gFAACA6RF6AQAAYHqEXgAAAJgeoRcAAACmR+gFAACA6RF6AQAAYHqEXgAAAJgeoRcAAACmR+gFAACA6RF6AQAAYHqEXgAAAJgeoRcAAACmR+gFAACA6RF6AQAAYHqEXgAAAJgeoRcAAACmR+gFAACA6RF6AQAAYHqEXgAAAJgeoRcAAACmR+gFAACA6RF6AQAAYHqEXgAAAJgeoRcAAACmR+gFAACA6RF6AQAAYHqEXgAAAJgeoRcAAACmR+gFAACA6RF6AQAAYHqEXgAAAJgeoRcAAACmR+gFAACA6RF6AQAAYHqEXgAAAJgeoRcAAACmR+gFAACA6RF6AQAAYHqEXgAAAJgeoRcAAACmR+gFAACA6RF6AQAAYHqEXgAAAJgeoRcAAACmR+gFAACA6RF6AQAAYHqEXgAAAJgeoRcAAACmR+gFAACA6RF6AQAAYHqEXgAAAJgeoRcAAACmR+gFAACA6RF6AQAAYHqEXgAAAJgeoRcAAACmR+gFAACA6RF6AQAAYHr2dV0AcDO5N2m1bB2d67oMAABuuD0p0XVdwm+KO70AAAAwPUIvAAAATI/QCwAAANMj9AIAAMD0CL0AAAAwPUIvAAAATI/QCwAAANMj9AIAAMD0CL0AAAAwPUIvAAAATI/QCwAAANMj9AIAAMD0CL0AAAAwPUIvAAAATI/QCwAAANMj9AIAAMD0CL0AAAAwPUIvAAAATI/QCwAAANMj9AIAAMD0CL0AAAAwPUIvAAAATI/QCwAAANMj9AIAAMD0CL0AAAAwPUIvAAAATM90oTc3N1c2NjY6fvz4JdtMnDhRISEhv1lNt6uaXItf8/b21htvvHHDagIAALenOg29Q4cOlY2NTZXl+++/v6HHHTNmjNauXXtd+7wQ8Nzc3HT27FmrbRs2bLCc26/bt23bVhUVFVbtGzdurMzMTMvnXwfBzZs3q0+fPmrWrJnq168vb29vDRgwQIcOHdLEiROrHdOLF+m/Yz98+PAq55KQkCAbGxsNHTr02gemls6dOyd3d3elpKRUu33y5Mlq3ry5ysvLJf0ynu3bt5ejo6P8/Pysxg8AAKDO7/T27NlTP/30k9Xi4+NzQ4/ZoEEDNW3a9Ib03bBhQ61YscJq3fz58+Xl5VVt+127dmnRokU17v/w4cPq3r27mjRpotWrV6uoqEgZGRny8PDQqVOnNGbMGKuxbNWqlV5++WWrdRd4enpq6dKlOnPmjGXd2bNntXjx4kvW+1txcHDQ4MGDlZGRUWWbYRjKzMxUbGys6tWrp927dys6OloREREqLCxUYmKihg0bptWrV9dB5QAA4GZU56HX0dFRLVq0sFpmzJihoKAgubi4yNPTU08//bROnjxp2Wfv3r3q3bu33Nzc5OLiorZt22rlypVW/RYUFKhDhw5ydnZWWFiYiouLLdt+Pb2hsrJSL7/8slq1aiVHR0eFhIRo1apVlu179uyRjY2NsrOzFRERIWdnZwUHB2v9+vVVzmfIkCFasGCB5fOZM2e0dOlSDRkypNrzf+aZZ5SUlKSysrIajVd+fr5KSko0b948hYaGysfHRxEREXr99dfl4+OjBg0aWI2lnZ2dGjZsaLXugvbt28vT01PZ2dmWddnZ2fLy8lJoaKjVccvKyjRy5EjL3eUHHnhAGzZssGqzcuVK+fv7y8nJSREREdqzZ0+V+vPy8vTggw/KyclJnp6eGjlypE6dOlXtucbHx2v79u3Ky8uzWr9u3Trt2rVL8fHxkqT09HT5+PgoLS1Nbdq00YgRI/TII4/o9ddfv+Q4lpWVqbS01GoBAADmVeehtzq2traaOXOmvvvuOy1cuFCffPKJxo0bZ9mekJCgsrIyffbZZ9q6datSU1PVoEEDqz5efPFFpaWlaePGjbK3t1dcXNwljzdjxgylpaVp+vTp2rJliyIjI9WnTx/t2LGjSp9jxoxRYWGh/P39NXDgQJ0/f96qTUxMjD7//HPt27dPkpSVlSVvb2+1b9++2mMnJibq/PnzmjVrVo3GpkWLFjp//rxWrFghwzBqtM/lxMXFWd1NXbBggZ544okq7caNG6esrCwtXLhQmzZtkp+fnyIjI3X06FFJ0v79+9W3b1/17t1bhYWFGjZsmCZMmGDVx86dO9WzZ0/169dPW7Zs0bJly5SXl6cRI0ZUW1tQUJDuu+8+qy8RkpSRkaGwsDAFBARIktavX68ePXpYtYmMjKz2S8kFycnJatSokWXx9PS8zCgBAIBbXZ2H3pycHDVo0MCy9O/fX4mJiYqIiJC3t7e6deumKVOmaPny5ZZ99u3bp/DwcAUFBenuu+9Wr1691KVLF6t+p06dqq5duyowMFATJkzQF198UWWu7QXTp0/X+PHj9dhjj+mee+5RamqqQkJCqjxQNWbMGEVHR8vf31+TJk3S3r17q8w/btasmaKioixzShcsWHDZwO3s7KykpCQlJyerpKTkiuPVqVMnvfDCC3r88cfl7u6uqKgoTZs2TT///PMV963O4MGDlZeXp71792rv3r3Kz8/X4MGDrdqcOnVKc+bM0bRp0xQVFaXAwEDNnTtXTk5Omj9/viRpzpw58vX1VVpamu655x4NGjSoypzg5ORkDRo0SImJiWrdurXCwsI0c+ZMLVq06JLXJj4+Xu+9957lTv+JEyf0j3/8w2pMDx48qObNm1vt17x5c5WWllpN3bjY888/r5KSEsuyf//+qxo3AABwa6nz0HthHuaFZebMmfr444/VvXt3tWzZUg0bNlRMTIyOHDmi06dPS5JGjhypKVOmKDw8XElJSdqyZUuVftu1a2f5+c4775QkHTp0qEq70tJSHThwQOHh4Vbrw8PDVVRUVKs+4+LilJmZqV27dmn9+vUaNGjQZccgPj5eTZs2VWpq6mXbXTB16lQdPHhQ6enpatu2rdLT0xUQEKCtW7fWaP+L3XHHHYqOjlZmZqYyMjIUHR0td3d3qzY7d+5UeXm51RjVq1dP999/v2WMioqK1LFjR6v9OnfubPV58+bNyszMtPqSExkZqcrKSu3evbva+gYOHKiKigrLl55ly5bJ1tZWAwYMuOpzvZijo6NcXV2tFgAAYF51HnpdXFzk5+dnWcrKytSrVy+1a9dOWVlZKigo0Jtvvinplyf6JWnYsGHatWuXYmJitHXrVnXo0KHK9IB69epZfr7wxoLKysprqrWmfUZFRenMmTOKj49X7969r/jQnL29vaZOnaoZM2bowIEDNaqladOm6t+/v6ZPn66ioiJ5eHho+vTpV3E2/3UhpC9cuPCyd6Wv1cmTJ/Xkk09afcnZvHmzduzYIV9f32r3cXV11SOPPGKZgpGRkaFHH33UajpLixYtqtzp/vnnn+Xq6ionJ6cbdj4AAODWUeeh99cKCgpUWVmptLQ0derUSf7+/tUGQU9PTw0fPlzZ2dkaPXq05s6dW6vjubq6ysPDQ/n5+Vbr8/PzFRgYWKs+7e3tFRsbq9zc3BqHyP79+6tt27aaNGnSVR/PwcFBvr6+l3wg7Ep69uypc+fOqby8XJGRkVW2+/r6ysHBwWqMysvLtWHDBssYtWnTRl9//bXVfl9++aXV5/bt22vbtm1WX3IuLA4ODpesLz4+Xnl5ecrJydEXX3xheYDtgs6dO1d5Bd2aNWuq3GkGAAC3L/u6LuDX/Pz8VF5erlmzZql3797Kz89Xenq6VZvExERFRUXJ399fx44d06effqo2bdrU+phjx45VUlKSfH19FRISooyMDBUWFurdd9+tdZ+TJ0/W2LFjr+rVaCkpKdWGzovl5ORo6dKleuyxx+Tv7y/DMPThhx9q5cqV1b7eqybs7Ows0xTs7OyqbHdxcdFTTz2lsWPHqkmTJvLy8tKrr76q06dPWwLo8OHDlZaWprFjx2rYsGEqKCio8q7c8ePHq1OnThoxYoSGDRsmFxcXbdu2TWvWrNHs2bMvWV+XLl3k5+en2NhYBQQEKCwszGr78OHDNXv2bI0bN05xcXH65JNPtHz5cv3rX/+q1XgAAADzuenu9AYHB+u1115Tamqq7r33Xr377rtKTk62alNRUaGEhAS1adNGPXv2lL+/v956661aH3PkyJEaNWqURo8eraCgIK1atUoffPCBWrduXes+HRwc5O7ubvUHKa6kW7du6tatW5U3QlwsMDBQzs7OGj16tEJCQtSpUyctX75c8+bNU0xMTK3rvdK81pSUFPXr108xMTFq3769vv/+e61evVpubm6SJC8vL2VlZen9999XcHCw0tPT9corr1j10a5dO61bt07bt2/Xgw8+qNDQUP3tb3+Th4fHZWuzsbFRXFycjh07Vu2dcx8fH/3rX//SmjVrFBwcrLS0NM2bN++KXyAAAMDtw8a4Hu+9Am5xpaWlv7y6LHG5bB2d67ocAABuuD0p0XVdwjW78Pu7pKTkig+l33R3egEAAIDrjdALAAAA0yP0AgAAwPQIvQAAADA9Qi8AAABMj9ALAAAA0yP0AgAAwPQIvQAAADA9Qi8AAABMj9ALAAAA0yP0AgAAwPQIvQAAADA9Qi8AAABMj9ALAAAA0yP0AgAAwPQIvQAAADA9Qi8AAABMj9ALAAAA0yP0AgAAwPQIvQAAADA9Qi8AAABMj9ALAAAA0yP0AgAAwPTs67oA4Gby7aRIubq61nUZAADgOuNOLwAAAEyP0AsAAADTI/QCAADA9Ai9AAAAMD1CLwAAAEyP0AsAAADTI/QCAADA9Ai9AAAAMD1CLwAAAEyP0AsAAADTI/QCAADA9Ai9AAAAMD1CLwAAAEyP0AsAAADTI/QCAADA9Ai9AAAAMD1CLwAAAEyP0AsAAADTI/QCAADA9Ai9AAAAMD1CLwAAAEyP0AsAAADTI/QCAADA9Ai9AAAAMD1CLwAAAEyP0AsAAADTI/QCAADA9Ai9AAAAMD1CLwAAAEzPvq4LAG4GhmFIkkpLS+u4EgAAUFMXfm9f+D1+OYReQNKRI0ckSZ6ennVcCQAAuFonTpxQo0aNLtuG0AtIatKkiSRp3759V/yPBnWrtLRUnp6e2r9/v1xdXeu6HFwC1+nWwbW6NXCdqmcYhk6cOCEPD48rtiX0ApJsbX+Z3t6oUSP+MblFuLq6cq1uAVynWwfX6tbAdaqqpjereJANAAAApkfoBQAAgOkRegFJjo6OSkpKkqOjY12XgivgWt0auE63Dq7VrYHrdO1sjJq84wEAAAC4hXGnFwAAAKZH6AUAAIDpEXoBAABgeoReAAAAmB6hF5D05ptvytvbW/Xr11fHjh319ddf13VJt7Xk5GTdd999atiwoZo1a6aHHnpIxcXFVm3Onj2rhIQENW3aVA0aNFC/fv30888/11HFkKSUlBTZ2NgoMTHRso7rdPP48ccfNXjwYDVt2lROTk4KCgrSxo0bLdsNw9Df/vY33XnnnXJyclKPHj20Y8eOOqz49lNRUaG//vWv8vHxkZOTk3x9fTV58mRd/M4BrlPtEXpx21u2bJlGjRqlpKQkbdq0ScHBwYqMjNShQ4fqurTb1rp165SQkKAvv/xSa9asUXl5uf7whz/o1KlTljbPPfecPvzwQ7333ntat26dDhw4oL59+9Zh1be3DRs26O2331a7du2s1nOdbg7Hjh1TeHi46tWrp3//+9/atm2b0tLS5ObmZmnz6quvaubMmUpPT9dXX30lFxcXRUZG6uzZs3VY+e0lNTVVc+bM0ezZs1VUVKTU1FS9+uqrmjVrlqUN1+kaGMBt7v777zcSEhIsnysqKgwPDw8jOTm5DqvCxQ4dOmRIMtatW2cYhmEcP37cqFevnvHee+9Z2hQVFRmSjPXr19dVmbetEydOGK1btzbWrFljdO3a1Xj22WcNw+A63UzGjx9vPPDAA5fcXllZabRo0cKYNm2aZd3x48cNR0dHY8mSJb9FiTAMIzo62oiLi7Na17dvX2PQoEGGYXCdrhV3enFbO3funAoKCtSjRw/LOltbW/Xo0UPr16+vw8pwsZKSEklSkyZNJEkFBQUqLy+3um4BAQHy8vLiutWBhIQERUdHW10Piet0M/nggw/UoUMH9e/fX82aNVNoaKjmzp1r2b57924dPHjQ6lo1atRIHTt25Fr9hsLCwrR27Vpt375dkrR582bl5eUpKipKEtfpWtnXdQFAXfrPf/6jiooKNW/e3Gp98+bN9X//9391VBUuVllZqcTERIWHh+vee++VJB08eFAODg5q3LixVdvmzZvr4MGDdVDl7Wvp0qXatGmTNmzYUGUb1+nmsWvXLs2ZM0ejRo3SCy+8oA0bNmjkyJFycHDQkCFDLNejun8LuVa/nQkTJqi0tFQBAQGys7NTRUWFpk6dqkGDBkkS1+kaEXoB3NQSEhL07bffKi8vr65Lwa/s379fzz77rNasWaP69evXdTm4jMrKSnXo0EGvvPKKJCk0NFTffvut0tPTNWTIkDquDhcsX75c7777rhYvXqy2bduqsLBQiYmJ8vDw4DpdB0xvwG3N3d1ddnZ2VZ4m//nnn9WiRYs6qgoXjBgxQjk5Ofr000/VqlUry/oWLVro3LlzOn78uFV7rttvq6CgQIcOHVL79u1lb28ve3t7rVu3TjNnzpS9vb2aN2/OdbpJ3HnnnQoMDLRa16ZNG+3bt0+SLNeDfwvr1tixYzVhwgQ99thjCgoKUkxMjJ577jklJydL4jpdK0IvbmsODg763e9+p7Vr11rWVVZWau3atercuXMdVnZ7MwxDI0aM0IoVK/TJJ5/Ix8fHavvvfvc71atXz+q6FRcXa9++fVy331D37t21detWFRYWWpYOHTpo0KBBlp+5TjeH8PDwKq/92759u+666y5Jko+Pj1q0aGF1rUpLS/XVV19xrX5Dp0+flq2tdTSzs7NTZWWlJK7TNavrJ+mAurZ06VLD0dHRyMzMNLZt22b85S9/MRo3bmwcPHiwrku7bT311FNGo0aNjNzcXOOnn36yLKdPn7a0GT58uOHl5WV88sknxsaNG43OnTsbnTt3rsOqYRiG1dsbDIPrdLP4+uuvDXt7e2Pq1KnGjh07jHfffddwdnY2/v73v1vapKSkGI0bNzb++c9/Glu2bDH+9Kc/GT4+PsaZM2fqsPLby5AhQ4yWLVsaOTk5xu7du43s7GzD3d3dGDdunKUN16n2CL2AYRizZs0yvLy8DAcHB+P+++83vvzyy7ou6bYmqdolIyPD0ubMmTPG008/bbi5uRnOzs7Gww8/bPz00091VzQMw6gaerlON48PP/zQuPfeew1HR0cjICDAeOedd6y2V1ZWGn/961+N5s2bG46Ojkb37t2N4uLiOqr29lRaWmo8++yzhpeXl1G/fn3j7rvvNl588UWjrKzM0obrVHs2hnHRn/kAAAAATIg5vQAAADA9Qi8AAABMj9ALAAAA0yP0AgAAwPQIvQAAADA9Qi8AAABMj9ALAAAA0yP0AgAAwPQIvQAAXKPi4mK1aNFCJ06cqHUf27ZtU6tWrXTq1KnrWBmACwi9AIBaWb9+vezs7BQdHV3XpdS5559/Xs8884waNmwoSdqzZ4+6dOkiFxcXdenSRXv27LFq36tXL2VlZVmtCwwMVKdOnfTaa6/9VmUDtxVCLwCgVubPn69nnnlGn332mQ4cOFCntZw7d67Ojr1v3z7l5ORo6NChlnWjR49Wy5YtVVhYqDvvvFNjxoyxbFu2bJlsbW3Vr1+/Kn098cQTmjNnjs6fP/9blA7cVgi9AICrdvLkSS1btkxPPfWUoqOjlZmZWaXNhx9+qPvuu0/169eXu7u7Hn74Ycu2srIyjR8/Xp6ennJ0dJSfn5/mz58vScrMzFTjxo2t+nr//fdlY2Nj+Txx4kSFhIRo3rx58vHxUf369SVJq1at0gMPPKDGjRuradOm6tWrl3bu3GnV1w8//KCBAweqSZMmcnFxUYcOHfTVV19pz549srW11caNG63av/HGG7rrrrtUWVlZ7VgsX75cwcHBatmypWVdUVGRhgwZotatW2vo0KEqKiqSJB0/flwvvfSS3nzzzWr7+v3vf6+jR49q3bp11W4HUHuEXgDAVVu+fLkCAgJ0zz33aPDgwVqwYIEMw7Bs/9e//qWHH35Yf/zjH/XNN99o7dq1uv/++y3bY2NjtWTJEs2cOVNFRUV6++231aBBg6uq4fvvv1dWVpays7NVWFgoSTp16pRGjRqljRs3au3atbK1tdXDDz9sCawnT55U165d9eOPP+qDDz7Q5s2bNW7cOFVWVsrb21s9evRQRkaG1XEyMjI0dOhQ2dpW/yvz888/V4cOHazWBQcH6+OPP1ZlZaU++ugjtWvXTpI0duxYJSQkyNPTs9q+HBwcFBISos8///yqxgJADRgAAFylsLAw44033jAMwzDKy8sNd3d349NPP7Vs79y5szFo0KBq9y0uLjYkGWvWrKl2e0ZGhtGoUSOrdStWrDAu/pWVlJRk1KtXzzh06NBl6zx8+LAhydi6dathGIbx9ttvGw0bNjSOHDlSbftly5YZbm5uxtmzZw3DMIyCggLDxsbG2L179yWPERwcbLz88stW63744QcjOjra8PT0NKKjo40ffvjBWLdundGhQwfjyJEjRv/+/Q0fHx/jySefNMrKyqz2ffjhh42hQ4de9rwAXD3u9AIArkpxcbG+/vprDRw4UJJkb2+vAQMGWKYnSFJhYaG6d+9e7f6FhYWys7NT165dr6mOu+66S3fccYfVuh07dmjgwIG6++675erqKm9vb0m/zLu9cOzQ0FA1adKk2j4feugh2dnZacWKFZJ+mWoRERFh6ac6Z86csUyvuKBly5bKycmxzPd1d3fX008/rfT0dE2ZMkUNGzZUcXGxduzYobfffttqXycnJ50+ffpqhgJADRB6AQBXZf78+Tp//rw8PDxkb28ve3t7zZkzR1lZWSopKZH0S3C7lMttkyRbW1urqRKSVF5eXqWdi4tLlXW9e/fW0aNHNXfuXH311Vf66quvJP33QbcrHdvBwUGxsbHKyMjQuXPntHjxYsXFxV12H3d3dx07duyybV555RX94Q9/0O9+9zvl5uaqX79+qlevnvr27avc3FyrtkePHq0S5gFcO0IvAKDGzp8/r0WLFiktLU2FhYWWZfPmzfLw8NCSJUskSe3atdPatWur7SMoKEiVlZWXfFjrjjvu0IkTJ6zeV3thzu7lHDlyRMXFxXrppZfUvXt3tWnTpkoYbdeunQoLC3X06NFL9jNs2DB9/PHHeuutt3T+/Hn17dv3sscNDQ3Vtm3bLrm9qKhIixcv1uTJkyVJFRUVlhBfXl6uiooKq/bffvutQkNDL3tMAFeP0AsAqLGcnBwdO3ZM8fHxuvfee62Wfv36WaY4JCUlacmSJUpKSlJRUZG2bt2q1NRUSZK3t7eGDBmiuLg4vf/++9q9e7dyc3O1fPlySVLHjh3l7OysF154QTt37tTixYurfTvEr7m5ualp06Z655139P333+uTTz7RqFGjrNoMHDhQLVq00EMPPaT8/Hzt2rVLWVlZWr9+vaVNmzZt1KlTJ40fP14DBw684t3hyMhIrV+/vkp4lSTDMPSXv/xFr7/+uuXOdHh4uObOnauioiItWrRI4eHhlvZ79uzRjz/+qB49elzxfAFcHUIvAKDG5s+frx49eqhRo0ZVtvXr108bN27Uli1b9D//8z9677339MEHHygkJETdunXT119/bWk7Z84cPfLII3r66acVEBCgP//5z5Y7u02aNNHf//53rVy5UkFBQVqyZIkmTpx4xdpsbW21dOlSFRQU6N5779Vzzz2nadOmWbVxcHDQRx99pGbNmumPf/yjgoKClJKSIjs7O6t28fHxOnfu3BWnNkhSVFSU7O3t9fHHH1fZ9s4776h58+bq1auXZd3EiRN19uxZdezYUX5+fkpISLBsW7Jkif7whz/orrvuuuJxAVwdG+PXE6cAALjNTZ48We+99562bNlSo/ZvvvmmPvjgA61evbrWxzx37pxat26txYsXW939BXB92Nd1AQAA3CxOnjypPXv2aPbs2ZoyZUqN93vyySd1/PhxnThxwvKniK/Wvn379MILLxB4gRuEO70AAPx/Q4cO1ZIlS/TQQw9p8eLFVaY9ALh1EXoBAABgejzIBgAAANMj9AIAAMD0CL0AAAAwPUIvAAAATI/QCwAAANMj9AIAAMD0CL0AAAAwPUIvAAAATO//AbHBZG6Tj+qEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_results.set_index(\"model_name\")[\"model_acc\"].plot(kind = \"barh\")\n",
    "plt.xlabel(\"Accuracy (%)\")\n",
    "plt.ylabel(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model: torch.nn.Module, data: list):\n",
    "  pred_probs = []\n",
    "  model.eval()\n",
    "  with torch.inference_mode():\n",
    "    for sample in data:\n",
    "      sample = torch.unsqueeze(sample, dim = 0)\n",
    "      pred_logit = model(sample)\n",
    "      pred_prob = torch.softmax(pred_logit.squeeze(), dim = 0)\n",
    "      pred_probs.append(pred_prob.cpu())\n",
    "  return torch.stack(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 9)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = test_data[0][:10]\n",
    "img.shape, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "test_samples = []\n",
    "test_labels = []\n",
    "for sample, label in random.sample(list(test_data), k=9):\n",
    "  test_samples.append(sample)\n",
    "  test_labels.append(label)\n",
    "test_samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Sandal')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_samples[0].squeeze(), cmap='gray')\n",
    "plt.title(class_names[test_labels[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving nd loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to :models\\cv_model_2.pth\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents = True, \n",
    "                 exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"cv_model_2.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "print(f\"Saving model to :{MODEL_SAVE_PATH}\")\n",
    "torch.save(obj = model_2.state_dict(), f= MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "loaded_model_2 = FashionMNISTModelV2(input_shape=1,\n",
    "                                     hidden_units=10,\n",
    "                                     output_shape=len(class_names))\n",
    "\n",
    "# Load model\n",
    "loaded_model_2.load_state_dict(torch.load(f = MODEL_SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV2',\n",
       " 'model_loss': 0.3078635632991791,\n",
       " 'model_acc': 88.75798722044729}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99400bc6538548eda3e182375b37c09b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "loaded_model_2_resuls = eval_model(model = loaded_model_2, data_loader=test_dataloader, loss_fn=loss_fn, accuracy_fn=accuracy_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV2',\n",
       " 'model_loss': 0.3078635632991791,\n",
       " 'model_acc': 88.75798722044729}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model_2_resuls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
