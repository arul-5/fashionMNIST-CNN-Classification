{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arulk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "#importing necessary libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.FashionMNIST(root = \"data\",\n",
    "                                  train = True,\n",
    "                                  download=True,\n",
    "                                   transform=ToTensor(),\n",
    "                                   target_transform=None\n",
    "                                   )\n",
    "test_data = datasets.FashionMNIST(\n",
    "  root = \"data\",\n",
    "  train = False,\n",
    "  download=True,\n",
    "  transform=ToTensor(),\n",
    "  target_transform=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0431,\n",
       "           0.5569, 0.7843, 0.4157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.3333, 0.7255, 0.4392, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5961, 0.8392,\n",
       "           0.8510, 0.7608, 0.9255, 0.8471, 0.7333, 0.5843, 0.5294, 0.6000,\n",
       "           0.8275, 0.8510, 0.9059, 0.8039, 0.8510, 0.7373, 0.1333, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2588, 0.7255, 0.6510,\n",
       "           0.7059, 0.7098, 0.7451, 0.8275, 0.8667, 0.7725, 0.5725, 0.7765,\n",
       "           0.8078, 0.7490, 0.6588, 0.7451, 0.6745, 0.7373, 0.6863, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5294, 0.6000, 0.6275,\n",
       "           0.6863, 0.7059, 0.6667, 0.7294, 0.7333, 0.7451, 0.7373, 0.7451,\n",
       "           0.7333, 0.6824, 0.7647, 0.7255, 0.6824, 0.6314, 0.6863, 0.2314,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6314, 0.5765, 0.6275,\n",
       "           0.6667, 0.6980, 0.6941, 0.7059, 0.6588, 0.6784, 0.6824, 0.6706,\n",
       "           0.7255, 0.7216, 0.7255, 0.6745, 0.6706, 0.6431, 0.6824, 0.4706,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.6863, 0.5725, 0.5686,\n",
       "           0.6588, 0.6980, 0.7098, 0.7255, 0.7059, 0.7216, 0.6980, 0.7020,\n",
       "           0.7333, 0.7490, 0.7569, 0.7451, 0.7098, 0.6706, 0.6745, 0.6196,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.6941, 0.6078, 0.5490,\n",
       "           0.5922, 0.6745, 0.7490, 0.7333, 0.7294, 0.7333, 0.7294, 0.7333,\n",
       "           0.7137, 0.7490, 0.7608, 0.7373, 0.7059, 0.6314, 0.6314, 0.7255,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2314, 0.6667, 0.6000, 0.5529,\n",
       "           0.4706, 0.6039, 0.6275, 0.6314, 0.6745, 0.6588, 0.6510, 0.6314,\n",
       "           0.6471, 0.6745, 0.6667, 0.6431, 0.5451, 0.5843, 0.6353, 0.6510,\n",
       "           0.0824, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.3098, 0.5686, 0.6275, 0.8392,\n",
       "           0.4824, 0.5020, 0.6000, 0.6275, 0.6431, 0.6196, 0.6157, 0.6039,\n",
       "           0.6078, 0.6667, 0.6471, 0.5529, 0.7647, 0.7569, 0.5961, 0.6510,\n",
       "           0.2392, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.3922, 0.6157, 0.8824, 0.9608,\n",
       "           0.6863, 0.4431, 0.6824, 0.6196, 0.6196, 0.6275, 0.6078, 0.6275,\n",
       "           0.6431, 0.6980, 0.7373, 0.5294, 0.7255, 0.9412, 0.7882, 0.6745,\n",
       "           0.4235, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1216, 0.6824, 0.1098,\n",
       "           0.4941, 0.6000, 0.6510, 0.5961, 0.6196, 0.6196, 0.6275, 0.6314,\n",
       "           0.6157, 0.6588, 0.7490, 0.7373, 0.0706, 0.5176, 0.6235, 0.0275,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.3216, 0.7333, 0.6235, 0.6000, 0.6157, 0.6196, 0.6353, 0.6431,\n",
       "           0.6431, 0.6039, 0.7333, 0.7451, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118, 0.0196, 0.0000,\n",
       "           0.1451, 0.6863, 0.6196, 0.6078, 0.6353, 0.6196, 0.6275, 0.6353,\n",
       "           0.6471, 0.6000, 0.6941, 0.8039, 0.0000, 0.0000, 0.0118, 0.0118,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000,\n",
       "           0.0980, 0.6863, 0.5961, 0.6275, 0.6196, 0.6314, 0.6275, 0.6431,\n",
       "           0.6431, 0.6314, 0.6510, 0.7843, 0.0000, 0.0000, 0.0039, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.0000,\n",
       "           0.1176, 0.6706, 0.5765, 0.6431, 0.6078, 0.6471, 0.6314, 0.6471,\n",
       "           0.6353, 0.6667, 0.6431, 0.6353, 0.0000, 0.0000, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.0000,\n",
       "           0.2235, 0.6510, 0.6078, 0.6431, 0.6510, 0.6314, 0.6314, 0.6431,\n",
       "           0.6549, 0.6471, 0.6471, 0.6353, 0.1098, 0.0000, 0.0118, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000,\n",
       "           0.4471, 0.6314, 0.6314, 0.6510, 0.6235, 0.6588, 0.6314, 0.6314,\n",
       "           0.6745, 0.6353, 0.6471, 0.6706, 0.1961, 0.0000, 0.0196, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000,\n",
       "           0.5843, 0.6157, 0.6549, 0.6745, 0.6235, 0.6745, 0.6431, 0.6314,\n",
       "           0.6745, 0.6667, 0.6275, 0.6706, 0.3490, 0.0000, 0.0157, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0157,\n",
       "           0.6706, 0.6431, 0.6510, 0.6784, 0.6235, 0.7020, 0.6510, 0.6275,\n",
       "           0.6824, 0.6549, 0.6353, 0.6510, 0.5020, 0.0000, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.0706,\n",
       "           0.5961, 0.6784, 0.6275, 0.7020, 0.6039, 0.7098, 0.6510, 0.6431,\n",
       "           0.6863, 0.6667, 0.6510, 0.6667, 0.6431, 0.0000, 0.0000, 0.0039,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.0000, 0.1843,\n",
       "           0.6471, 0.6745, 0.6549, 0.7255, 0.6000, 0.7333, 0.6784, 0.6471,\n",
       "           0.6824, 0.7020, 0.6510, 0.6510, 0.6196, 0.0196, 0.0000, 0.0118,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.0000, 0.3412,\n",
       "           0.7059, 0.6353, 0.7020, 0.7020, 0.6157, 0.7490, 0.7137, 0.6471,\n",
       "           0.6588, 0.7451, 0.6784, 0.6471, 0.6510, 0.0784, 0.0000, 0.0157,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.0000, 0.4118,\n",
       "           0.7333, 0.6157, 0.7608, 0.6863, 0.6314, 0.7451, 0.7216, 0.6667,\n",
       "           0.6196, 0.8039, 0.6941, 0.6588, 0.6706, 0.1725, 0.0000, 0.0157,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0196, 0.0000, 0.5412,\n",
       "           0.7098, 0.6196, 0.8039, 0.6275, 0.6549, 0.7451, 0.7765, 0.6549,\n",
       "           0.5961, 0.8549, 0.7294, 0.6667, 0.6745, 0.2235, 0.0000, 0.0196,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0196, 0.0000, 0.5294,\n",
       "           0.6824, 0.6549, 0.7804, 0.6078, 0.6510, 0.7882, 0.8588, 0.6471,\n",
       "           0.6196, 0.8549, 0.7373, 0.6549, 0.6863, 0.2196, 0.0000, 0.0275,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0196, 0.0000, 0.5059,\n",
       "           0.6706, 0.6745, 0.6941, 0.6000, 0.6235, 0.8078, 0.8471, 0.5804,\n",
       "           0.6157, 0.8078, 0.7451, 0.6471, 0.6863, 0.1882, 0.0000, 0.0196,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0196, 0.0000, 0.6549,\n",
       "           0.7333, 0.7137, 0.7765, 0.7608, 0.7843, 0.8863, 0.9412, 0.7216,\n",
       "           0.8078, 1.0000, 0.7725, 0.6980, 0.7020, 0.1647, 0.0000, 0.0196,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.4510,\n",
       "           0.5294, 0.4431, 0.4157, 0.3333, 0.3216, 0.4235, 0.5216, 0.3255,\n",
       "           0.3529, 0.4745, 0.4706, 0.4314, 0.6196, 0.0706, 0.0000, 0.0118,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = train_data[10]\n",
    "image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T-shirt/top': 0,\n",
       " 'Trouser': 1,\n",
       " 'Pullover': 2,\n",
       " 'Dress': 3,\n",
       " 'Coat': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'Bag': 8,\n",
       " 'Ankle boot': 9}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_to_idx = train_data.class_to_idx\n",
    "class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 0, 0,  ..., 3, 0, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25a8eb79d50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualizing the data\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "plt.imshow(image.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.squeeze(), cmap = \"gray\")\n",
    "plt.title(class_names[label])\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset FashionMNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: ToTensor(),\n",
       " Dataset FashionMNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: data\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: ToTensor())"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "BATCH_SIZE = 32\n",
    "train_dataloader = DataLoader(dataset =train_data,\n",
    "                              batch_size = BATCH_SIZE,\n",
    "                              shuffle = True)\n",
    "test_dataloader = DataLoader(dataset = test_data,\n",
    "                             batch_size = BATCH_SIZE,\n",
    "                             shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x25a8ea1f3d0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x25ae4bbbfa0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before flattening: torch.Size([1, 28, 28])\n",
      "Shape after flattening: torch.Size([1, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten_model  = nn.Flatten()\n",
    "x = train_features_batch[0] \n",
    "output = flatten_model(x)\n",
    "print(f\"Shape before flattening: {x.shape}\")\n",
    "print(f\"Shape after flattening: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTModelV0(nn.Module):\n",
    "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "    super().__init__()\n",
    "    self.layer_stack = nn.Sequential(\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "      nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
    "    )\n",
    "  def forward(self,x):\n",
    "    return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNISTModelV0(\n",
       "  (layer_stack): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model_0  =FashionMNISTModelV0(\n",
    "  input_shape=28*28,\n",
    "  hidden_units=10,\n",
    "  output_shape=len(class_names)\n",
    "\n",
    ")\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0315,  0.3171,  0.0531, -0.2525,  0.5959,  0.2112,  0.3233,  0.2694,\n",
       "         -0.1004,  0.0157]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_x = torch.rand([1,1,28,28])\n",
    "model_0(dummy_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer_stack.1.weight',\n",
       "              tensor([[ 0.0273,  0.0296, -0.0084,  ..., -0.0142,  0.0093,  0.0135],\n",
       "                      [-0.0188, -0.0354,  0.0187,  ..., -0.0106, -0.0001,  0.0115],\n",
       "                      [-0.0008,  0.0017,  0.0045,  ..., -0.0127, -0.0188,  0.0059],\n",
       "                      ...,\n",
       "                      [-0.0116,  0.0273, -0.0344,  ...,  0.0176,  0.0283, -0.0011],\n",
       "                      [-0.0230,  0.0257,  0.0291,  ..., -0.0187, -0.0087,  0.0001],\n",
       "                      [ 0.0176, -0.0147,  0.0053,  ..., -0.0336, -0.0221,  0.0205]])),\n",
       "             ('layer_stack.1.bias',\n",
       "              tensor([-0.0093,  0.0283, -0.0033,  0.0255,  0.0017,  0.0037, -0.0302, -0.0123,\n",
       "                       0.0018,  0.0163])),\n",
       "             ('layer_stack.2.weight',\n",
       "              tensor([[ 0.0614, -0.0687,  0.0021,  0.2718,  0.2109,  0.1079, -0.2279, -0.1063,\n",
       "                        0.2019,  0.2847],\n",
       "                      [-0.1495,  0.1344, -0.0740,  0.2006, -0.0475, -0.2514, -0.3130, -0.0118,\n",
       "                        0.0932, -0.1864],\n",
       "                      [ 0.2488,  0.1500,  0.1907,  0.1457, -0.3050, -0.0580,  0.1643,  0.1565,\n",
       "                       -0.2877, -0.1792],\n",
       "                      [ 0.2305, -0.2618,  0.2397, -0.0610,  0.0232,  0.1542,  0.0851, -0.2027,\n",
       "                        0.1030, -0.2715],\n",
       "                      [-0.1596, -0.0555, -0.0633,  0.2302, -0.1726,  0.2654,  0.1473,  0.1029,\n",
       "                        0.2252, -0.2160],\n",
       "                      [-0.2725,  0.0118,  0.1559,  0.1596,  0.0132,  0.3024,  0.1124,  0.1366,\n",
       "                       -0.1533,  0.0965],\n",
       "                      [-0.1184, -0.2555, -0.2057, -0.1909, -0.0477, -0.1324,  0.2905,  0.1307,\n",
       "                       -0.2629,  0.0133],\n",
       "                      [ 0.2727, -0.0127,  0.0513,  0.0863, -0.1043, -0.2047, -0.1185, -0.0825,\n",
       "                        0.2488, -0.2571],\n",
       "                      [ 0.0425, -0.1209, -0.0336, -0.0281, -0.1227,  0.0730,  0.0747, -0.1816,\n",
       "                        0.1943,  0.2853],\n",
       "                      [-0.1310,  0.0645, -0.1171,  0.2168, -0.0245, -0.2820,  0.0736,  0.2621,\n",
       "                        0.0012, -0.0810]])),\n",
       "             ('layer_stack.2.bias',\n",
       "              tensor([-0.0087,  0.1791,  0.2712, -0.0791,  0.1685,  0.1762,  0.2825,  0.2266,\n",
       "                      -0.2612, -0.2613]))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "  correct = torch.eq(y_true, y_pred).sum().item()\n",
    "  acc= (correct/ len(y_pred)) * 100\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params = model_0.parameters(),\n",
    "                           lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer \n",
    "def print_train_time(start:float, end: float, device: torch.device = None):\n",
    "  \"\"\"prints difference start and end time\"\"\"\n",
    "  total_time = end-start\n",
    "  print(f\"Train time is {total_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcdc35fb41614366907976c87e265b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.5904 | Test Loss: 0.5095, Test Acc: 82.0387\n",
      "Epoch: 1\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4763 | Test Loss: 0.4799, Test Acc: 83.1969\n",
      "Epoch: 2\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4550 | Test Loss: 0.4766, Test Acc: 83.4265\n",
      "Epoch: 3\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4425 | Test Loss: 0.4631, Test Acc: 83.7460\n",
      "Epoch: 4\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4358 | Test Loss: 0.4687, Test Acc: 83.2668\n",
      "Epoch: 5\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4291 | Test Loss: 0.4589, Test Acc: 83.6362\n",
      "Epoch: 6\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4248 | Test Loss: 0.4877, Test Acc: 83.3167\n",
      "Epoch: 7\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4227 | Test Loss: 0.4722, Test Acc: 83.3766\n",
      "Epoch: 8\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4203 | Test Loss: 0.4713, Test Acc: 83.4565\n",
      "Epoch: 9\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4175 | Test Loss: 0.4628, Test Acc: 83.6462\n",
      "Train time is 54.401 seconds\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "torch.manual_seed(42)\n",
    "start_time = timer()\n",
    "epochs = 10\n",
    "for epoch in tqdm(range(epochs)):\n",
    "  print(f\"Epoch: {epoch}\\n----\")\n",
    "  train_loss = 0\n",
    "  for batch, (X,y) in enumerate(train_dataloader):\n",
    "    model_0.train()\n",
    "    y_pred  =model_0(X)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    train_loss += loss\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch%400 ==0:\n",
    "       print(f\"Looked at {batch*len(X)}/{len(train_dataloader.dataset)} samples.\")\n",
    "  train_loss /= len(train_dataloader )\n",
    "  test_loss, test_acc = 0,0\n",
    "  model_0.eval()\n",
    "  with torch.inference_mode():\n",
    "    for X, y in test_dataloader:\n",
    "      test_pred = model_0(X)\n",
    "      test_loss += loss_fn(test_pred, y)\n",
    "      \n",
    "      test_acc += accuracy_fn(y_true = y, y_pred  =test_pred.argmax(dim=1))\n",
    "    test_loss /= len(test_dataloader)\n",
    "    test_acc /= len(test_dataloader)\n",
    "  print(f\"\\nTrain Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "end_time = timer()\n",
    "total_train_time = print_train_time(start=start_time, end=end_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d13aa565a34c67b79b2538909dde8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV0',\n",
       " 'model_loss': 0.46279823780059814,\n",
       " 'model_acc': 83.64616613418531}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "def eval_model(model: torch.nn.Module, data_loader: torch.utils.data.DataLoader,loss_fn: torch.nn.Module, accuracy_fn):\n",
    "  '''returns a dictionary containing the results of model predicting on data loader'''\n",
    "  loss, acc =0,0\n",
    "  model.eval()\n",
    "  with torch.inference_mode():\n",
    "    for X,y in tqdm(data_loader):\n",
    "      y_pred = model(X)\n",
    "      loss += loss_fn(y_pred,y)\n",
    "      acc += accuracy_fn(y_true = y, y_pred = y_pred.argmax(dim=1))\n",
    "    loss /= len(data_loader)\n",
    "    acc  /= len(data_loader)\n",
    "  return {\"model_name\": model.__class__.__name__,\n",
    "          \"model_loss\": loss.item(),\n",
    "          \"model_acc\": acc}\n",
    "model_0_results = eval_model(model = model_0, data_loader = test_dataloader, loss_fn = loss_fn, accuracy_fn = accuracy_fn)\n",
    "model_0_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model with non linear layers\n",
    "class FashionMNISTModelV1(nn.Module):\n",
    "  def __init__(self, \n",
    "               input_shape:int,\n",
    "               hidden_units: int,\n",
    "               output_shape: int):\n",
    "    super().__init__()\n",
    "    self.layer_stack = nn.Sequential(\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "  def forward(self, x: torch.Tensor):\n",
    "    return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0273,  0.0296, -0.0084,  ..., -0.0142,  0.0093,  0.0135],\n",
       "        [-0.0188, -0.0354,  0.0187,  ..., -0.0106, -0.0001,  0.0115],\n",
       "        [-0.0008,  0.0017,  0.0045,  ..., -0.0127, -0.0188,  0.0059],\n",
       "        ...,\n",
       "        [-0.0116,  0.0273, -0.0344,  ...,  0.0176,  0.0283, -0.0011],\n",
       "        [-0.0230,  0.0257,  0.0291,  ..., -0.0187, -0.0087,  0.0001],\n",
       "        [ 0.0176, -0.0147,  0.0053,  ..., -0.0336, -0.0221,  0.0205]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model_1 = FashionMNISTModelV1(input_shape=784,\n",
    "                              hidden_units=10,\n",
    "                              output_shape=len(class_names))\n",
    "next(model_1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params = model_1.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.train()\n",
    "    for batch, (X,y) in enumerate(data_loader):\n",
    "      y_pred  =model(X)\n",
    "      loss = loss_fn(y_pred, y)\n",
    "      train_loss += loss\n",
    "      train_acc += accuracy_fn(y_true = y, \n",
    "                               y_pred = y_pred.argmax(dim=1))\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "    train_loss /= len(data_loader )\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train Loss:{train_loss:.5f} | Train Acc: {train_acc:.5f}%\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module,\n",
    "              data_loader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn):\n",
    "  model.eval()\n",
    "  test_loss, test_acc = 0,0\n",
    "  with torch.inference_mode():\n",
    "    for X, y in data_loader:\n",
    "      test_pred = model(X)\n",
    "      test_loss += loss_fn(test_pred, y)\n",
    "        \n",
    "      test_acc += accuracy_fn(y_true = y, y_pred  =test_pred.argmax(dim=1))\n",
    "    test_loss /= len(data_loader)\n",
    "    test_acc /= len(data_loader)\n",
    "  print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e67602708e490089504f08d47dc2c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train Loss:1.09199 | Train Acc: 61.34333%\n",
      "Test Loss: 0.9564, Test Acc: 64.9960%\n",
      "Epoch: 1\n",
      "Train Loss:0.78101 | Train Acc: 71.92833%\n",
      "Test Loss: 0.7223, Test Acc: 73.9117%\n",
      "Epoch: 2\n",
      "Train Loss:0.67027 | Train Acc: 75.93667%\n",
      "Test Loss: 0.6850, Test Acc: 75.0200%\n",
      "Train time is 16.356 seconds\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "train_time_start = timer()\n",
    "epochs = 3\n",
    "for epoch in tqdm(range(epochs)):\n",
    "  print(f\"Epoch: {epoch}\")\n",
    "  train_step(\n",
    "    model = model_1, data_loader=train_dataloader, loss_fn = loss_fn, optimizer=optimizer, accuracy_fn=accuracy_fn\n",
    "  )\n",
    "  test_step(model =model_1, data_loader= test_dataloader, loss_fn= loss_fn, accuracy_fn= accuracy_fn)\n",
    "train_time_end = timer()\n",
    "total_train_time = print_train_time(start = train_time_start, end = train_time_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf45328e357e4d57a4ddc1a8327f761f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_1_results = eval_model(model=model_1, data_loader=test_dataloader, loss_fn=loss_fn, accuracy_fn=accuracy_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV1',\n",
       " 'model_loss': 0.6850008964538574,\n",
       " 'model_acc': 75.01996805111821}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTModelV2(nn.Module):\n",
    "  '''Model architecture that replicates tinyVGG'''\n",
    "  def __init__(self, input_shape:int, hidden_units: int, output_shape: int):\n",
    "    super().__init__()\n",
    "    self.conv_block_1 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=input_shape,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride = 1,\n",
    "                padding = 1\n",
    "                ),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units,\n",
    "                kernel_size =3,\n",
    "                stride = 1,\n",
    "                padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size = 2)\n",
    "    )\n",
    "    self.conv_block_2 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units,kernel_size=3,stride = 1, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride = 1, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2)\n",
    "    )\n",
    "    self.classifier = nn.Sequential(\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(in_features=hidden_units*7*7,\n",
    "                out_features=output_shape)\n",
    "    )\n",
    "  def forward(self, x):\n",
    "    x =self.conv_block_1(x)\n",
    "    #print(x.shape)\n",
    "    x = self.conv_block_2(x)\n",
    "    #print(x.shape)\n",
    "    x = self.classifier(x)\n",
    "    #print(x.shape)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model_2 = FashionMNISTModelV2(input_shape=1,hidden_units=10,output_shape=len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_img_tensor = torch.randn(size = (1,28,28))\n",
    "rand_img_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0744e-01,  2.1310e+00,  2.4406e-01,  1.0901e+00,  7.7187e-01,\n",
       "           1.6738e-02,  6.8036e-01, -1.2983e-01, -5.7276e-01, -3.6839e-01,\n",
       "          -1.6833e-01,  2.0470e+00, -2.0023e+00, -1.2304e+00,  8.7704e-01,\n",
       "          -2.0921e+00, -5.6889e-01,  3.4890e-01, -1.1777e+00,  9.8450e-01,\n",
       "           7.9244e-01, -3.0765e-01,  6.7602e-01,  2.6806e+00,  4.7541e-01,\n",
       "           5.7430e-01,  1.9246e-01,  4.3041e-01],\n",
       "         [ 5.3109e-01,  5.3204e-01, -1.5853e+00,  2.4220e+00,  3.9226e-01,\n",
       "          -2.4747e-01, -2.6899e-01,  1.3260e-01,  4.7382e-01,  3.1056e-02,\n",
       "          -1.4894e-01, -3.6520e-01, -9.6763e-01, -6.9899e-01, -9.2018e-02,\n",
       "          -9.8115e-01,  1.0240e+00, -1.0366e+00, -1.9978e+00,  1.5088e+00,\n",
       "           1.7852e-01,  2.8669e-01,  3.5793e-01, -1.0362e+00,  1.0007e+00,\n",
       "           7.0487e-01, -6.9784e-01,  4.7286e-01],\n",
       "         [ 1.1344e+00, -4.2129e-01,  3.0239e-02, -5.5710e-01, -8.8292e-01,\n",
       "          -7.0626e-01, -1.2800e+00,  1.3593e-01, -1.2744e+00,  8.8456e-01,\n",
       "          -7.5566e-01,  2.0247e+00, -6.3806e-01,  5.3368e-01,  1.6807e-01,\n",
       "          -1.0806e+00, -1.9468e-01, -3.4295e-02, -5.6552e-01,  4.3978e-01,\n",
       "          -6.2775e-01, -1.4592e-01, -4.2360e-01, -1.4882e+00,  3.7751e-01,\n",
       "          -2.0932e-01,  1.7607e+00, -5.6119e-01],\n",
       "         [ 3.0583e-02,  1.5137e-02,  1.1773e+00, -9.6496e-01,  3.5080e-01,\n",
       "           6.3477e-01, -7.4758e-01, -2.1754e-01, -1.3796e+00,  1.0700e+00,\n",
       "          -9.0354e-01,  7.6843e-01,  8.9321e-01,  4.7491e-01,  8.5692e-01,\n",
       "          -7.3647e-01, -7.8533e-01,  1.0901e+00, -6.6455e-02,  1.2573e+00,\n",
       "           8.6748e-02, -1.2705e+00, -1.9873e-01, -4.1027e-01,  7.0857e-01,\n",
       "           2.9490e-01, -6.9377e-01, -8.0132e-01],\n",
       "         [-7.7904e-01,  1.1783e+00,  4.2371e-02, -6.1082e-01, -6.6256e-01,\n",
       "          -5.4954e-01,  5.8682e-02,  1.5382e+00, -2.1542e+00, -4.2973e-01,\n",
       "           1.4808e+00, -2.7136e+00,  1.1272e+00,  5.4450e-01, -2.1858e-01,\n",
       "           4.1211e-01, -1.9089e+00, -6.1621e-02, -6.2887e-01, -3.9982e-02,\n",
       "          -9.6348e-01, -1.0543e+00, -6.1099e-01,  1.1033e-01,  6.4398e-01,\n",
       "          -1.6229e+00,  2.4068e-01,  1.6771e+00],\n",
       "         [-9.6226e-02, -6.8070e-01,  7.3392e-01,  9.3939e-02, -3.6622e-01,\n",
       "           5.1108e-01,  9.4761e-01, -1.7694e+00,  9.0191e-01,  3.1770e-01,\n",
       "           1.5054e+00, -4.5409e-04,  6.2740e-01, -9.0721e-01, -1.1753e+00,\n",
       "          -1.6300e+00,  7.8123e-01, -1.4737e+00,  9.1280e-01, -8.1394e-01,\n",
       "          -9.7817e-01,  4.6866e-01, -3.3286e-02, -8.6844e-01, -1.3389e+00,\n",
       "          -1.0444e-01,  1.5695e-01, -1.5132e+00],\n",
       "         [ 8.2570e-01,  1.3953e+00,  1.5590e-01, -1.7197e-01,  8.3635e-01,\n",
       "          -2.0765e+00,  9.2636e-01,  1.8823e+00,  3.7435e-02, -1.0223e+00,\n",
       "          -6.0164e-01, -3.4738e-01, -9.6253e-01,  9.5393e-01, -1.4123e+00,\n",
       "           8.1285e-01, -8.7211e-02,  1.9312e+00,  8.2432e-01,  3.2105e-01,\n",
       "          -6.0463e-01, -6.8750e-01,  2.0560e-01, -7.1922e-01,  9.9742e-01,\n",
       "           3.8142e-01,  1.1022e+00,  1.4521e-01],\n",
       "         [-1.0026e+00, -8.6914e-01,  1.0349e+00,  1.1414e+00,  1.8630e+00,\n",
       "           6.3446e-01,  8.0740e-02,  7.6934e-01, -1.2069e+00, -1.6842e-01,\n",
       "          -1.0213e+00,  4.5474e-01, -9.9611e-01,  6.8377e-02,  1.1345e+00,\n",
       "          -6.2708e-01, -2.3483e-01,  1.8348e-01,  8.2710e-01,  6.8175e-01,\n",
       "           5.8005e-01, -3.1850e-01, -3.3317e-01,  1.3781e+00,  2.2485e-01,\n",
       "          -2.3762e+00,  4.0155e-01, -2.2946e+00],\n",
       "         [ 6.1818e-01,  2.5706e+00, -6.1464e-01, -4.2742e-01, -1.4890e+00,\n",
       "           5.8501e-01, -6.4059e-01, -1.9064e+00, -1.7118e-01,  2.4884e-01,\n",
       "          -2.1651e-02,  7.1713e-01, -1.3825e+00,  5.6673e-01, -2.2063e+00,\n",
       "           2.8584e-01, -7.0945e-01, -1.5487e-01,  1.5452e+00,  3.4486e-01,\n",
       "           7.9914e-01,  3.4314e-01, -7.1088e-01,  4.0654e-01,  3.2983e-01,\n",
       "           2.8110e-01,  6.9242e-01, -8.0597e-01],\n",
       "         [ 1.8508e+00, -1.2886e+00,  1.2673e+00, -9.6881e-01,  2.2709e+00,\n",
       "           6.2684e-01,  1.6014e+00,  1.1966e+00,  7.0630e-02, -6.8063e-02,\n",
       "           1.2693e+00,  2.2910e+00,  3.4564e-01, -1.9724e-01, -1.5218e+00,\n",
       "          -6.1098e-02, -4.9620e-01,  1.5591e+00, -1.2024e+00, -6.3514e-01,\n",
       "          -2.6685e-01,  6.4505e-02, -1.4933e+00,  1.6295e+00, -1.7387e+00,\n",
       "           1.7332e+00,  7.3354e-01,  9.9386e-01],\n",
       "         [ 8.1700e-01, -1.0389e+00, -1.4859e+00,  1.4144e+00,  7.2411e-01,\n",
       "           1.1350e+00,  1.3726e-01, -2.8324e-01,  1.9970e-01,  8.8416e-01,\n",
       "           9.4998e-01, -1.0251e-01,  9.8307e-01, -1.6503e+00, -8.4474e-01,\n",
       "          -1.7778e+00, -7.2901e-01, -1.3368e+00,  2.8592e-01,  1.0035e+00,\n",
       "           6.4698e-01,  1.3001e+00,  6.4310e-01, -1.3192e+00, -2.2553e+00,\n",
       "          -1.0051e+00,  2.7072e-01,  2.9641e-01],\n",
       "         [-1.0662e-02,  3.2636e-01, -3.9913e-01, -5.4581e-01,  9.0894e-01,\n",
       "          -1.2521e+00,  5.0658e-01, -5.6990e-01, -2.0494e+00,  1.2204e+00,\n",
       "           1.3751e+00,  4.9697e-01, -8.2124e-01,  7.8169e-01,  2.5165e+00,\n",
       "          -8.6160e-02,  1.1008e-01, -4.9934e-01,  1.4105e+00,  9.0974e-01,\n",
       "           1.0248e+00, -3.8765e-01,  1.1529e+00, -1.7237e-01,  6.9148e-01,\n",
       "           4.3387e-01,  1.6470e-01,  9.2992e-01],\n",
       "         [-2.6299e-01,  3.9443e-01, -5.6013e-01,  5.6457e-01,  2.8999e-01,\n",
       "          -2.8325e-01, -7.4868e-01, -1.4254e+00,  2.9738e-01, -1.5418e+00,\n",
       "          -6.5947e-01, -1.5964e+00, -6.6038e-01, -9.2917e-01,  1.0411e+00,\n",
       "           1.7303e+00, -6.8286e-02,  1.2681e+00, -9.1252e-01,  4.8035e-01,\n",
       "          -4.1451e-01, -1.7113e+00,  3.6452e-01, -5.8035e-01,  1.5388e+00,\n",
       "           1.1634e+00, -6.7053e-01,  1.5959e+00],\n",
       "         [ 5.2196e-01,  3.4126e-01,  1.0109e+00, -4.6918e-02, -7.4653e-01,\n",
       "          -1.1631e+00, -1.9771e+00, -4.4984e-03,  2.3253e-02, -1.0358e+00,\n",
       "           6.9172e-01, -6.7895e-01, -7.6813e-01, -8.9178e-01,  2.0132e-01,\n",
       "           6.6459e-01, -1.7229e+00, -5.2109e-01,  6.0717e-02,  4.2114e-01,\n",
       "          -6.8855e-01, -2.3013e-01,  7.8437e-02, -1.9521e-01,  7.7359e-01,\n",
       "           1.4078e-01, -2.7783e-01,  1.5577e-02],\n",
       "         [ 6.5733e-01,  7.8904e-01,  7.0539e-01, -4.0017e-01, -3.0289e+00,\n",
       "           2.6210e-01,  2.5721e+00, -4.7537e-01,  1.4928e-02, -1.5317e-01,\n",
       "           1.6928e+00, -7.1612e-01, -1.5331e-01, -1.3848e+00,  4.5417e-01,\n",
       "           3.8795e-01,  1.0760e+00,  1.3860e+00, -2.2771e-02, -4.9435e-01,\n",
       "          -6.9273e-01, -6.2174e-01,  7.4563e-01, -4.6407e-01,  8.8848e-01,\n",
       "           1.7476e-01, -2.0528e+00,  3.8554e-02],\n",
       "         [ 1.2138e+00, -8.6570e-02, -7.5610e-01, -6.0872e-01,  5.5490e-01,\n",
       "          -9.4617e-01, -7.3941e-01,  7.4925e-01, -6.0584e-01, -3.8430e-01,\n",
       "          -1.5004e+00,  1.4241e+00,  3.9047e-02, -1.7162e-01, -8.4248e-01,\n",
       "           1.2268e+00,  6.2589e-01, -2.1850e-02, -1.7424e+00, -7.6729e-01,\n",
       "          -7.1444e-01,  7.0411e-01, -1.2723e+00, -7.1344e-01,  2.3755e-01,\n",
       "           2.4901e+00,  3.1266e-01, -3.8830e-01],\n",
       "         [-4.0348e-01, -6.0248e-01, -4.6981e-01,  5.7327e-01, -4.0826e-03,\n",
       "           7.2984e-02, -2.5910e-01,  7.9609e-01, -1.5237e-01,  1.1046e-01,\n",
       "          -9.9129e-01, -8.8786e-01,  1.3683e+00,  1.2856e+00, -1.3335e+00,\n",
       "           9.4325e-01,  1.7698e+00,  1.3942e+00, -4.4747e-01, -8.0292e-01,\n",
       "          -9.0479e-01, -1.0662e-02, -3.0602e-01, -2.0311e+00,  5.9401e-01,\n",
       "           8.2598e-01,  1.2241e+00, -1.4314e-01],\n",
       "         [-7.9281e-01,  4.7013e-01,  9.6294e-02,  1.7162e+00,  1.7242e+00,\n",
       "           2.1783e+00, -6.1399e-01,  9.9399e-01,  5.2973e-01, -3.7780e-01,\n",
       "           1.4174e+00,  4.9107e-01, -1.4276e+00,  8.3103e-01, -1.4381e+00,\n",
       "           6.2128e-01, -1.9692e+00, -2.4453e-01, -6.7767e-01,  4.7823e-01,\n",
       "          -1.1979e+00,  5.5965e-01,  4.8749e-01, -1.5288e+00,  3.6162e-01,\n",
       "           4.4447e-01,  3.7175e-01,  1.7289e-01],\n",
       "         [-1.4194e+00, -2.2494e-01, -5.3420e-01, -7.8784e-02,  9.7180e-01,\n",
       "           1.5757e-01, -1.2937e-01,  9.4592e-01, -8.3734e-01, -4.4729e-01,\n",
       "          -1.1803e-01,  8.9325e-01,  8.5920e-01,  1.0688e+00,  1.0354e+00,\n",
       "          -1.0889e+00,  6.0094e-01,  5.4608e-02, -5.6699e-01, -1.0099e+00,\n",
       "          -4.5413e-01,  6.9793e-01,  5.4690e-01,  5.5246e-01,  6.7458e-01,\n",
       "          -1.7007e+00,  2.6413e+00, -4.2235e-01],\n",
       "         [ 3.2800e-01, -2.2357e-01,  6.3385e-01,  1.2713e+00,  8.8556e-01,\n",
       "          -3.1540e-01,  2.8686e-01,  1.3422e+00, -4.5323e-01,  1.0592e+00,\n",
       "          -1.7509e+00,  8.3122e-01,  2.0407e+00, -7.5694e-01, -1.8586e+00,\n",
       "           1.3976e+00, -8.2356e-01, -3.6673e-01,  5.7609e-01, -5.4015e-01,\n",
       "          -1.2378e+00,  1.4525e+00, -1.4253e-01,  2.6613e-01, -9.2466e-01,\n",
       "           6.7150e-01,  4.1903e-01, -2.2128e-01],\n",
       "         [ 1.2662e-01,  9.1385e-01,  1.5243e-01, -1.7770e+00, -2.7009e-01,\n",
       "           1.1325e+00,  1.2827e+00,  4.0248e-01, -2.5367e-01, -6.0270e-01,\n",
       "           4.1119e-01, -4.7856e-01, -3.7983e-01, -6.7844e-01, -1.0526e+00,\n",
       "           2.2322e-01,  3.4093e-01,  9.6618e-02,  8.0482e-01, -9.3085e-01,\n",
       "          -7.4956e-01, -1.1346e+00,  4.3102e-01, -2.2315e-01,  2.7896e-01,\n",
       "           3.3156e-01, -5.1994e-02, -3.8997e-01],\n",
       "         [ 4.5961e-01,  1.5001e+00,  3.8992e-01,  4.0374e-01, -1.2495e+00,\n",
       "          -1.8244e+00,  1.9354e+00,  3.2967e-01, -5.0370e-01,  5.8248e-01,\n",
       "          -2.6750e+00,  1.8529e-01, -1.1496e+00,  5.5760e-01, -4.4239e-01,\n",
       "          -1.1939e+00,  5.1212e-01,  3.4507e-01, -1.1712e+00,  2.5597e-01,\n",
       "           3.6448e-01, -1.3919e+00, -1.3599e-01,  5.0216e-01,  3.1002e-01,\n",
       "           8.0718e-02,  1.3723e-01,  1.2757e+00],\n",
       "         [ 1.0261e+00, -1.5927e-01,  1.6456e+00,  8.0955e-01, -5.0844e-01,\n",
       "          -3.8419e-01, -1.8623e-01, -1.6419e-01,  5.4377e-01,  5.8241e-01,\n",
       "           2.5589e-01, -7.6497e-01,  1.6420e+00, -1.3696e+00, -1.3332e-01,\n",
       "           6.1232e-01, -4.3007e-02,  4.3993e-01,  4.4535e-01, -1.7399e+00,\n",
       "           6.8525e-01,  1.6848e+00, -5.5461e-01, -3.9066e-01, -5.3171e-01,\n",
       "          -3.5423e-02, -4.6917e-01,  3.5407e+00],\n",
       "         [-3.8007e-01, -2.6199e-01, -5.2260e-01, -4.2274e-01, -9.4266e-01,\n",
       "          -3.4241e-01, -1.6840e+00,  6.5372e-01,  3.6240e-01, -1.1096e+00,\n",
       "           1.5687e-01,  6.1850e-01, -6.7774e-01, -1.4288e-01,  3.9184e-01,\n",
       "           2.7028e-01, -1.9761e+00, -6.5923e-01, -6.7635e-01,  7.7160e-02,\n",
       "           3.0672e-01,  2.6992e+00, -2.3807e-01, -3.8906e-01, -3.0060e-01,\n",
       "          -4.9752e-02,  1.6682e+00,  7.0868e-01],\n",
       "         [ 8.3910e-01, -1.0962e+00, -4.4092e-01, -1.6116e+00,  7.7819e-01,\n",
       "          -8.6512e-01, -4.1890e-01,  9.1329e-01,  2.0143e-01, -9.8894e-01,\n",
       "          -9.2795e-01, -1.0297e+00, -1.0448e+00, -8.1244e-01,  4.9417e-01,\n",
       "           1.2591e+00,  2.3193e-01,  1.0128e+00,  2.8556e-01,  2.7378e-01,\n",
       "          -7.8985e-01, -4.2243e-01,  2.0087e+00, -6.7153e-01, -1.3939e-01,\n",
       "          -1.3287e+00, -1.6961e+00, -4.2138e-01],\n",
       "         [-1.1771e+00, -7.6260e-01,  1.0223e+00,  5.8568e-01, -7.1266e-02,\n",
       "          -7.8039e-01,  7.8077e-01, -1.6109e+00, -1.8808e+00,  1.4752e+00,\n",
       "           1.6363e+00, -9.6454e-01, -1.0800e+00,  1.4510e+00, -3.4883e-01,\n",
       "           1.3017e-01,  3.4857e-01,  5.8185e-01, -3.9348e-01,  4.5355e-01,\n",
       "           7.8322e-01,  2.7604e-01,  3.8524e-01,  8.4654e-01,  1.2129e-01,\n",
       "           4.4559e-01, -9.7703e-01, -5.8460e-01],\n",
       "         [-1.8720e+00, -5.5087e-01,  1.4841e-01,  6.1050e-01, -4.4323e-01,\n",
       "           1.2706e+00, -6.7737e-01,  6.4786e-01, -1.3303e+00, -7.1200e-01,\n",
       "           1.0064e+00,  7.2440e-01, -7.1964e-01,  6.4515e-01, -1.0183e+00,\n",
       "          -1.1015e+00,  1.0320e-01,  2.1853e-02, -6.1640e-01, -5.0537e-01,\n",
       "           3.5302e-01,  4.1270e-01, -9.2464e-01, -1.5020e+00,  1.6695e-01,\n",
       "           2.5365e-01,  9.3744e-01,  2.0111e+00],\n",
       "         [-3.2855e-01,  6.4060e-01, -2.3416e-01,  1.8856e-01,  4.3880e-01,\n",
       "          -2.0330e-01, -8.5389e-01,  2.2006e+00, -2.2161e-02,  4.2238e-01,\n",
       "          -8.5958e-01,  2.9099e-01, -7.1094e-01, -7.6892e-01, -1.3048e+00,\n",
       "           5.8784e-01,  1.0671e-01,  1.4935e-01,  2.1158e+00,  2.6433e-01,\n",
       "          -2.3907e-01, -1.8270e-01,  5.2393e-02, -1.8020e+00, -8.2199e-01,\n",
       "           1.3311e+00, -3.0205e-01, -1.0949e+00]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 14, 14])\n",
      "torch.Size([1, 10, 7, 7])\n",
      "torch.Size([1, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0402, -0.0870,  0.0767, -0.0430,  0.0317,  0.0221,  0.0063, -0.0002,\n",
       "          0.0030, -0.0256]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2(rand_img_tensor.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params = model_2.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv_block_1.0.weight',\n",
       "              tensor([[[[ 0.2548,  0.2767, -0.0781],\n",
       "                        [ 0.3062, -0.0730,  0.0673],\n",
       "                        [-0.1623,  0.1958,  0.2938]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2445,  0.2897,  0.0624],\n",
       "                        [ 0.2463,  0.0451,  0.1607],\n",
       "                        [-0.0471,  0.2570,  0.0493]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1556,  0.0850, -0.1536],\n",
       "                        [-0.0391, -0.1354,  0.2211],\n",
       "                        [-0.2631, -0.1537, -0.0941]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2004,  0.0315, -0.3292],\n",
       "                        [ 0.3010, -0.2832,  0.2573],\n",
       "                        [ 0.0555, -0.1082,  0.2060]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0520,  0.2693,  0.0364],\n",
       "                        [-0.1051,  0.0896, -0.0904],\n",
       "                        [ 0.1403,  0.2976,  0.1927]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1457,  0.1924,  0.0596],\n",
       "                        [ 0.1693, -0.2032, -0.3300],\n",
       "                        [-0.1288, -0.2557,  0.2735]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0960,  0.1381,  0.1054],\n",
       "                        [-0.0058,  0.2609, -0.2368],\n",
       "                        [ 0.0210, -0.2275,  0.1028]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1148,  0.1021, -0.0694],\n",
       "                        [ 0.2765, -0.1976, -0.1988],\n",
       "                        [-0.1988,  0.2998,  0.1111]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3208, -0.2751, -0.3306],\n",
       "                        [-0.2608, -0.2242,  0.1350],\n",
       "                        [ 0.1194,  0.2770, -0.1721]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2272,  0.1769, -0.1347],\n",
       "                        [ 0.2023, -0.0791,  0.1907],\n",
       "                        [-0.2590, -0.1682,  0.1016]]]])),\n",
       "             ('conv_block_1.0.bias',\n",
       "              tensor([ 0.0705, -0.0850,  0.1987,  0.2266, -0.2417, -0.1780,  0.3052, -0.1125,\n",
       "                      -0.1182, -0.3225])),\n",
       "             ('conv_block_1.2.weight',\n",
       "              tensor([[[[-0.0604,  0.0263, -0.0139],\n",
       "                        [-0.0765,  0.0025, -0.0720],\n",
       "                        [-0.0894, -0.0580, -0.0923]],\n",
       "              \n",
       "                       [[-0.0671,  0.1054,  0.0199],\n",
       "                        [ 0.0325, -0.0983, -0.0692],\n",
       "                        [-0.0351,  0.0165, -0.0928]],\n",
       "              \n",
       "                       [[-0.0454, -0.0631,  0.0003],\n",
       "                        [-0.0392, -0.0073, -0.0714],\n",
       "                        [-0.0724, -0.0615, -0.0361]],\n",
       "              \n",
       "                       [[-0.0832,  0.0884, -0.0209],\n",
       "                        [ 0.0907,  0.0328, -0.0893],\n",
       "                        [ 0.0729, -0.0290, -0.0404]],\n",
       "              \n",
       "                       [[-0.0875, -0.1048,  0.0302],\n",
       "                        [-0.0230,  0.0410, -0.0865],\n",
       "                        [ 0.0783, -0.0774, -0.0182]],\n",
       "              \n",
       "                       [[ 0.0220,  0.0544,  0.0851],\n",
       "                        [ 0.0960, -0.0836,  0.0265],\n",
       "                        [-0.0453, -0.0116, -0.0789]],\n",
       "              \n",
       "                       [[ 0.0960, -0.0774,  0.0563],\n",
       "                        [ 0.0370,  0.0343, -0.0570],\n",
       "                        [ 0.0958,  0.0232,  0.0136]],\n",
       "              \n",
       "                       [[-0.0929,  0.0442, -0.0158],\n",
       "                        [-0.0483,  0.0905,  0.0235],\n",
       "                        [-0.0583, -0.0534, -0.0050]],\n",
       "              \n",
       "                       [[ 0.0589, -0.0269, -0.0601],\n",
       "                        [-0.0361, -0.0787,  0.0376],\n",
       "                        [ 0.0816, -0.0992,  0.0245]],\n",
       "              \n",
       "                       [[ 0.0545,  0.0191, -0.0375],\n",
       "                        [ 0.0550,  0.0554,  0.0394],\n",
       "                        [-0.0185, -0.0279,  0.0113]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0186, -0.0314,  0.0674],\n",
       "                        [ 0.0906, -0.0104, -0.0236],\n",
       "                        [ 0.0015, -0.0063,  0.0253]],\n",
       "              \n",
       "                       [[ 0.0295, -0.0957, -0.0389],\n",
       "                        [ 0.0888,  0.0411, -0.0052],\n",
       "                        [-0.0636, -0.0645, -0.0944]],\n",
       "              \n",
       "                       [[-0.0344,  0.0356,  0.0672],\n",
       "                        [ 0.0487, -0.0932, -0.0634],\n",
       "                        [-0.0166,  0.1020,  0.0152]],\n",
       "              \n",
       "                       [[-0.0273,  0.0436, -0.0401],\n",
       "                        [-0.0682,  0.0769, -0.0479],\n",
       "                        [-0.0211, -0.1049,  0.0705]],\n",
       "              \n",
       "                       [[ 0.0799,  0.0384, -0.0735],\n",
       "                        [-0.1040, -0.0856,  0.0786],\n",
       "                        [ 0.0506,  0.0887,  0.0552]],\n",
       "              \n",
       "                       [[ 0.0267, -0.0010, -0.0802],\n",
       "                        [-0.0903, -0.0986,  0.0432],\n",
       "                        [-0.0518, -0.0212, -0.0607]],\n",
       "              \n",
       "                       [[-0.0192, -0.0742, -0.0689],\n",
       "                        [ 0.0350, -0.0313,  0.0651],\n",
       "                        [-0.0338, -0.0773, -0.0186]],\n",
       "              \n",
       "                       [[-0.0511, -0.0322, -0.1003],\n",
       "                        [ 0.0590, -0.0734,  0.0530],\n",
       "                        [ 0.0478,  0.0753, -0.0809]],\n",
       "              \n",
       "                       [[ 0.0758, -0.0498,  0.0391],\n",
       "                        [ 0.0990, -0.0149, -0.0008],\n",
       "                        [-0.0243, -0.0880,  0.0506]],\n",
       "              \n",
       "                       [[-0.1046,  0.0654,  0.0789],\n",
       "                        [ 0.0997, -0.0249, -0.0866],\n",
       "                        [ 0.0237,  0.0582, -0.1049]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0239, -0.0632, -0.0092],\n",
       "                        [-0.0519, -0.0431, -0.0335],\n",
       "                        [-0.1002,  0.0865,  0.0884]],\n",
       "              \n",
       "                       [[-0.0165, -0.0120, -0.0430],\n",
       "                        [-0.0952, -0.1026,  0.0392],\n",
       "                        [-0.0579, -0.0678, -0.0082]],\n",
       "              \n",
       "                       [[-0.0351, -0.0341,  0.0034],\n",
       "                        [-0.0224, -0.0363, -0.0505],\n",
       "                        [-0.0858,  0.0884, -0.0422]],\n",
       "              \n",
       "                       [[ 0.0279, -0.0366,  0.0086],\n",
       "                        [ 0.0983,  0.0486, -0.0913],\n",
       "                        [ 0.0418,  0.1001,  0.0277]],\n",
       "              \n",
       "                       [[ 0.0707,  0.1039, -0.0162],\n",
       "                        [ 0.0219, -0.0733, -0.0217],\n",
       "                        [ 0.0781,  0.0540, -0.0667]],\n",
       "              \n",
       "                       [[-0.0845, -0.0720, -0.1040],\n",
       "                        [-0.0813, -0.0261,  0.0711],\n",
       "                        [ 0.0176, -0.0802, -0.0846]],\n",
       "              \n",
       "                       [[ 0.0524, -0.0784, -0.0130],\n",
       "                        [ 0.0506, -0.0488, -0.0115],\n",
       "                        [-0.0092, -0.0249, -0.0534]],\n",
       "              \n",
       "                       [[-0.0940, -0.0852, -0.0564],\n",
       "                        [ 0.1018, -0.0509, -0.0708],\n",
       "                        [ 0.0256,  0.0291,  0.0578]],\n",
       "              \n",
       "                       [[ 0.0801,  0.0587, -0.1045],\n",
       "                        [ 0.0093,  0.0639, -0.0097],\n",
       "                        [-0.0621,  0.1005, -0.0394]],\n",
       "              \n",
       "                       [[-0.0600, -0.0950,  0.0047],\n",
       "                        [ 0.0467,  0.0233,  0.0208],\n",
       "                        [-0.0799, -0.0984,  0.0019]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0961,  0.0608, -0.0614],\n",
       "                        [-0.0137, -0.0777, -0.0509],\n",
       "                        [ 0.0191,  0.0574,  0.0873]],\n",
       "              \n",
       "                       [[-0.0968,  0.0705, -0.0743],\n",
       "                        [ 0.0395,  0.0892,  0.0015],\n",
       "                        [ 0.0959, -0.0898, -0.0403]],\n",
       "              \n",
       "                       [[ 0.0615, -0.0230, -0.0216],\n",
       "                        [-0.0439,  0.0727,  0.0517],\n",
       "                        [ 0.0338, -0.0592, -0.0856]],\n",
       "              \n",
       "                       [[ 0.0114,  0.0312, -0.0487],\n",
       "                        [-0.0295,  0.0712,  0.0084],\n",
       "                        [ 0.0048, -0.0259, -0.0955]],\n",
       "              \n",
       "                       [[-0.0991, -0.0504, -0.0536],\n",
       "                        [ 0.0328, -0.0307, -0.0412],\n",
       "                        [ 0.1005,  0.0367,  0.0751]],\n",
       "              \n",
       "                       [[-0.0510, -0.0431,  0.0387],\n",
       "                        [-0.0702, -0.0689, -0.0051],\n",
       "                        [-0.0386, -0.0790,  0.0625]],\n",
       "              \n",
       "                       [[ 0.0848,  0.0171, -0.0184],\n",
       "                        [-0.0976, -0.0384,  0.0268],\n",
       "                        [ 0.0497, -0.0133, -0.0417]],\n",
       "              \n",
       "                       [[ 0.0587, -0.0839,  0.0666],\n",
       "                        [-0.0409,  0.0016, -0.0208],\n",
       "                        [ 0.0128, -0.0319,  0.0766]],\n",
       "              \n",
       "                       [[-0.0027,  0.0823,  0.1013],\n",
       "                        [-0.0514, -0.0769,  0.0846],\n",
       "                        [ 0.0826, -0.0805, -0.0081]],\n",
       "              \n",
       "                       [[-0.1039, -0.0863,  0.0204],\n",
       "                        [ 0.0280,  0.0223, -0.0287],\n",
       "                        [ 0.0972,  0.0151, -0.0622]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0060,  0.0253,  0.0369],\n",
       "                        [-0.0745,  0.0395, -0.0539],\n",
       "                        [-0.0876, -0.0576,  0.1017]],\n",
       "              \n",
       "                       [[ 0.0901,  0.0944,  0.0619],\n",
       "                        [ 0.0796, -0.0141, -0.0580],\n",
       "                        [ 0.0527, -0.0546, -0.0711]],\n",
       "              \n",
       "                       [[-0.0337,  0.0221,  0.0543],\n",
       "                        [-0.0409, -0.0620,  0.0142],\n",
       "                        [-0.0621, -0.0686,  0.0549]],\n",
       "              \n",
       "                       [[-0.0177,  0.0963,  0.1025],\n",
       "                        [ 0.0315,  0.0363,  0.0243],\n",
       "                        [ 0.0017, -0.0077,  0.0014]],\n",
       "              \n",
       "                       [[ 0.0394,  0.0980, -0.0273],\n",
       "                        [-0.0446, -0.0255, -0.0509],\n",
       "                        [ 0.0179,  0.0787,  0.0824]],\n",
       "              \n",
       "                       [[ 0.0484, -0.0776, -0.0566],\n",
       "                        [-0.0232, -0.0194,  0.0087],\n",
       "                        [-0.0968,  0.0328, -0.0804]],\n",
       "              \n",
       "                       [[-0.0667, -0.0876,  0.0918],\n",
       "                        [-0.0998,  0.0795, -0.0035],\n",
       "                        [-0.0123,  0.0659, -0.0097]],\n",
       "              \n",
       "                       [[ 0.0661,  0.0762, -0.0915],\n",
       "                        [ 0.0406,  0.0199,  0.0227],\n",
       "                        [ 0.0154,  0.0288, -0.0507]],\n",
       "              \n",
       "                       [[-0.0135,  0.1002,  0.0708],\n",
       "                        [-0.0040, -0.0991,  0.0046],\n",
       "                        [-0.0718,  0.0857, -0.0640]],\n",
       "              \n",
       "                       [[-0.0076, -0.0234,  0.0188],\n",
       "                        [ 0.0992,  0.0100,  0.0610],\n",
       "                        [ 0.0818,  0.0851, -0.0364]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0236,  0.0508, -0.0288],\n",
       "                        [ 0.0494, -0.0230, -0.0715],\n",
       "                        [ 0.0429,  0.0162,  0.0470]],\n",
       "              \n",
       "                       [[ 0.1047,  0.0720,  0.0999],\n",
       "                        [ 0.0056, -0.0907, -0.0739],\n",
       "                        [-0.0655, -0.0929, -0.0528]],\n",
       "              \n",
       "                       [[-0.0970, -0.0973, -0.0630],\n",
       "                        [-0.1039, -0.0647,  0.0402],\n",
       "                        [ 0.0879, -0.0314, -0.0307]],\n",
       "              \n",
       "                       [[ 0.0563, -0.0520, -0.0498],\n",
       "                        [ 0.0649, -0.0918,  0.0129],\n",
       "                        [ 0.0931,  0.0181,  0.0287]],\n",
       "              \n",
       "                       [[-0.0614, -0.0015,  0.0058],\n",
       "                        [ 0.0259,  0.0410,  0.0916],\n",
       "                        [-0.0805,  0.0032, -0.0527]],\n",
       "              \n",
       "                       [[-0.0834, -0.0084, -0.0928],\n",
       "                        [ 0.0736,  0.0122, -0.0568],\n",
       "                        [ 0.0551, -0.0998, -0.0408]],\n",
       "              \n",
       "                       [[-0.0205, -0.0896, -0.0670],\n",
       "                        [-0.0172,  0.0800,  0.1018],\n",
       "                        [ 0.0671, -0.0629, -0.0690]],\n",
       "              \n",
       "                       [[ 0.0920,  0.0373,  0.0028],\n",
       "                        [ 0.0143, -0.0847, -0.0352],\n",
       "                        [ 0.1015, -0.0260, -0.0053]],\n",
       "              \n",
       "                       [[-0.0875, -0.0590, -0.0022],\n",
       "                        [-0.0655, -0.0131,  0.0429],\n",
       "                        [-0.1031,  0.0313, -0.0697]],\n",
       "              \n",
       "                       [[-0.0514,  0.0405,  0.0838],\n",
       "                        [-0.0288, -0.0433, -0.0953],\n",
       "                        [-0.0544, -0.0923, -0.0241]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0215, -0.0988,  0.0920],\n",
       "                        [ 0.0661, -0.1032, -0.0503],\n",
       "                        [ 0.0344, -0.0217, -0.0115]],\n",
       "              \n",
       "                       [[-0.0476,  0.0847, -0.0589],\n",
       "                        [ 0.0874,  0.0068,  0.0212],\n",
       "                        [ 0.0822, -0.0174, -0.0600]],\n",
       "              \n",
       "                       [[-0.0170,  0.0855, -0.0782],\n",
       "                        [ 0.0239, -0.1036,  0.0553],\n",
       "                        [ 0.0389,  0.0045,  0.0452]],\n",
       "              \n",
       "                       [[ 0.0001,  0.0583, -0.0834],\n",
       "                        [-0.0155,  0.0468,  0.1050],\n",
       "                        [ 0.0537, -0.0767,  0.0811]],\n",
       "              \n",
       "                       [[-0.0235, -0.0225, -0.0958],\n",
       "                        [-0.0166,  0.0746,  0.0147],\n",
       "                        [-0.0614,  0.0324, -0.0338]],\n",
       "              \n",
       "                       [[ 0.0962, -0.0915, -0.0333],\n",
       "                        [-0.1018, -0.0415,  0.0332],\n",
       "                        [ 0.1015,  0.0177,  0.1033]],\n",
       "              \n",
       "                       [[ 0.0206,  0.0609,  0.0845],\n",
       "                        [ 0.0881, -0.0590,  0.0969],\n",
       "                        [ 0.0639, -0.0493, -0.0503]],\n",
       "              \n",
       "                       [[-0.0884,  0.0265, -0.0854],\n",
       "                        [ 0.0445,  0.0333, -0.0916],\n",
       "                        [ 0.0287, -0.0086,  0.0482]],\n",
       "              \n",
       "                       [[ 0.0605, -0.1048,  0.0967],\n",
       "                        [ 0.0884,  0.0419, -0.0963],\n",
       "                        [-0.0377, -0.0305, -0.0271]],\n",
       "              \n",
       "                       [[ 0.0594,  0.0383,  0.0835],\n",
       "                        [-0.0395,  0.0355,  0.0375],\n",
       "                        [-0.0878, -0.1022, -0.0547]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0722, -0.0992, -0.0918],\n",
       "                        [ 0.0591,  0.0569,  0.0867],\n",
       "                        [-0.0796, -0.0771,  0.0541]],\n",
       "              \n",
       "                       [[ 0.0917,  0.0631,  0.0165],\n",
       "                        [ 0.0347,  0.1000, -0.0680],\n",
       "                        [-0.0479,  0.0737, -0.0721]],\n",
       "              \n",
       "                       [[-0.0581,  0.0769,  0.0333],\n",
       "                        [ 0.0341, -0.0447, -0.0015],\n",
       "                        [ 0.0965, -0.0633,  0.0008]],\n",
       "              \n",
       "                       [[ 0.0501, -0.0728,  0.1024],\n",
       "                        [-0.0527, -0.0253, -0.0285],\n",
       "                        [-0.0687, -0.1034,  0.0594]],\n",
       "              \n",
       "                       [[ 0.0280, -0.0987, -0.0678],\n",
       "                        [ 0.1042,  0.0403,  0.0423],\n",
       "                        [-0.0631, -0.0462, -0.0159]],\n",
       "              \n",
       "                       [[-0.0193, -0.0722,  0.0087],\n",
       "                        [ 0.0105, -0.0133,  0.0146],\n",
       "                        [-0.0418,  0.0274,  0.0398]],\n",
       "              \n",
       "                       [[-0.0555, -0.1045,  0.0552],\n",
       "                        [ 0.0251, -0.0536,  0.1016],\n",
       "                        [-0.0477,  0.0712,  0.0535]],\n",
       "              \n",
       "                       [[-0.0884,  0.0680, -0.0969],\n",
       "                        [-0.0584, -0.0176, -0.0711],\n",
       "                        [ 0.1030, -0.0211,  0.0419]],\n",
       "              \n",
       "                       [[-0.0941,  0.0607, -0.0328],\n",
       "                        [-0.0802,  0.0154,  0.0511],\n",
       "                        [ 0.0912, -0.0644, -0.0519]],\n",
       "              \n",
       "                       [[ 0.0203,  0.0286,  0.0405],\n",
       "                        [ 0.0579, -0.0239,  0.0586],\n",
       "                        [ 0.0777, -0.0275,  0.0750]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0515,  0.0930, -0.0599],\n",
       "                        [-0.0521, -0.0305,  0.0053],\n",
       "                        [ 0.0633, -0.0602,  0.0528]],\n",
       "              \n",
       "                       [[-0.0378,  0.0637, -0.0050],\n",
       "                        [-0.0923, -0.0580, -0.0763],\n",
       "                        [ 0.0523, -0.0707, -0.0088]],\n",
       "              \n",
       "                       [[ 0.0227, -0.0578,  0.0304],\n",
       "                        [-0.1029, -0.0754, -0.0955],\n",
       "                        [-0.0319, -0.0384,  0.0151]],\n",
       "              \n",
       "                       [[-0.0195,  0.0496,  0.0966],\n",
       "                        [ 0.0378, -0.0415, -0.0987],\n",
       "                        [ 0.0382, -0.0522,  0.0536]],\n",
       "              \n",
       "                       [[ 0.0705,  0.0407,  0.0989],\n",
       "                        [ 0.1001,  0.0223, -0.0768],\n",
       "                        [ 0.0942, -0.0500, -0.0498]],\n",
       "              \n",
       "                       [[ 0.0882,  0.0817,  0.0318],\n",
       "                        [ 0.0066, -0.0887, -0.0109],\n",
       "                        [ 0.1011,  0.0268,  0.0090]],\n",
       "              \n",
       "                       [[-0.0219, -0.0368,  0.0628],\n",
       "                        [ 0.0065,  0.0686, -0.0187],\n",
       "                        [ 0.0461,  0.0435,  0.0168]],\n",
       "              \n",
       "                       [[ 0.0662,  0.0661,  0.0977],\n",
       "                        [ 0.0810, -0.0270, -0.0892],\n",
       "                        [ 0.0193, -0.0009, -0.0275]],\n",
       "              \n",
       "                       [[-0.0177,  0.0050,  0.0769],\n",
       "                        [ 0.0329, -0.0374, -0.0433],\n",
       "                        [-0.0261, -0.0407,  0.0948]],\n",
       "              \n",
       "                       [[ 0.0558,  0.0952,  0.0003],\n",
       "                        [ 0.0213,  0.0366, -0.0998],\n",
       "                        [ 0.0094, -0.0071, -0.0591]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0818,  0.0933,  0.0857],\n",
       "                        [ 0.0489,  0.1006, -0.0428],\n",
       "                        [-0.0182,  0.0399, -0.0174]],\n",
       "              \n",
       "                       [[-0.0207, -0.0871,  0.0283],\n",
       "                        [-0.0637,  0.0038,  0.1028],\n",
       "                        [-0.0324, -0.0332,  0.0636]],\n",
       "              \n",
       "                       [[-0.0388, -0.0091,  0.0984],\n",
       "                        [-0.0432, -0.0754, -0.0590],\n",
       "                        [-0.0292, -0.0500, -0.0547]],\n",
       "              \n",
       "                       [[ 0.0426,  0.0179, -0.0337],\n",
       "                        [-0.0819, -0.0332, -0.0445],\n",
       "                        [-0.0343, -0.0951,  0.0227]],\n",
       "              \n",
       "                       [[-0.0774, -0.0821, -0.0861],\n",
       "                        [ 0.0440, -0.0635, -0.0435],\n",
       "                        [ 0.0826,  0.0560,  0.0604]],\n",
       "              \n",
       "                       [[-0.1001, -0.0756, -0.0398],\n",
       "                        [ 0.0871,  0.0108, -0.0788],\n",
       "                        [ 0.0007, -0.0819, -0.0231]],\n",
       "              \n",
       "                       [[-0.0290,  0.0912,  0.0326],\n",
       "                        [-0.0184,  0.0178, -0.0304],\n",
       "                        [ 0.0414,  0.0417,  0.0283]],\n",
       "              \n",
       "                       [[-0.0411,  0.0899, -0.0152],\n",
       "                        [-0.0410,  0.0660,  0.0859],\n",
       "                        [ 0.1049,  0.0312, -0.0359]],\n",
       "              \n",
       "                       [[ 0.0535,  0.0904, -0.1034],\n",
       "                        [-0.0131, -0.0719,  0.0196],\n",
       "                        [ 0.0436, -0.0218, -0.0088]],\n",
       "              \n",
       "                       [[ 0.0474, -0.0177, -0.0885],\n",
       "                        [ 0.0843, -0.0531, -0.0116],\n",
       "                        [ 0.0099, -0.0063, -0.0992]]]])),\n",
       "             ('conv_block_1.2.bias',\n",
       "              tensor([ 0.0484, -0.0479, -0.0547,  0.0252, -0.0550, -0.0487, -0.0355, -0.0396,\n",
       "                      -0.0440, -0.0284])),\n",
       "             ('conv_block_2.0.weight',\n",
       "              tensor([[[[ 2.7393e-02, -8.5299e-02, -6.3802e-02],\n",
       "                        [ 1.5381e-03,  1.4659e-02,  5.8217e-02],\n",
       "                        [-7.4044e-02,  3.3646e-02,  5.9914e-02]],\n",
       "              \n",
       "                       [[ 5.8530e-02, -9.8180e-02, -4.0225e-02],\n",
       "                        [-9.0606e-02, -6.6704e-02,  5.8711e-02],\n",
       "                        [-1.5740e-02,  4.4769e-02, -6.1876e-02]],\n",
       "              \n",
       "                       [[ 1.6018e-02, -6.3758e-02,  5.2693e-02],\n",
       "                        [-4.6104e-02, -2.6432e-02, -9.1456e-02],\n",
       "                        [ 3.4823e-04,  1.0008e-01,  5.1163e-02]],\n",
       "              \n",
       "                       [[-5.6240e-02,  1.4176e-03, -1.1558e-02],\n",
       "                        [-8.4862e-02,  8.2650e-02,  1.6993e-03],\n",
       "                        [ 2.2199e-02, -4.2567e-02, -4.9323e-02]],\n",
       "              \n",
       "                       [[ 1.7381e-02,  3.8971e-02,  2.3643e-02],\n",
       "                        [-5.0801e-02,  1.0234e-01, -1.5517e-02],\n",
       "                        [-6.4554e-02, -4.9301e-02,  1.0377e-01]],\n",
       "              \n",
       "                       [[ 5.0738e-06, -1.4309e-02, -4.3867e-02],\n",
       "                        [-2.7633e-02, -8.8779e-02, -8.3767e-02],\n",
       "                        [ 6.1695e-02,  9.0172e-02,  1.0059e-01]],\n",
       "              \n",
       "                       [[-7.6099e-02,  5.7012e-02, -6.5245e-02],\n",
       "                        [ 6.2883e-02,  7.6058e-02,  8.1573e-02],\n",
       "                        [ 7.5900e-02,  6.5941e-02,  2.0517e-03]],\n",
       "              \n",
       "                       [[ 4.8434e-02, -3.7712e-02,  4.5899e-02],\n",
       "                        [-3.3879e-02, -1.7700e-03, -9.1746e-02],\n",
       "                        [-2.7562e-02, -5.5432e-02, -3.5557e-02]],\n",
       "              \n",
       "                       [[-6.7313e-02, -9.4810e-02,  6.8639e-03],\n",
       "                        [ 6.8408e-02,  9.6001e-02,  6.1512e-02],\n",
       "                        [-5.4638e-02, -1.0425e-01,  3.9983e-02]],\n",
       "              \n",
       "                       [[ 5.9062e-02, -9.0495e-02,  3.7798e-02],\n",
       "                        [ 8.9121e-02,  6.3853e-03, -6.3505e-02],\n",
       "                        [ 8.6423e-02,  4.5011e-02,  6.9802e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.1287e-02,  6.1342e-02, -7.2002e-02],\n",
       "                        [ 1.0430e-01, -4.4662e-02,  6.3516e-02],\n",
       "                        [ 2.1107e-02,  2.7935e-02, -1.6165e-02]],\n",
       "              \n",
       "                       [[ 4.3295e-02, -4.3932e-02, -9.9357e-02],\n",
       "                        [-4.0499e-02,  8.2592e-02, -2.7751e-02],\n",
       "                        [ 3.3132e-02, -3.8973e-02,  7.9073e-02]],\n",
       "              \n",
       "                       [[ 6.3086e-02,  3.7211e-02, -5.3881e-02],\n",
       "                        [-8.6133e-02,  3.9686e-03, -6.1839e-02],\n",
       "                        [ 8.6667e-02, -1.0130e-01,  4.7104e-02]],\n",
       "              \n",
       "                       [[ 1.0508e-01,  5.2792e-02,  3.5942e-02],\n",
       "                        [-1.0142e-01,  1.0139e-01, -1.8030e-02],\n",
       "                        [-9.8495e-02,  1.0406e-01, -4.2894e-02]],\n",
       "              \n",
       "                       [[-7.4575e-03,  9.6479e-02, -7.3070e-02],\n",
       "                        [-7.4576e-02,  1.7141e-02, -1.4109e-02],\n",
       "                        [ 2.4280e-02, -8.8407e-02,  3.1524e-03]],\n",
       "              \n",
       "                       [[-4.6882e-02, -5.1820e-02, -9.6517e-02],\n",
       "                        [ 5.5890e-02,  2.0306e-02, -8.9118e-02],\n",
       "                        [ 8.3648e-02,  3.1794e-02,  1.9560e-02]],\n",
       "              \n",
       "                       [[-6.1890e-02,  1.5896e-02,  1.0157e-01],\n",
       "                        [ 7.2299e-02, -8.2100e-02,  9.6220e-02],\n",
       "                        [ 8.1702e-03,  5.0698e-02,  8.1869e-02]],\n",
       "              \n",
       "                       [[ 8.9862e-02, -8.2170e-02,  9.2303e-02],\n",
       "                        [-7.1591e-02,  7.9021e-03, -7.3656e-02],\n",
       "                        [-2.3109e-02, -4.7901e-03, -1.2611e-02]],\n",
       "              \n",
       "                       [[-1.6652e-02,  8.3137e-03,  1.0398e-01],\n",
       "                        [ 6.1244e-02,  5.8973e-02,  4.2190e-02],\n",
       "                        [ 8.1606e-02, -4.8645e-03,  8.3813e-03]],\n",
       "              \n",
       "                       [[ 2.1693e-02, -9.1931e-02, -8.4913e-02],\n",
       "                        [ 1.2923e-02, -4.1241e-02, -1.9342e-03],\n",
       "                        [-2.4187e-02,  1.6408e-02,  6.8581e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4958e-02,  8.4418e-02,  8.3227e-02],\n",
       "                        [-8.0901e-02, -8.1400e-02, -8.5284e-02],\n",
       "                        [-5.7766e-02, -4.1033e-02, -7.9341e-03]],\n",
       "              \n",
       "                       [[-2.5635e-02, -5.3258e-02, -3.3488e-02],\n",
       "                        [-3.8131e-02,  1.0341e-01, -3.9068e-02],\n",
       "                        [-7.5473e-02,  4.3818e-02, -6.0886e-03]],\n",
       "              \n",
       "                       [[ 8.0698e-02,  6.5863e-02,  9.6843e-02],\n",
       "                        [-7.7197e-02,  6.7764e-02,  8.8464e-02],\n",
       "                        [-5.2054e-02,  9.6890e-02,  7.9019e-02]],\n",
       "              \n",
       "                       [[ 1.1544e-03,  5.0823e-02, -3.6853e-02],\n",
       "                        [-9.1936e-02,  2.6645e-02,  3.1425e-02],\n",
       "                        [-6.8891e-02,  5.1123e-02, -9.0043e-02]],\n",
       "              \n",
       "                       [[ 9.0718e-02,  1.0208e-01,  2.8699e-02],\n",
       "                        [-6.6137e-02,  5.1300e-02,  1.7963e-02],\n",
       "                        [ 2.8663e-02,  3.4643e-02,  8.0254e-02]],\n",
       "              \n",
       "                       [[-4.5309e-02, -2.3711e-02,  2.8746e-02],\n",
       "                        [ 1.1486e-02,  8.5000e-02, -5.5365e-02],\n",
       "                        [-3.8387e-03,  1.9696e-02, -2.7996e-02]],\n",
       "              \n",
       "                       [[ 7.1859e-02,  1.1530e-02, -9.7422e-02],\n",
       "                        [-1.1420e-02, -4.7809e-02,  1.0243e-02],\n",
       "                        [-1.2250e-02, -1.0456e-01, -1.9208e-02]],\n",
       "              \n",
       "                       [[-1.0096e-02, -3.1083e-02,  9.6848e-02],\n",
       "                        [-2.3000e-02,  6.7717e-02,  2.6112e-02],\n",
       "                        [-8.8979e-02,  2.4770e-02,  8.7356e-02]],\n",
       "              \n",
       "                       [[-6.8948e-02, -6.8134e-02,  1.0318e-01],\n",
       "                        [ 8.4697e-02, -5.8807e-02,  6.3429e-02],\n",
       "                        [-1.3485e-02, -1.0393e-01,  7.9198e-03]],\n",
       "              \n",
       "                       [[ 3.4057e-02, -3.1619e-02,  3.6670e-02],\n",
       "                        [-9.0136e-02,  7.3050e-02,  8.9865e-02],\n",
       "                        [ 5.8130e-02,  1.7866e-02,  3.4716e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.6269e-02, -2.6339e-02, -1.0063e-02],\n",
       "                        [-5.8659e-02, -7.7857e-02,  7.0900e-02],\n",
       "                        [ 7.1535e-02, -9.5731e-02,  3.3542e-02]],\n",
       "              \n",
       "                       [[ 4.2881e-02,  1.0014e-01,  6.0985e-02],\n",
       "                        [ 9.6907e-02, -3.4510e-02,  7.3827e-02],\n",
       "                        [ 8.5740e-02, -9.9541e-02, -8.4613e-02]],\n",
       "              \n",
       "                       [[ 2.1335e-02,  5.7557e-02, -5.2369e-02],\n",
       "                        [ 1.1609e-02, -1.5303e-04,  2.6680e-02],\n",
       "                        [-5.6642e-02,  5.9455e-02,  7.0098e-02]],\n",
       "              \n",
       "                       [[-7.3139e-02,  1.0211e-03,  2.9247e-04],\n",
       "                        [ 3.3849e-02,  9.8198e-02,  3.0913e-02],\n",
       "                        [-2.3951e-02,  9.4672e-02, -4.0112e-02]],\n",
       "              \n",
       "                       [[-3.0608e-02,  7.1969e-03, -8.0270e-02],\n",
       "                        [ 1.1470e-02, -7.1518e-02,  1.0838e-02],\n",
       "                        [ 1.0099e-02,  1.4591e-02, -8.8891e-02]],\n",
       "              \n",
       "                       [[-1.0012e-01,  4.8501e-02,  9.0399e-02],\n",
       "                        [-9.3537e-02,  3.9043e-02, -7.7594e-02],\n",
       "                        [ 6.6082e-03,  9.8068e-02,  7.9965e-02]],\n",
       "              \n",
       "                       [[-7.7069e-02,  6.5203e-02,  5.5057e-02],\n",
       "                        [-1.6169e-04,  1.0211e-01, -4.1866e-02],\n",
       "                        [-2.4530e-02, -5.3275e-02,  1.5168e-02]],\n",
       "              \n",
       "                       [[ 2.7911e-02,  8.3990e-03, -5.9307e-02],\n",
       "                        [-4.7452e-02,  3.5855e-02, -9.2426e-02],\n",
       "                        [-1.6416e-02, -2.3350e-03, -4.2708e-02]],\n",
       "              \n",
       "                       [[ 3.8360e-02,  6.7940e-03,  7.4004e-02],\n",
       "                        [-9.3616e-03, -6.6528e-02,  7.4477e-02],\n",
       "                        [ 1.4720e-02, -3.0189e-02, -6.9476e-02]],\n",
       "              \n",
       "                       [[ 2.4707e-02, -1.0053e-01,  2.7762e-02],\n",
       "                        [ 5.2119e-02, -9.2465e-02, -6.9009e-02],\n",
       "                        [-7.5781e-02,  8.8597e-02,  8.9611e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.5987e-03,  9.8959e-02, -3.5239e-02],\n",
       "                        [-1.0233e-01,  3.6819e-02,  3.7343e-02],\n",
       "                        [ 1.0334e-01, -3.0510e-05,  8.0785e-02]],\n",
       "              \n",
       "                       [[ 6.4612e-02,  7.6292e-02, -1.0460e-01],\n",
       "                        [ 8.6800e-02, -8.9856e-02,  9.4501e-02],\n",
       "                        [-4.3682e-03, -9.3415e-02,  2.9314e-02]],\n",
       "              \n",
       "                       [[-2.1456e-02, -9.4678e-02, -3.8215e-02],\n",
       "                        [ 1.0868e-02,  8.2098e-02, -3.2406e-02],\n",
       "                        [ 6.2610e-02,  1.3200e-02,  3.5531e-03]],\n",
       "              \n",
       "                       [[ 2.0170e-02, -6.9177e-02, -8.7616e-02],\n",
       "                        [-3.3121e-02, -9.8226e-02, -4.9158e-02],\n",
       "                        [ 4.8494e-03, -6.9424e-02, -4.3723e-02]],\n",
       "              \n",
       "                       [[-1.8941e-02, -1.2144e-02, -5.8187e-02],\n",
       "                        [ 5.0650e-03, -1.4795e-02,  3.0147e-02],\n",
       "                        [ 4.7611e-03, -5.2638e-02, -3.6291e-02]],\n",
       "              \n",
       "                       [[-1.2149e-03, -6.5774e-02,  8.2520e-03],\n",
       "                        [-7.4425e-03,  4.0897e-02,  2.4947e-02],\n",
       "                        [ 7.8887e-02, -3.4749e-03, -7.7887e-02]],\n",
       "              \n",
       "                       [[ 4.7119e-02, -7.1240e-02, -1.4489e-02],\n",
       "                        [-3.4132e-02, -3.9997e-02, -3.9000e-02],\n",
       "                        [ 9.6863e-02,  6.0342e-02,  2.9213e-02]],\n",
       "              \n",
       "                       [[ 9.8975e-02, -9.5524e-02,  1.7010e-02],\n",
       "                        [ 6.7481e-02,  7.0022e-02, -8.3890e-02],\n",
       "                        [ 3.7514e-02, -6.0050e-02, -4.1187e-03]],\n",
       "              \n",
       "                       [[-2.1996e-02, -8.8013e-02, -1.0055e-01],\n",
       "                        [-6.9349e-02,  4.7832e-02,  4.8218e-02],\n",
       "                        [-9.1681e-02, -3.9586e-02,  1.7218e-03]],\n",
       "              \n",
       "                       [[-9.1135e-02,  5.9393e-02,  9.5473e-02],\n",
       "                        [ 1.8643e-02, -7.8321e-02,  2.4580e-02],\n",
       "                        [ 3.8265e-02,  8.3468e-02, -5.6085e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.4437e-02,  4.6312e-02,  6.5624e-03],\n",
       "                        [-3.4345e-02, -4.4169e-02, -5.4351e-02],\n",
       "                        [ 8.5328e-02, -1.8187e-02,  7.6022e-02]],\n",
       "              \n",
       "                       [[ 9.4094e-02,  1.3353e-02,  2.2454e-02],\n",
       "                        [-7.1789e-03,  7.2397e-02, -9.4983e-02],\n",
       "                        [ 4.1919e-02, -1.7174e-02,  4.8132e-02]],\n",
       "              \n",
       "                       [[-4.6949e-04, -3.9029e-02, -1.1379e-02],\n",
       "                        [ 5.6920e-02, -7.3210e-02, -6.6629e-02],\n",
       "                        [-2.3611e-02, -3.8235e-02,  4.1409e-02]],\n",
       "              \n",
       "                       [[ 7.0937e-02, -1.1289e-02,  9.9672e-02],\n",
       "                        [-4.4042e-02, -5.9151e-02, -4.7191e-02],\n",
       "                        [-7.2624e-02, -7.3885e-02, -9.3921e-02]],\n",
       "              \n",
       "                       [[-9.3422e-02,  2.7512e-02,  6.4284e-02],\n",
       "                        [ 9.8963e-02,  8.9787e-02, -6.0709e-03],\n",
       "                        [ 2.0454e-02, -6.3068e-02,  4.0743e-02]],\n",
       "              \n",
       "                       [[-1.0107e-01,  4.9719e-02,  1.9334e-02],\n",
       "                        [ 3.2393e-02,  3.8595e-02, -4.8394e-02],\n",
       "                        [ 9.0452e-02,  5.0307e-02,  6.9243e-02]],\n",
       "              \n",
       "                       [[ 1.3922e-02,  6.6196e-02,  7.0941e-02],\n",
       "                        [ 4.7775e-02,  8.0297e-02, -1.9119e-02],\n",
       "                        [ 6.9310e-02,  2.4286e-02,  6.3424e-02]],\n",
       "              \n",
       "                       [[ 1.0267e-01,  2.3869e-02, -3.9124e-02],\n",
       "                        [-1.0488e-02,  2.9676e-02,  1.7773e-02],\n",
       "                        [-2.8795e-02,  8.2590e-02,  6.3331e-02]],\n",
       "              \n",
       "                       [[-6.5475e-02, -8.5889e-03, -1.0119e-02],\n",
       "                        [-6.6063e-02,  1.5374e-02, -3.2360e-02],\n",
       "                        [-5.4419e-02, -3.3894e-02, -3.7584e-02]],\n",
       "              \n",
       "                       [[ 1.0084e-01,  4.0432e-02,  1.0373e-01],\n",
       "                        [ 2.8903e-02,  2.3868e-02,  4.3333e-02],\n",
       "                        [ 1.8092e-02, -8.2722e-02, -6.2334e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5538e-02,  1.5846e-03,  3.9709e-02],\n",
       "                        [ 4.0588e-02,  8.3623e-02,  2.1458e-02],\n",
       "                        [-3.5975e-02, -7.9271e-02, -7.7203e-02]],\n",
       "              \n",
       "                       [[-6.2965e-02,  3.1792e-02,  5.6950e-02],\n",
       "                        [ 9.2224e-02, -3.3342e-02, -8.3150e-03],\n",
       "                        [-3.1303e-02, -3.8517e-04,  3.3837e-02]],\n",
       "              \n",
       "                       [[-2.3160e-03,  4.8799e-03,  1.3354e-02],\n",
       "                        [ 3.9256e-02, -3.1981e-02, -6.2855e-02],\n",
       "                        [ 2.4869e-02, -1.2481e-02, -4.7753e-02]],\n",
       "              \n",
       "                       [[ 4.4268e-02,  9.5597e-04, -1.5333e-02],\n",
       "                        [-5.1027e-02, -1.3868e-02, -8.9632e-02],\n",
       "                        [ 2.3980e-02,  1.5818e-03,  6.3966e-02]],\n",
       "              \n",
       "                       [[ 6.8063e-03,  8.4277e-03,  2.8715e-02],\n",
       "                        [ 8.0210e-02, -4.9812e-02,  6.2930e-02],\n",
       "                        [ 2.5779e-02, -7.0320e-02,  3.6702e-02]],\n",
       "              \n",
       "                       [[-6.3217e-02, -3.3181e-02, -5.0245e-02],\n",
       "                        [-7.1711e-02,  8.3017e-02, -9.4217e-02],\n",
       "                        [ 5.2706e-02, -9.4870e-02, -1.2829e-02]],\n",
       "              \n",
       "                       [[ 6.2868e-03,  7.4937e-02, -3.8147e-02],\n",
       "                        [ 3.0340e-02,  1.6329e-02,  6.2021e-02],\n",
       "                        [ 6.2668e-03,  3.9470e-02, -6.3677e-02]],\n",
       "              \n",
       "                       [[-7.3250e-02,  9.3928e-02, -7.6808e-02],\n",
       "                        [-1.7945e-02, -1.2742e-02,  1.0308e-01],\n",
       "                        [-2.2780e-02, -8.0249e-02, -2.6721e-02]],\n",
       "              \n",
       "                       [[ 5.4372e-02,  4.1773e-02,  8.7204e-02],\n",
       "                        [-2.1579e-02,  4.9653e-02, -9.9194e-02],\n",
       "                        [ 4.0787e-02,  4.8432e-02,  6.7998e-02]],\n",
       "              \n",
       "                       [[-6.0446e-02, -2.8142e-02,  2.5502e-02],\n",
       "                        [-7.4905e-02, -8.3851e-02, -1.0141e-01],\n",
       "                        [ 5.8842e-03,  6.5458e-02,  2.7075e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.4263e-03,  3.6727e-02, -6.6240e-02],\n",
       "                        [ 1.1113e-02, -2.6186e-02, -5.2193e-02],\n",
       "                        [ 9.0902e-02, -8.1550e-02,  1.5448e-02]],\n",
       "              \n",
       "                       [[-9.2624e-02, -3.5762e-03, -4.6840e-02],\n",
       "                        [ 3.4695e-02, -5.9191e-02,  6.7466e-02],\n",
       "                        [-8.5536e-02,  6.3313e-02, -7.9181e-02]],\n",
       "              \n",
       "                       [[ 5.6456e-02, -4.4384e-02, -2.4556e-04],\n",
       "                        [-1.9238e-02,  6.8414e-02,  3.4546e-02],\n",
       "                        [-9.2887e-02,  9.6914e-03, -7.2718e-02]],\n",
       "              \n",
       "                       [[ 7.8800e-02,  1.7319e-02, -2.7109e-02],\n",
       "                        [-5.3777e-02,  3.6485e-02, -6.3129e-02],\n",
       "                        [ 4.9992e-02,  5.7519e-02,  6.4701e-02]],\n",
       "              \n",
       "                       [[ 2.7537e-02, -9.2272e-02,  7.5823e-02],\n",
       "                        [-3.2700e-02, -3.1163e-02, -1.1325e-02],\n",
       "                        [ 7.7068e-02,  8.1052e-02,  1.6276e-02]],\n",
       "              \n",
       "                       [[ 5.0296e-02, -9.8241e-02,  2.4901e-04],\n",
       "                        [-9.3254e-02,  3.5876e-02, -7.5099e-02],\n",
       "                        [-3.7568e-02,  7.3684e-02,  1.0074e-01]],\n",
       "              \n",
       "                       [[-6.3286e-02, -5.8503e-02,  1.3055e-02],\n",
       "                        [ 4.1437e-02, -1.7168e-02, -3.2918e-02],\n",
       "                        [-6.9237e-02,  4.4997e-02,  1.0328e-01]],\n",
       "              \n",
       "                       [[-5.1026e-02,  4.9718e-02,  5.1481e-02],\n",
       "                        [ 8.4728e-02, -1.2001e-02,  3.3202e-03],\n",
       "                        [ 7.7444e-02,  6.6631e-02,  1.0411e-01]],\n",
       "              \n",
       "                       [[-3.0207e-02,  4.1709e-02,  7.3605e-02],\n",
       "                        [-7.1553e-02,  2.0940e-02, -2.3586e-02],\n",
       "                        [ 6.7760e-02, -4.7342e-02,  7.3933e-03]],\n",
       "              \n",
       "                       [[ 6.3067e-02, -9.6567e-02, -8.9004e-02],\n",
       "                        [-5.3989e-02,  6.7611e-02,  7.0680e-02],\n",
       "                        [-7.1991e-02,  2.0100e-02, -5.5854e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8926e-02,  9.0907e-02,  5.0914e-02],\n",
       "                        [-2.8828e-02,  1.5516e-02,  2.0424e-02],\n",
       "                        [ 2.4691e-02, -3.6079e-02, -6.2074e-02]],\n",
       "              \n",
       "                       [[ 6.9788e-02,  1.4164e-02,  4.4119e-02],\n",
       "                        [-3.9922e-02,  5.1057e-02,  7.6713e-02],\n",
       "                        [ 6.4107e-02,  2.8660e-02,  1.0371e-01]],\n",
       "              \n",
       "                       [[-2.3053e-04,  2.2441e-02,  1.0015e-01],\n",
       "                        [ 1.0245e-01, -4.4506e-02,  9.4953e-02],\n",
       "                        [ 3.8902e-02, -1.1799e-02,  9.2038e-02]],\n",
       "              \n",
       "                       [[-5.4605e-02,  6.8490e-02,  1.0445e-01],\n",
       "                        [-7.2701e-02, -6.2201e-02, -1.0445e-01],\n",
       "                        [-1.8970e-02, -9.5733e-02, -3.5304e-02]],\n",
       "              \n",
       "                       [[ 3.2002e-02,  7.4511e-02,  5.8717e-02],\n",
       "                        [ 5.8511e-02,  4.3730e-02, -6.5378e-02],\n",
       "                        [-8.3694e-02,  4.3696e-03,  1.0009e-01]],\n",
       "              \n",
       "                       [[ 5.9351e-03, -9.0662e-03, -7.1545e-02],\n",
       "                        [-5.2266e-02, -8.1256e-02,  8.4398e-02],\n",
       "                        [-1.7174e-02, -9.3119e-02,  1.1308e-02]],\n",
       "              \n",
       "                       [[ 7.6494e-03, -1.3023e-02,  3.7733e-02],\n",
       "                        [ 5.6687e-02, -9.9128e-02, -8.0753e-02],\n",
       "                        [-5.0639e-03, -9.7729e-02, -9.5750e-02]],\n",
       "              \n",
       "                       [[ 9.3067e-02, -8.0174e-03, -5.2113e-02],\n",
       "                        [-3.6157e-02, -8.2295e-02,  8.2258e-02],\n",
       "                        [-2.2857e-02, -5.9265e-02, -7.9944e-02]],\n",
       "              \n",
       "                       [[ 6.1611e-02, -1.4571e-02, -1.1074e-02],\n",
       "                        [-2.7473e-02, -5.0883e-02,  1.8751e-02],\n",
       "                        [ 8.1099e-02, -6.1093e-02,  5.0504e-03]],\n",
       "              \n",
       "                       [[-8.0165e-02, -4.9426e-02,  9.2525e-02],\n",
       "                        [ 1.1052e-03,  1.0154e-01, -1.8468e-02],\n",
       "                        [-5.7453e-02, -6.2981e-02,  9.3426e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.1058e-02,  5.5318e-02,  2.6203e-02],\n",
       "                        [ 3.1107e-02,  5.9476e-02, -2.7577e-02],\n",
       "                        [ 6.5223e-02, -8.3982e-02, -3.7087e-02]],\n",
       "              \n",
       "                       [[ 7.7164e-02,  3.1283e-02, -1.4038e-02],\n",
       "                        [-2.4616e-02, -6.4364e-02,  6.4098e-02],\n",
       "                        [-3.3520e-03, -3.5664e-03,  2.4929e-02]],\n",
       "              \n",
       "                       [[ 7.7787e-02, -5.3778e-02, -3.6303e-02],\n",
       "                        [ 7.1429e-02,  5.9532e-02, -5.1855e-02],\n",
       "                        [-1.0428e-01,  1.9555e-02,  5.5434e-02]],\n",
       "              \n",
       "                       [[ 2.5178e-02,  7.4768e-02, -8.3640e-02],\n",
       "                        [ 5.3156e-02, -6.5531e-02,  5.9325e-02],\n",
       "                        [ 7.8394e-02,  3.3385e-02,  8.5284e-02]],\n",
       "              \n",
       "                       [[-6.9481e-02, -9.4275e-02, -1.0135e-01],\n",
       "                        [ 6.6179e-02,  3.6926e-02, -7.7188e-02],\n",
       "                        [ 5.1048e-02,  9.6177e-02, -1.0394e-01]],\n",
       "              \n",
       "                       [[ 7.6466e-02,  1.6167e-02,  9.8053e-03],\n",
       "                        [ 9.4847e-02,  9.5458e-02,  4.4414e-02],\n",
       "                        [ 8.3288e-02,  4.3853e-02,  1.7176e-02]],\n",
       "              \n",
       "                       [[-9.2656e-02,  1.9689e-02, -7.4993e-02],\n",
       "                        [ 3.2452e-02,  1.8598e-02,  2.3681e-03],\n",
       "                        [-7.2071e-02, -6.3899e-02,  7.7912e-02]],\n",
       "              \n",
       "                       [[ 5.1336e-02,  5.5576e-02, -3.1410e-02],\n",
       "                        [-1.8151e-02, -2.7014e-02,  7.2489e-02],\n",
       "                        [-4.5504e-02,  6.6394e-02,  7.2679e-02]],\n",
       "              \n",
       "                       [[-9.6403e-02,  6.4369e-04, -2.0076e-02],\n",
       "                        [-5.8273e-02,  4.5507e-02, -1.2807e-02],\n",
       "                        [ 9.2287e-02, -6.5976e-02,  4.8976e-02]],\n",
       "              \n",
       "                       [[-8.9998e-02, -5.2833e-02,  7.1903e-03],\n",
       "                        [ 8.3283e-02,  5.5521e-02, -8.6550e-02],\n",
       "                        [ 1.1676e-02, -6.2138e-02,  4.5674e-03]]]])),\n",
       "             ('conv_block_2.0.bias',\n",
       "              tensor([-0.0878, -0.0309,  0.0723, -0.0967, -0.1005,  0.0192,  0.0144, -0.0193,\n",
       "                       0.0920, -0.0635])),\n",
       "             ('conv_block_2.2.weight',\n",
       "              tensor([[[[-6.3992e-02, -7.8791e-02, -1.9619e-02],\n",
       "                        [-2.6901e-02,  6.5222e-02, -5.9186e-03],\n",
       "                        [ 3.3663e-02, -4.3804e-02,  8.5507e-02]],\n",
       "              \n",
       "                       [[ 8.8862e-02, -9.4401e-02, -2.7090e-02],\n",
       "                        [-8.9439e-02,  4.4781e-02, -9.2094e-02],\n",
       "                        [-4.9839e-02,  1.0532e-01, -1.0066e-01]],\n",
       "              \n",
       "                       [[ 7.7771e-02,  8.9049e-03,  8.4289e-02],\n",
       "                        [-5.3494e-02,  6.9236e-02,  1.2718e-02],\n",
       "                        [ 8.1073e-03,  7.1945e-02, -1.0019e-01]],\n",
       "              \n",
       "                       [[-8.4902e-02,  1.0180e-01, -6.3298e-02],\n",
       "                        [-7.5980e-02, -5.1539e-03, -3.3742e-02],\n",
       "                        [-1.4421e-02, -7.0623e-02,  3.8034e-02]],\n",
       "              \n",
       "                       [[-9.0703e-02,  8.5374e-03,  6.1510e-02],\n",
       "                        [ 2.0253e-02,  1.4006e-02,  1.5418e-02],\n",
       "                        [-3.0880e-02, -2.0080e-02, -4.4450e-02]],\n",
       "              \n",
       "                       [[-7.1207e-02, -5.5810e-02,  1.0420e-01],\n",
       "                        [-1.7641e-02,  3.6924e-02,  7.2896e-02],\n",
       "                        [-8.2343e-03, -5.6707e-02, -7.1419e-02]],\n",
       "              \n",
       "                       [[-3.8833e-02,  3.7624e-02, -8.8771e-02],\n",
       "                        [-1.2870e-02,  4.0096e-02,  8.5999e-02],\n",
       "                        [ 3.1721e-02,  2.0846e-02,  7.2162e-02]],\n",
       "              \n",
       "                       [[ 4.8708e-02,  3.5661e-02, -3.2682e-02],\n",
       "                        [-8.4528e-02, -2.2769e-02, -1.9117e-02],\n",
       "                        [ 7.7410e-03, -1.1593e-02,  4.2616e-02]],\n",
       "              \n",
       "                       [[ 7.0050e-02, -4.2735e-02, -1.0002e-01],\n",
       "                        [-5.4081e-02, -5.0436e-02,  5.9750e-02],\n",
       "                        [-6.7994e-02, -9.9145e-03, -2.2340e-02]],\n",
       "              \n",
       "                       [[-6.3976e-02,  4.7780e-02, -4.3909e-02],\n",
       "                        [-5.4531e-03, -7.4112e-02, -1.0632e-02],\n",
       "                        [ 1.4977e-02, -4.2894e-03, -3.9386e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.1315e-02, -2.7311e-02, -5.8439e-02],\n",
       "                        [-7.7732e-02, -2.2329e-02, -9.9578e-02],\n",
       "                        [ 8.7492e-02, -5.0357e-02, -4.3684e-02]],\n",
       "              \n",
       "                       [[ 9.7439e-03,  2.7326e-02, -9.9393e-03],\n",
       "                        [ 7.2313e-02, -6.1448e-02,  3.7777e-02],\n",
       "                        [-2.3773e-04, -8.5747e-02, -4.0824e-02]],\n",
       "              \n",
       "                       [[ 2.6825e-02,  2.0138e-02,  7.6647e-02],\n",
       "                        [ 7.0518e-02, -5.7493e-02, -4.5013e-02],\n",
       "                        [-2.2351e-02, -7.5517e-02, -2.8459e-02]],\n",
       "              \n",
       "                       [[-8.6258e-02,  4.0092e-02,  7.4583e-02],\n",
       "                        [ 8.3459e-03, -7.5460e-02, -7.9827e-02],\n",
       "                        [-4.1036e-02,  3.0659e-02,  2.5711e-03]],\n",
       "              \n",
       "                       [[ 1.9166e-02,  9.9346e-02,  4.8956e-02],\n",
       "                        [ 2.2665e-02, -2.1327e-02,  4.9864e-02],\n",
       "                        [ 3.8563e-02, -9.4879e-02, -6.2266e-02]],\n",
       "              \n",
       "                       [[ 3.5381e-03,  3.9997e-02,  5.1282e-02],\n",
       "                        [-6.2748e-02, -1.0458e-01, -5.4909e-03],\n",
       "                        [-1.2050e-02,  3.0588e-02, -2.8988e-02]],\n",
       "              \n",
       "                       [[ 8.0588e-02,  7.0333e-03,  7.6975e-02],\n",
       "                        [-7.3398e-02,  4.2167e-02,  1.2560e-02],\n",
       "                        [-5.2720e-02,  5.2256e-02, -1.0372e-01]],\n",
       "              \n",
       "                       [[ 8.5220e-02,  8.4947e-03,  1.0178e-02],\n",
       "                        [ 4.8746e-02,  8.7503e-03,  4.5184e-02],\n",
       "                        [ 6.7063e-02, -8.2268e-02,  6.9735e-02]],\n",
       "              \n",
       "                       [[-1.5784e-02, -2.4513e-02,  2.1217e-02],\n",
       "                        [ 8.2446e-02, -5.7302e-02, -7.1039e-02],\n",
       "                        [ 6.5418e-02, -4.9507e-02,  3.3937e-02]],\n",
       "              \n",
       "                       [[-1.5530e-02,  2.9014e-02,  8.0439e-02],\n",
       "                        [-5.3421e-02, -5.1151e-02,  5.1716e-02],\n",
       "                        [ 5.7714e-03, -1.1601e-02, -9.2590e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.9309e-02, -3.9919e-03, -1.9415e-02],\n",
       "                        [-4.3269e-02, -2.0801e-02,  5.1233e-02],\n",
       "                        [-2.4227e-03,  9.0147e-02, -6.0858e-03]],\n",
       "              \n",
       "                       [[-1.5122e-02,  5.9498e-02, -2.7275e-03],\n",
       "                        [-2.1039e-02,  3.5231e-02,  8.3129e-02],\n",
       "                        [ 2.6305e-02,  7.3398e-02,  6.8309e-02]],\n",
       "              \n",
       "                       [[ 2.9810e-02,  3.6650e-02,  3.4014e-02],\n",
       "                        [ 1.0934e-02,  8.9675e-02,  9.7308e-02],\n",
       "                        [ 3.7524e-02, -5.2640e-03,  9.4509e-02]],\n",
       "              \n",
       "                       [[-8.2042e-02,  7.7453e-02,  5.5849e-02],\n",
       "                        [ 6.7687e-02, -8.0992e-03, -7.8646e-02],\n",
       "                        [ 7.5193e-02, -4.6091e-02,  2.7734e-02]],\n",
       "              \n",
       "                       [[ 5.9719e-02, -9.8508e-02,  6.9954e-03],\n",
       "                        [-3.7444e-02,  7.4815e-02, -6.7114e-02],\n",
       "                        [ 6.4001e-02,  6.5730e-02,  5.8156e-02]],\n",
       "              \n",
       "                       [[ 1.0119e-01,  1.5964e-02, -9.5541e-02],\n",
       "                        [ 7.5248e-02,  9.6499e-03,  2.0918e-03],\n",
       "                        [-1.0041e-01, -2.3691e-02, -5.1162e-02]],\n",
       "              \n",
       "                       [[ 1.0324e-01,  7.5054e-02,  7.8634e-02],\n",
       "                        [ 7.2188e-02, -6.5340e-02, -4.5270e-02],\n",
       "                        [-4.1252e-02, -4.2257e-02,  8.2054e-02]],\n",
       "              \n",
       "                       [[ 3.5815e-02,  8.4470e-02, -4.9309e-03],\n",
       "                        [-9.3965e-02, -3.0582e-02,  7.4081e-02],\n",
       "                        [ 6.4174e-02,  3.2632e-02, -3.0919e-02]],\n",
       "              \n",
       "                       [[-9.8386e-02, -5.6639e-02,  5.4958e-02],\n",
       "                        [-4.2518e-02,  5.0421e-02,  2.8781e-02],\n",
       "                        [-4.0486e-02,  6.4202e-02, -3.3871e-02]],\n",
       "              \n",
       "                       [[-3.5020e-03, -4.0152e-02, -9.9988e-02],\n",
       "                        [ 1.6996e-02,  3.0460e-02, -5.3072e-02],\n",
       "                        [ 6.4663e-02, -9.4558e-02, -1.0161e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.5106e-02, -3.6430e-02, -1.1707e-02],\n",
       "                        [-2.0370e-02,  4.8108e-02, -9.2510e-02],\n",
       "                        [ 1.5521e-02,  1.8254e-03,  2.7842e-02]],\n",
       "              \n",
       "                       [[ 1.0479e-01,  6.4874e-02, -5.8366e-02],\n",
       "                        [-8.6378e-02, -2.5520e-02, -5.2876e-02],\n",
       "                        [ 3.6820e-02,  9.6628e-04,  8.4783e-02]],\n",
       "              \n",
       "                       [[ 4.1405e-02, -1.9382e-02,  3.6229e-03],\n",
       "                        [ 2.5244e-02, -1.3080e-02,  8.5058e-02],\n",
       "                        [-8.2420e-02,  5.1377e-02, -6.7192e-02]],\n",
       "              \n",
       "                       [[-9.2347e-02, -2.1640e-02,  5.1366e-02],\n",
       "                        [ 7.4478e-02,  2.6452e-02, -9.1104e-03],\n",
       "                        [-5.9092e-03, -4.2731e-02, -9.4592e-03]],\n",
       "              \n",
       "                       [[-7.2831e-03,  8.9699e-02,  6.1690e-02],\n",
       "                        [-8.4351e-02,  4.3605e-04, -6.4834e-02],\n",
       "                        [-1.6733e-02, -8.3776e-02,  2.7402e-02]],\n",
       "              \n",
       "                       [[-7.6008e-02,  1.0406e-01,  7.9605e-02],\n",
       "                        [-7.2559e-02, -9.9239e-02,  4.1128e-03],\n",
       "                        [-2.9425e-02,  3.0945e-02, -7.1353e-02]],\n",
       "              \n",
       "                       [[ 4.3148e-02, -9.1047e-02, -5.5632e-02],\n",
       "                        [-5.5414e-02,  5.1007e-02, -2.7597e-03],\n",
       "                        [-1.0130e-01, -6.0201e-02, -4.8781e-02]],\n",
       "              \n",
       "                       [[-9.7802e-02,  1.3497e-02,  3.7561e-02],\n",
       "                        [-1.9340e-02, -4.1947e-02, -6.3926e-04],\n",
       "                        [-8.3725e-02, -6.4184e-02, -2.4040e-03]],\n",
       "              \n",
       "                       [[ 9.3643e-02, -3.2414e-02,  5.2247e-02],\n",
       "                        [-4.1484e-02, -2.8060e-02, -1.0034e-01],\n",
       "                        [ 8.7330e-02,  1.0264e-01, -2.2139e-03]],\n",
       "              \n",
       "                       [[ 6.6974e-02,  8.6219e-02,  5.2359e-02],\n",
       "                        [ 5.4288e-02, -1.0035e-01, -9.9050e-02],\n",
       "                        [-8.0906e-02,  3.2970e-02, -9.1177e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.0464e-02, -5.1092e-02, -9.7154e-02],\n",
       "                        [ 1.4203e-04,  1.5207e-02, -6.1686e-02],\n",
       "                        [ 6.9018e-02, -4.0018e-02, -2.9676e-02]],\n",
       "              \n",
       "                       [[ 8.0309e-02,  9.0499e-02, -1.2093e-02],\n",
       "                        [-7.5671e-02, -5.2881e-02,  1.3423e-02],\n",
       "                        [ 6.1790e-02,  5.2477e-02, -4.6547e-02]],\n",
       "              \n",
       "                       [[-9.9650e-02, -9.2249e-02, -3.3537e-02],\n",
       "                        [ 1.3223e-03, -4.7347e-02, -8.3348e-02],\n",
       "                        [ 1.1109e-02, -8.3668e-02, -8.0946e-02]],\n",
       "              \n",
       "                       [[-8.5692e-02, -2.8563e-02,  9.3104e-02],\n",
       "                        [ 4.1207e-02, -1.2498e-02,  2.1694e-02],\n",
       "                        [ 4.1975e-02,  6.1414e-04, -8.5020e-02]],\n",
       "              \n",
       "                       [[-6.4944e-02, -7.1610e-02, -2.6766e-03],\n",
       "                        [-9.6492e-02, -1.9166e-02, -3.8545e-02],\n",
       "                        [ 1.0345e-01,  8.5679e-02,  6.1227e-02]],\n",
       "              \n",
       "                       [[ 5.9116e-03, -3.4129e-02,  2.6887e-02],\n",
       "                        [-7.2830e-02, -4.4957e-02, -2.1175e-02],\n",
       "                        [-2.4766e-02, -9.9854e-02,  4.1903e-02]],\n",
       "              \n",
       "                       [[ 8.6803e-02, -5.8141e-02,  2.8415e-02],\n",
       "                        [-1.2225e-02, -3.8445e-03,  6.1443e-03],\n",
       "                        [ 9.1346e-02,  1.4124e-02, -6.6690e-02]],\n",
       "              \n",
       "                       [[-3.7917e-02,  5.1495e-02,  3.2893e-02],\n",
       "                        [ 2.0487e-03, -1.3912e-02, -4.1012e-02],\n",
       "                        [-3.7413e-02, -5.5602e-02,  1.7273e-02]],\n",
       "              \n",
       "                       [[ 2.9603e-02,  8.0717e-02, -2.3813e-02],\n",
       "                        [ 7.5461e-03,  6.8125e-02,  4.5852e-02],\n",
       "                        [ 1.3544e-02,  3.2390e-02,  5.4714e-03]],\n",
       "              \n",
       "                       [[-9.0419e-02,  4.0636e-03, -2.3040e-02],\n",
       "                        [ 9.5123e-02,  9.5145e-02,  2.0912e-02],\n",
       "                        [ 9.4215e-02, -5.4288e-02,  9.1619e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 9.0756e-02, -4.0288e-03, -8.4592e-02],\n",
       "                        [-3.4015e-02, -2.8189e-02,  1.7411e-03],\n",
       "                        [-9.5569e-02,  1.9535e-02, -4.3839e-02]],\n",
       "              \n",
       "                       [[-2.6989e-02, -5.4443e-02, -2.2255e-02],\n",
       "                        [-9.7896e-02, -5.5885e-02,  9.7108e-03],\n",
       "                        [ 6.9072e-02,  9.5790e-02, -7.9737e-02]],\n",
       "              \n",
       "                       [[ 4.4264e-02, -5.9419e-02, -8.1498e-02],\n",
       "                        [-4.6417e-03, -6.0468e-02, -9.0783e-02],\n",
       "                        [-9.8509e-02, -7.0556e-02,  8.6619e-02]],\n",
       "              \n",
       "                       [[ 5.8788e-02, -4.1726e-02, -7.0553e-02],\n",
       "                        [-8.1085e-02, -6.2246e-02, -4.3376e-02],\n",
       "                        [ 6.3308e-02,  3.4496e-02, -4.0622e-02]],\n",
       "              \n",
       "                       [[ 7.2567e-02, -6.5484e-02, -8.5876e-02],\n",
       "                        [ 2.3006e-02, -5.8123e-02,  2.9987e-02],\n",
       "                        [ 8.9306e-02, -4.9849e-02, -7.3556e-02]],\n",
       "              \n",
       "                       [[ 3.9676e-02, -9.5200e-02,  9.4044e-02],\n",
       "                        [-4.9780e-02,  5.0961e-02, -8.3818e-02],\n",
       "                        [-7.1348e-02,  1.1611e-02,  3.7463e-02]],\n",
       "              \n",
       "                       [[ 8.1734e-02,  8.8158e-02, -6.0623e-03],\n",
       "                        [-1.3552e-02,  1.7424e-02, -2.4486e-02],\n",
       "                        [ 3.5882e-03, -9.9828e-02, -8.6531e-02]],\n",
       "              \n",
       "                       [[ 7.2233e-02, -6.1597e-02,  8.3008e-02],\n",
       "                        [ 1.1568e-02,  2.5676e-02,  9.5804e-02],\n",
       "                        [-5.8628e-02, -1.6640e-02,  1.8675e-02]],\n",
       "              \n",
       "                       [[ 3.6012e-02, -1.0259e-01,  3.7464e-02],\n",
       "                        [-6.2163e-02,  1.3846e-02,  7.1315e-02],\n",
       "                        [-1.0500e-02, -3.3346e-03, -7.8757e-03]],\n",
       "              \n",
       "                       [[ 8.7962e-02,  5.9907e-02,  1.7727e-02],\n",
       "                        [-6.3437e-02, -5.7241e-02,  8.3964e-02],\n",
       "                        [ 7.5834e-02,  6.1033e-02, -8.2189e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.2092e-02, -1.0076e-02,  7.7661e-02],\n",
       "                        [ 9.1553e-02,  1.1554e-02, -4.3863e-02],\n",
       "                        [ 9.9153e-02, -5.4931e-02,  6.8876e-02]],\n",
       "              \n",
       "                       [[-1.0108e-01, -3.3153e-02, -9.1902e-02],\n",
       "                        [-4.7284e-02,  4.4759e-02, -7.5529e-02],\n",
       "                        [-9.1158e-02,  7.5371e-02,  5.6270e-02]],\n",
       "              \n",
       "                       [[-1.1527e-03, -7.4309e-02, -2.7927e-02],\n",
       "                        [-3.4129e-02,  6.5100e-02, -3.4478e-02],\n",
       "                        [-3.0360e-02, -7.4720e-02, -4.9646e-02]],\n",
       "              \n",
       "                       [[ 5.7074e-02,  6.7914e-02,  1.5315e-02],\n",
       "                        [-3.9549e-02,  1.0124e-01,  2.0806e-02],\n",
       "                        [-4.0688e-02, -3.6535e-02, -1.4752e-02]],\n",
       "              \n",
       "                       [[ 4.9974e-02,  3.8555e-02,  7.6418e-02],\n",
       "                        [-4.7494e-03,  8.7183e-02, -4.2816e-02],\n",
       "                        [-4.8547e-02, -3.8927e-02, -9.8896e-02]],\n",
       "              \n",
       "                       [[-6.9195e-02, -9.5382e-02, -6.2294e-03],\n",
       "                        [ 9.9374e-04, -2.7358e-02, -7.2035e-02],\n",
       "                        [ 9.5637e-02, -3.4926e-02,  5.0233e-02]],\n",
       "              \n",
       "                       [[ 7.3408e-02, -6.9292e-02, -1.3179e-02],\n",
       "                        [ 6.0923e-02,  1.0218e-01, -1.3299e-02],\n",
       "                        [ 7.6382e-02, -8.2732e-02, -6.8489e-02]],\n",
       "              \n",
       "                       [[ 8.6682e-02, -9.9801e-03,  1.0414e-01],\n",
       "                        [ 7.6651e-03, -4.3714e-02,  1.0011e-01],\n",
       "                        [ 9.2179e-02,  9.7826e-03, -6.3900e-02]],\n",
       "              \n",
       "                       [[-4.5639e-03, -5.0693e-02,  7.6810e-02],\n",
       "                        [ 4.8829e-03,  2.2191e-02,  6.3927e-02],\n",
       "                        [ 3.4916e-02, -6.5803e-02,  8.7566e-02]],\n",
       "              \n",
       "                       [[ 6.4758e-02, -6.5073e-02,  7.9700e-02],\n",
       "                        [ 2.9905e-02, -2.0750e-02, -7.5385e-02],\n",
       "                        [-1.7490e-02, -1.0335e-01,  6.0163e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.6343e-02, -3.0347e-02,  9.7720e-02],\n",
       "                        [-3.9032e-02,  1.8051e-02, -7.3459e-02],\n",
       "                        [-4.4565e-03,  4.2610e-02,  4.5403e-02]],\n",
       "              \n",
       "                       [[-3.5346e-03, -5.3154e-02,  7.3680e-02],\n",
       "                        [ 6.9788e-02,  1.6916e-02, -4.8475e-02],\n",
       "                        [ 2.2349e-02,  2.8186e-04,  9.6302e-02]],\n",
       "              \n",
       "                       [[ 1.5621e-02,  8.1301e-03,  7.2057e-03],\n",
       "                        [ 5.6079e-02, -1.3024e-03,  9.0351e-02],\n",
       "                        [ 5.4917e-02, -7.9650e-02, -1.2070e-06]],\n",
       "              \n",
       "                       [[-8.9472e-02, -8.0934e-02,  2.0480e-02],\n",
       "                        [ 2.3687e-02, -9.2246e-03,  1.0019e-01],\n",
       "                        [-5.6627e-02, -4.4176e-02, -1.6881e-02]],\n",
       "              \n",
       "                       [[ 6.3911e-04, -8.9284e-03,  9.4909e-02],\n",
       "                        [-4.4519e-02, -5.5137e-02,  9.0599e-03],\n",
       "                        [ 7.9171e-02,  2.5019e-02,  5.6787e-02]],\n",
       "              \n",
       "                       [[ 2.0406e-02,  8.9839e-02,  6.3311e-02],\n",
       "                        [ 7.5428e-02, -1.4198e-02, -8.7268e-02],\n",
       "                        [-5.0002e-02,  3.5910e-02,  7.3950e-02]],\n",
       "              \n",
       "                       [[-4.1184e-02,  8.7218e-02,  1.5150e-02],\n",
       "                        [ 4.1869e-04,  4.1093e-03, -1.8623e-02],\n",
       "                        [ 9.8683e-02,  4.5784e-03,  6.4564e-02]],\n",
       "              \n",
       "                       [[-8.8967e-02, -5.4309e-02,  1.1852e-02],\n",
       "                        [ 8.4169e-02,  5.0184e-02,  2.0076e-02],\n",
       "                        [-1.0414e-01,  1.9816e-03, -6.9581e-02]],\n",
       "              \n",
       "                       [[-9.0006e-02,  1.4414e-02, -6.6693e-02],\n",
       "                        [ 9.5674e-02, -5.7294e-02,  3.3970e-02],\n",
       "                        [ 6.1871e-02, -8.1928e-02,  5.3946e-02]],\n",
       "              \n",
       "                       [[-1.4114e-02,  5.4619e-02,  1.0201e-01],\n",
       "                        [-4.4922e-02, -4.5653e-02,  8.3753e-02],\n",
       "                        [ 1.1722e-02, -1.0513e-02,  7.9971e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.0928e-02, -5.2047e-03,  7.2403e-02],\n",
       "                        [ 4.1195e-02, -6.8180e-02,  2.7398e-02],\n",
       "                        [-8.0368e-02, -5.7245e-02,  6.7779e-02]],\n",
       "              \n",
       "                       [[-2.8093e-02, -5.3691e-02,  7.4717e-03],\n",
       "                        [ 2.5759e-02, -6.5524e-02, -7.1084e-02],\n",
       "                        [-1.0209e-01,  2.7236e-02, -6.8013e-02]],\n",
       "              \n",
       "                       [[ 8.0331e-03, -2.3576e-02, -6.8923e-02],\n",
       "                        [-3.3636e-02, -8.1027e-02, -5.5797e-02],\n",
       "                        [-3.2857e-03, -9.0116e-02, -9.2447e-02]],\n",
       "              \n",
       "                       [[ 7.8958e-02,  9.9188e-03, -4.6618e-02],\n",
       "                        [-3.5047e-03,  7.8168e-02, -8.7939e-02],\n",
       "                        [-5.5886e-02, -7.6226e-02, -7.6634e-03]],\n",
       "              \n",
       "                       [[-3.6274e-03, -8.2146e-02,  7.3163e-02],\n",
       "                        [-8.0946e-02,  9.8414e-02, -7.2560e-02],\n",
       "                        [-1.4446e-02,  1.9710e-02, -4.6852e-02]],\n",
       "              \n",
       "                       [[ 9.6939e-02, -7.2673e-02, -5.8427e-03],\n",
       "                        [-7.7398e-02,  2.9261e-02,  8.9871e-02],\n",
       "                        [ 9.7776e-02,  1.2514e-02, -5.2773e-02]],\n",
       "              \n",
       "                       [[ 1.0244e-01,  7.8667e-03,  7.1317e-02],\n",
       "                        [-5.4751e-02, -4.8920e-02, -8.7504e-02],\n",
       "                        [ 9.6990e-02,  1.7486e-02, -7.5704e-02]],\n",
       "              \n",
       "                       [[ 9.0535e-03, -4.5211e-02,  5.2659e-03],\n",
       "                        [ 3.4988e-02, -5.2308e-02,  1.8394e-02],\n",
       "                        [-6.6553e-02,  2.0312e-02, -1.0178e-01]],\n",
       "              \n",
       "                       [[ 1.6797e-02,  1.0473e-01,  9.7094e-02],\n",
       "                        [ 3.8451e-02,  7.7563e-02,  1.0248e-01],\n",
       "                        [ 2.9870e-02,  3.5156e-02,  1.3707e-02]],\n",
       "              \n",
       "                       [[ 9.3322e-02,  9.0551e-02, -4.9570e-02],\n",
       "                        [-4.3333e-03, -5.3110e-02,  3.7824e-02],\n",
       "                        [-1.0214e-01,  3.7301e-02, -2.8929e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.8227e-02,  3.2899e-02, -5.2454e-02],\n",
       "                        [ 5.4687e-02,  4.4762e-02, -8.9602e-02],\n",
       "                        [ 1.0517e-01,  9.0731e-02,  6.5584e-02]],\n",
       "              \n",
       "                       [[-1.0699e-02,  3.7345e-02, -5.7028e-02],\n",
       "                        [-3.5818e-02,  4.9749e-02,  4.6925e-02],\n",
       "                        [ 4.1741e-02, -1.0053e-01,  8.7350e-02]],\n",
       "              \n",
       "                       [[-4.4028e-02,  9.1223e-02,  8.6852e-02],\n",
       "                        [ 3.9070e-02,  1.0502e-01,  6.0528e-02],\n",
       "                        [ 6.1821e-02, -3.5794e-02,  9.7766e-02]],\n",
       "              \n",
       "                       [[ 2.7627e-02,  6.2280e-02, -2.3834e-02],\n",
       "                        [ 7.6340e-02,  9.3509e-02, -8.0770e-02],\n",
       "                        [ 8.6415e-02, -6.9664e-02, -7.2571e-02]],\n",
       "              \n",
       "                       [[-8.8089e-02,  3.0459e-02, -7.9144e-02],\n",
       "                        [-3.9680e-02, -5.2988e-02,  2.8172e-02],\n",
       "                        [-1.0349e-01, -4.8324e-02,  7.7112e-04]],\n",
       "              \n",
       "                       [[ 9.4660e-03, -4.7605e-02,  3.7764e-02],\n",
       "                        [-6.9544e-02, -8.9270e-02, -1.4986e-02],\n",
       "                        [-5.6989e-02,  6.6443e-02, -7.2049e-02]],\n",
       "              \n",
       "                       [[-8.8494e-03,  4.3782e-02, -9.2311e-02],\n",
       "                        [ 8.1599e-02, -4.7895e-02, -2.8684e-02],\n",
       "                        [-6.4480e-02, -3.9279e-02, -4.0645e-02]],\n",
       "              \n",
       "                       [[-9.3801e-02,  3.6019e-02, -3.3768e-04],\n",
       "                        [ 1.0311e-01,  7.1117e-02,  9.1699e-02],\n",
       "                        [ 3.1014e-02,  5.5388e-02,  9.8704e-02]],\n",
       "              \n",
       "                       [[ 8.6545e-02, -8.0996e-02, -2.3636e-02],\n",
       "                        [-1.0166e-01,  3.9877e-03, -3.7229e-02],\n",
       "                        [ 9.1486e-02,  1.6666e-02,  1.1601e-03]],\n",
       "              \n",
       "                       [[-7.6248e-02, -8.2718e-02,  1.6594e-02],\n",
       "                        [-5.2376e-02, -4.8409e-02,  7.3938e-02],\n",
       "                        [-5.4952e-02, -4.6918e-02,  8.0934e-02]]]])),\n",
       "             ('conv_block_2.2.bias',\n",
       "              tensor([ 0.0412, -0.0599,  0.0319,  0.0531, -0.0936,  0.0197,  0.0241, -0.0041,\n",
       "                       0.1011, -0.0697])),\n",
       "             ('classifier.1.weight',\n",
       "              tensor([[ 0.0245, -0.0240, -0.0387,  ...,  0.0094, -0.0015, -0.0225],\n",
       "                      [ 0.0228,  0.0067, -0.0439,  ..., -0.0302,  0.0368,  0.0293],\n",
       "                      [ 0.0303,  0.0347, -0.0211,  ...,  0.0207, -0.0423, -0.0240],\n",
       "                      ...,\n",
       "                      [-0.0359, -0.0343,  0.0166,  ...,  0.0324,  0.0113, -0.0143],\n",
       "                      [-0.0294, -0.0316,  0.0251,  ..., -0.0056,  0.0300, -0.0396],\n",
       "                      [-0.0246, -0.0035, -0.0046,  ..., -0.0146, -0.0358,  0.0175]])),\n",
       "             ('classifier.1.bias',\n",
       "              tensor([ 0.0320, -0.0445,  0.0246, -0.0357, -0.0442,  0.0156, -0.0010, -0.0277,\n",
       "                       0.0404,  0.0037]))])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and testing for `model_2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2fd3bc0865a46aba313487ad8f7ef48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 \n",
      "---\n",
      "Train Loss:0.30448 | Train Acc: 88.97667%\n",
      "Test Loss: 0.3324, Test Acc: 88.0791%\n",
      "Epoch : 1 \n",
      "---\n",
      "Train Loss:0.29002 | Train Acc: 89.47167%\n",
      "Test Loss: 0.3099, Test Acc: 88.7780%\n",
      "Epoch : 2 \n",
      "---\n",
      "Train Loss:0.27965 | Train Acc: 89.83167%\n",
      "Test Loss: 0.2917, Test Acc: 89.3071%\n",
      "Epoch : 3 \n",
      "---\n",
      "Train Loss:0.27184 | Train Acc: 90.09000%\n",
      "Test Loss: 0.2887, Test Acc: 89.1573%\n",
      "Epoch : 4 \n",
      "---\n",
      "Train Loss:0.26359 | Train Acc: 90.47833%\n",
      "Test Loss: 0.2884, Test Acc: 89.6665%\n",
      "Epoch : 5 \n",
      "---\n",
      "Train Loss:0.25779 | Train Acc: 90.59833%\n",
      "Test Loss: 0.2895, Test Acc: 89.6665%\n",
      "Epoch : 6 \n",
      "---\n",
      "Train Loss:0.25147 | Train Acc: 90.83833%\n",
      "Test Loss: 0.2840, Test Acc: 89.8762%\n",
      "Epoch : 7 \n",
      "---\n",
      "Train Loss:0.25204 | Train Acc: 90.80333%\n",
      "Test Loss: 0.2875, Test Acc: 89.5667%\n",
      "Epoch : 8 \n",
      "---\n",
      "Train Loss:0.24603 | Train Acc: 90.94667%\n",
      "Test Loss: 0.2822, Test Acc: 90.0759%\n",
      "Epoch : 9 \n",
      "---\n",
      "Train Loss:0.24133 | Train Acc: 91.15333%\n",
      "Test Loss: 0.3021, Test Acc: 88.9377%\n",
      "Train time is 737.526 seconds\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "from timeit import default_timer as timer\n",
    "train_time_start_model_2 = timer()\n",
    "\n",
    "epochs = 10\n",
    "for epoch in tqdm(range(epochs)):\n",
    "  print(f\"Epoch : {epoch} \\n---\")\n",
    "  train_step(model = model_2, data_loader= train_dataloader, loss_fn= loss_fn, optimizer=optimizer, accuracy_fn=accuracy_fn)\n",
    "  test_step(model=model_2, data_loader= test_dataloader, loss_fn = loss_fn, accuracy_fn=accuracy_fn)\n",
    "train_time_end_model_2 = timer()\n",
    "total_train_time = print_train_time(start = train_time_start_model_2,\n",
    "                                    end = train_time_end_model_2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07bca7c181c4592b2008ed2ed35101a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV2',\n",
       " 'model_loss': 0.3021107316017151,\n",
       " 'model_acc': 88.93769968051119}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_results = eval_model(model = model_2,\n",
    "                             data_loader=test_dataloader,\n",
    "                             loss_fn = loss_fn,\n",
    "                             accuracy_fn = accuracy_fn)\n",
    "\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV0',\n",
       " 'model_loss': 0.46279823780059814,\n",
       " 'model_acc': 83.64616613418531}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_loss</th>\n",
       "      <th>model_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FashionMNISTModelV0</td>\n",
       "      <td>0.462798</td>\n",
       "      <td>83.646166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FashionMNISTModelV1</td>\n",
       "      <td>0.685001</td>\n",
       "      <td>75.019968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FashionMNISTModelV2</td>\n",
       "      <td>0.302111</td>\n",
       "      <td>88.937700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name  model_loss  model_acc\n",
       "0  FashionMNISTModelV0    0.462798  83.646166\n",
       "1  FashionMNISTModelV1    0.685001  75.019968\n",
       "2  FashionMNISTModelV2    0.302111  88.937700"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "compare_results = pd.DataFrame([model_0_results,\n",
    "                                model_1_results, model_2_results])\n",
    "compare_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
