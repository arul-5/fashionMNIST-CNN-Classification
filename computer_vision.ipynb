{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arulk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "#importing necessary libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.FashionMNIST(root = \"data\",\n",
    "                                  train = True,\n",
    "                                  download=True,\n",
    "                                   transform=ToTensor(),\n",
    "                                   target_transform=None\n",
    "                                   )\n",
    "test_data = datasets.FashionMNIST(\n",
    "  root = \"data\",\n",
    "  train = False,\n",
    "  download=True,\n",
    "  transform=ToTensor(),\n",
    "  target_transform=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
       "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
       "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
       "           0.0157, 0.0000, 0.0000, 0.0118],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
       "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0471, 0.0392, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
       "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
       "           0.3020, 0.5098, 0.2824, 0.0588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
       "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
       "           0.5529, 0.3451, 0.6745, 0.2588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
       "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
       "           0.4824, 0.7686, 0.8980, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
       "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
       "           0.8745, 0.9608, 0.6784, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
       "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
       "           0.8627, 0.9529, 0.7922, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
       "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
       "           0.8863, 0.7725, 0.8196, 0.2039],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
       "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
       "           0.9608, 0.4667, 0.6549, 0.2196],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
       "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
       "           0.8510, 0.8196, 0.3608, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
       "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
       "           0.8549, 1.0000, 0.3020, 0.0000],\n",
       "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
       "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
       "           0.8784, 0.9569, 0.6235, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
       "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
       "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
       "           0.9137, 0.9333, 0.8431, 0.0000],\n",
       "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
       "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
       "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
       "           0.8627, 0.9098, 0.9647, 0.0000],\n",
       "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
       "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
       "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
       "           0.8706, 0.8941, 0.8824, 0.0000],\n",
       "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
       "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
       "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
       "           0.8745, 0.8784, 0.8980, 0.1137],\n",
       "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
       "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
       "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
       "           0.8627, 0.8667, 0.9020, 0.2627],\n",
       "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
       "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
       "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
       "           0.7098, 0.8039, 0.8078, 0.4510],\n",
       "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
       "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
       "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
       "           0.6549, 0.6941, 0.8235, 0.3608],\n",
       "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
       "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
       "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
       "           0.7529, 0.8471, 0.6667, 0.0000],\n",
       "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
       "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
       "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
       "           0.3882, 0.2275, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
       "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = train_data[0]\n",
    "image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T-shirt/top': 0,\n",
       " 'Trouser': 1,\n",
       " 'Pullover': 2,\n",
       " 'Dress': 3,\n",
       " 'Coat': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'Bag': 8,\n",
       " 'Ankle boot': 9}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_to_idx = train_data.class_to_idx\n",
    "class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 0, 0,  ..., 3, 0, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2958648dc30>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualizing the data\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "plt.imshow(image.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.squeeze(), cmap = \"gray\")\n",
    "plt.title(class_names[label])\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset FashionMNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: ToTensor(),\n",
       " Dataset FashionMNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: data\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: ToTensor())"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "BATCH_SIZE = 32\n",
    "train_dataloader = DataLoader(dataset =train_data,\n",
    "                              batch_size = BATCH_SIZE,\n",
    "                              shuffle = True)\n",
    "test_dataloader = DataLoader(dataset = test_data,\n",
    "                             batch_size = BATCH_SIZE,\n",
    "                             shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x2958644bd00>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x2958648d9c0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before flattening: torch.Size([1, 28, 28])\n",
      "Shape after flattening: torch.Size([1, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten_model  = nn.Flatten()\n",
    "x = train_features_batch[0] \n",
    "output = flatten_model(x)\n",
    "print(f\"Shape before flattening: {x.shape}\")\n",
    "print(f\"Shape after flattening: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTModelV0(nn.Module):\n",
    "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "    super().__init__()\n",
    "    self.layer_stack = nn.Sequential(\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "      nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
    "    )\n",
    "  def forward(self,x):\n",
    "    return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNISTModelV0(\n",
       "  (layer_stack): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model_0  =FashionMNISTModelV0(\n",
    "  input_shape=28*28,\n",
    "  hidden_units=10,\n",
    "  output_shape=len(class_names)\n",
    "\n",
    ")\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0315,  0.3171,  0.0531, -0.2525,  0.5959,  0.2112,  0.3233,  0.2694,\n",
       "         -0.1004,  0.0157]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_x = torch.rand([1,1,28,28])\n",
    "model_0(dummy_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer_stack.1.weight',\n",
       "              tensor([[ 0.0273,  0.0296, -0.0084,  ..., -0.0142,  0.0093,  0.0135],\n",
       "                      [-0.0188, -0.0354,  0.0187,  ..., -0.0106, -0.0001,  0.0115],\n",
       "                      [-0.0008,  0.0017,  0.0045,  ..., -0.0127, -0.0188,  0.0059],\n",
       "                      ...,\n",
       "                      [-0.0116,  0.0273, -0.0344,  ...,  0.0176,  0.0283, -0.0011],\n",
       "                      [-0.0230,  0.0257,  0.0291,  ..., -0.0187, -0.0087,  0.0001],\n",
       "                      [ 0.0176, -0.0147,  0.0053,  ..., -0.0336, -0.0221,  0.0205]])),\n",
       "             ('layer_stack.1.bias',\n",
       "              tensor([-0.0093,  0.0283, -0.0033,  0.0255,  0.0017,  0.0037, -0.0302, -0.0123,\n",
       "                       0.0018,  0.0163])),\n",
       "             ('layer_stack.2.weight',\n",
       "              tensor([[ 0.0614, -0.0687,  0.0021,  0.2718,  0.2109,  0.1079, -0.2279, -0.1063,\n",
       "                        0.2019,  0.2847],\n",
       "                      [-0.1495,  0.1344, -0.0740,  0.2006, -0.0475, -0.2514, -0.3130, -0.0118,\n",
       "                        0.0932, -0.1864],\n",
       "                      [ 0.2488,  0.1500,  0.1907,  0.1457, -0.3050, -0.0580,  0.1643,  0.1565,\n",
       "                       -0.2877, -0.1792],\n",
       "                      [ 0.2305, -0.2618,  0.2397, -0.0610,  0.0232,  0.1542,  0.0851, -0.2027,\n",
       "                        0.1030, -0.2715],\n",
       "                      [-0.1596, -0.0555, -0.0633,  0.2302, -0.1726,  0.2654,  0.1473,  0.1029,\n",
       "                        0.2252, -0.2160],\n",
       "                      [-0.2725,  0.0118,  0.1559,  0.1596,  0.0132,  0.3024,  0.1124,  0.1366,\n",
       "                       -0.1533,  0.0965],\n",
       "                      [-0.1184, -0.2555, -0.2057, -0.1909, -0.0477, -0.1324,  0.2905,  0.1307,\n",
       "                       -0.2629,  0.0133],\n",
       "                      [ 0.2727, -0.0127,  0.0513,  0.0863, -0.1043, -0.2047, -0.1185, -0.0825,\n",
       "                        0.2488, -0.2571],\n",
       "                      [ 0.0425, -0.1209, -0.0336, -0.0281, -0.1227,  0.0730,  0.0747, -0.1816,\n",
       "                        0.1943,  0.2853],\n",
       "                      [-0.1310,  0.0645, -0.1171,  0.2168, -0.0245, -0.2820,  0.0736,  0.2621,\n",
       "                        0.0012, -0.0810]])),\n",
       "             ('layer_stack.2.bias',\n",
       "              tensor([-0.0087,  0.1791,  0.2712, -0.0791,  0.1685,  0.1762,  0.2825,  0.2266,\n",
       "                      -0.2612, -0.2613]))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "  correct = torch.eq(y_true, y_pred).sum().item()\n",
    "  acc= (correct/ len(y_pred)) * 100\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params = model_0.parameters(),\n",
    "                           lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer \n",
    "def print_train_time(start:float, end: float, device: torch.device = None):\n",
    "  \"\"\"prints difference start and end time\"\"\"\n",
    "  total_time = end-start\n",
    "  print(f\"Train time is {total_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc6daedc9cf4840bdf8e7e79bab1ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4909 | Test Loss: 0.4922, Test Acc: 82.7576\n",
      "Epoch: 1\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4487 | Test Loss: 0.4705, Test Acc: 83.7061\n",
      "Epoch: 2\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4373 | Test Loss: 0.4688, Test Acc: 83.6961\n",
      "Epoch: 3\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4295 | Test Loss: 0.4584, Test Acc: 83.8059\n",
      "Epoch: 4\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4256 | Test Loss: 0.4644, Test Acc: 83.3666\n",
      "Epoch: 5\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4207 | Test Loss: 0.4574, Test Acc: 83.9257\n",
      "Epoch: 6\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4176 | Test Loss: 0.4861, Test Acc: 83.3267\n",
      "Epoch: 7\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4165 | Test Loss: 0.4708, Test Acc: 83.5164\n",
      "Epoch: 8\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4148 | Test Loss: 0.4746, Test Acc: 83.4365\n",
      "Epoch: 9\n",
      "----\n",
      "Looked at 0/60000 samples.\n",
      "Looked at 12800/60000 samples.\n",
      "Looked at 25600/60000 samples.\n",
      "Looked at 38400/60000 samples.\n",
      "Looked at 51200/60000 samples.\n",
      "\n",
      "Train Loss: 0.4126 | Test Loss: 0.4632, Test Acc: 83.6462\n",
      "Train time is 50.747 seconds\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "torch.manual_seed(42)\n",
    "start_time = timer()\n",
    "epochs = 10\n",
    "for epoch in tqdm(range(epochs)):\n",
    "  print(f\"Epoch: {epoch}\\n----\")\n",
    "  train_loss = 0\n",
    "  for batch, (X,y) in enumerate(train_dataloader):\n",
    "    model_0.train()\n",
    "    y_pred  =model_0(X)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    train_loss += loss\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch%400 ==0:\n",
    "       print(f\"Looked at {batch*len(X)}/{len(train_dataloader.dataset)} samples.\")\n",
    "  train_loss /= len(train_dataloader )\n",
    "  test_loss, test_acc = 0,0\n",
    "  model_0.eval()\n",
    "  with torch.inference_mode():\n",
    "    for X, y in test_dataloader:\n",
    "      test_pred = model_0(X)\n",
    "      test_loss += loss_fn(test_pred, y)\n",
    "      \n",
    "      test_acc += accuracy_fn(y_true = y, y_pred  =test_pred.argmax(dim=1))\n",
    "    test_loss /= len(test_dataloader)\n",
    "    test_acc /= len(test_dataloader)\n",
    "  print(f\"\\nTrain Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "end_time = timer()\n",
    "total_train_time = print_train_time(start=start_time, end=end_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4dd0d6934f34a9baf3c36de11f1e910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV0',\n",
       " 'model_loss': 0.450991153717041,\n",
       " 'model_acc': 84.29512779552715}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "def eval_model(model: torch.nn.Module, data_loader: torch.utils.data.DataLoader,loss_fn: torch.nn.Module, accuracy_fn):\n",
    "  '''returns a dictionary containing the results of model predicting on data loader'''\n",
    "  loss, acc =0,0\n",
    "  model.eval()\n",
    "  with torch.inference_mode():\n",
    "    for X,y in tqdm(data_loader):\n",
    "      y_pred = model(X)\n",
    "      loss += loss_fn(y_pred,y)\n",
    "      acc += accuracy_fn(y_true = y, y_pred = y_pred.argmax(dim=1))\n",
    "    loss /= len(data_loader)\n",
    "    acc  /= len(data_loader)\n",
    "  return {\"model_name\": model.__class__.__name__,\n",
    "          \"model_loss\": loss.item(),\n",
    "          \"model_acc\": acc}\n",
    "model_0_results = eval_model(model = model_0, data_loader = test_dataloader, loss_fn = loss_fn, accuracy_fn = accuracy_fn)\n",
    "model_0_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model with non linear layers\n",
    "class FashionMNISTModelV1(nn.Module):\n",
    "  def __init__(self, \n",
    "               input_shape:int,\n",
    "               hidden_units: int,\n",
    "               output_shape: int):\n",
    "    super().__init__()\n",
    "    self.layer_stack = nn.Sequential(\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "  def forward(self, x: torch.Tensor):\n",
    "    return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0273,  0.0296, -0.0084,  ..., -0.0142,  0.0093,  0.0135],\n",
       "        [-0.0188, -0.0354,  0.0187,  ..., -0.0106, -0.0001,  0.0115],\n",
       "        [-0.0008,  0.0017,  0.0045,  ..., -0.0127, -0.0188,  0.0059],\n",
       "        ...,\n",
       "        [-0.0116,  0.0273, -0.0344,  ...,  0.0176,  0.0283, -0.0011],\n",
       "        [-0.0230,  0.0257,  0.0291,  ..., -0.0187, -0.0087,  0.0001],\n",
       "        [ 0.0176, -0.0147,  0.0053,  ..., -0.0336, -0.0221,  0.0205]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model_1 = FashionMNISTModelV1(input_shape=784,\n",
    "                              hidden_units=10,\n",
    "                              output_shape=len(class_names))\n",
    "next(model_1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.train()\n",
    "    for batch, (X,y) in enumerate(data_loader):\n",
    "      y_pred  =model(X)\n",
    "      loss = loss_fn(y_pred, y)\n",
    "      train_loss += loss\n",
    "      train_acc += accuracy_fn(y_true = y, \n",
    "                               y_pred = y_pred.argmax(dim=1))\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "    train_loss /= len(data_loader )\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train Loss:{train_loss:.5f} | Train Acc: {train_acc:.5f}%\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module,\n",
    "              data_loader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn):\n",
    "  model.eval()\n",
    "  with torch.inference_mode():\n",
    "    for X, y in data_loader:\n",
    "      test_pred = model(X)\n",
    "      test_loss += loss_fn(test_pred, y)\n",
    "        \n",
    "      test_acc += accuracy_fn(y_true = y, y_pred  =test_pred.argmax(dim=1))\n",
    "    test_loss /= len(data_loader)\n",
    "    test_acc /= len(data_loader)\n",
    "  print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
